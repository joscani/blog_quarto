---
title: Error irreducible
date: '2025-02-24'
categories: 
  - estadística
  - pensamientos
  - obviedades
  - "2025"
description: ''
execute: 
  message: false
  warning: false
  echo: true
  output: true
format: 
  html: 
    toc: true
    fig-height: 5
    fig-dpi: 300
    fig-width: 8
    fig-align: center
    code-fold: show
    code-link: true
    code-summary: "Show the code"
    code-tools: true 
knitr:
  opts_chunk:
    out.width: 80%
    fig.showtext: TRUE
    collapse: true
    comment: "#>"
image: "pendiente_imagen.png"
---


::: callout-note
## Listening

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/3DT23wxXsPHMDjSEFNeHH0?utm_source=generator" width="100%" height="250" frameBorder="0" allowfullscreen="" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>

:::



A pesar de todo el _hype_ de la IA y del _Machín Lenin_  hay una cosa muy obvia que se le olvida a la mayoría de la gente, y es el error irreducible. 

Imaginad, que como pasa en la vida real,  se quiere modelar por ejemplo la propensión de comprar un producto por parte de clientes. 
Y se tienen recogidas digamos unas 4 variables, pues lo más normal es que a igual valor en las 4 variables  unos clientes compren y otros no, y por lo tanto
es imposible tener un acierto total. Ni con IA, ni con _Machín Lenin_ ni que el mismo Odín te ayude con el tema. 

Y eso hace por tanto que haya un límite a métricas a AUC-ROC y similares. 


Ejemplo tonto. 

Digamos que tenemos 2 variables

```{r}
library(tidyverse)

x1 <- c("A", "B", "C")
x2 <- c("D", "E", "F")

n <- c (100, 200,400, 150, 200, 300, 400, 25, 90 ) 
exitos  <-  round(n * c(0.4, 0.6, 0.2, 0.5, 0.9, 0.15, 0.3, 0.7, 0.1)) 

df  <-  expand.grid(x1, x2)

df$n  <-  n
df$exitos  <-  exitos
names(df)[1:2]  <-  c("x1", "x2")

df

# Expandir los datos, añado la prop_real
df_exp <- df   |> 
  rowwise()  |> 
  mutate(data = list(tibble(x1 = x1, x2 = x2, prop_real = exitos /n,  y = c(rep(1, exitos), rep(0, n - exitos)))))  |> 
  select(-x1, -x2, -n, -exitos)  |> 
  unnest(data)  |> 
  mutate(y = as.factor(y))  |> 
  select(x1, x2, y, prop_real)


skimr::skim(df_exp)

```


```{r}


DT::datatable(head(df_exp, 100))

df_exp  |> 
  group_by(x1, x2)  |> 
  summarise(
            n = n(), 
            exitos = sum(as.numeric(y)-1),
            prop_real = mean(prop_real)
  )


```

Con esas 2 variables, x1  y x2 un modelo perfecto como mucho daría un 0.4 de probabilidad a todas las
filas que tengan `x1 = "A"`  y `x2= "D"`

Pues aquí el modelo perfecto tendría como mucho el siguiente _auc_roc_

```{r}

yardstick::roc_auc_vec( df_exp$y, df_exp$prop_real, event_level = "second")

```


Pues como decía, hay un error irreducible. Esto es importante a la hora de gestionar expectativas en 
nuestros análisis. Incluso un modelo perfecto (al predecir nuevos datos) puede no llegar a tener unas 
métricas maravillosas. 


