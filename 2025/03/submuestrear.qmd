---
title: Submuestrear si es pecado
date: '2025-03-22'
categories: 
  - estadística
  - muestreo
  - "2025"
description: ''
execute: 
  message: false
  warning: false
  echo: true
  output: true
format: 
  html: 
    toc: true
    fig-height: 5
    fig-dpi: 300
    fig-width: 8
    fig-align: center
    code-fold: show
    code-link: true
    code-summary: "Show the code"
    code-tools: true 
knitr:
  opts_chunk:
    out.width: 80%
    fig.showtext: TRUE
    collapse: true
    comment: "#>"
image: "ups.jpg"
---


::: callout-note
## Watching

<iframe 
  width="560" 
  height="315" 
  src="https://www.youtube.com/embed/lm53uqt-ln0" 
  title="Probability song" 
  frameborder="0" 
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
  allowfullscreen>
</iframe>
:::


Aunque el título de este blog es Muestrear no es pecado, hoy quiero comentar brevemente algo que creo  que si no es pecado, se acerca bastante. Se trata del submuestreo.

El miércoles pasado estaba de cervezas con mi amiga Laura y su pareja  y comentábamos muchas de las  cosas que se hacen mal en la industria. Y me acordé del próximo podcast que vamos a sacar Leo y yo dónde tratamos de forma tangencial el tema del submuestreo. 

Al grano, mucha gente piensa que cuando tienes que modelar una variable dicotómica en la que la proporción del  "éxito" es muy pequeña, (típicamente lo llaman "dataset desbalanceado"), creen que lo que hay que hacer es algún tipo de balanceo, y entre los más conocidos está el submustrear observaciones de la clase mayoritaria.  Básicamente, eliminar filas . 

Se supone que de esta forma se facilita el ajuste  de los algoritmos de Machín Lenin. Por la red se  puede encontrar fácilmente demostracinoes que por ejemplo en el caso de la regresión logística el modelo que se obtiene submuestreando y sin submuestrear es equivalente en cuánto al orden de los "scores".  Y en otro tipo de algoritmos como los basados en árboles uno podría pensar que tendría cierta lógica, pero existen alternativas. 

Por ejemplo, se puede dar un peso a las observaciones de la clase minoritaria de forma que el algoritmo las tenga más en cuenta sin tener que descartar observaciones de la mayoritaria, o incluso modificar la función de coste utilizada de forma que se penalice más equivocarse en la predicción de esa clase. 

Con el afán de submuestrear (o balancear) he visto por esos lares aberraciones como la de submuestrear en el conjunto de train,  estandarizar las variables en ese conjunto de train submuestreado y aplicar esas medias y desviaciones típicas al conjunto que se va a predecir,  lo cual, obviamente es un error conceptual grave. 

Pues nada más, a ver si Leo puede editar pronto el episodio que grabamos hablando sobre bootstrap, submuestreo  y demás cositas.  Yo creo que estuvo bastante bien, al menos yo me lo pasé estupendamente grabándolo. 




