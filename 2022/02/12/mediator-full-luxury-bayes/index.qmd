---
title: Mediator. Full luxury bayes
author: jlcr
date: '2022-02-12'
slug: mediator-full-luxury-bayes
categories:
  - bayesian
  - estadística
tags:
  - análisis bayesiano
  - causal inference
  - R
description: ''
topics: []
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

Continuando con la serie sobre cosas de inferencia causal y full luxury bayes, antes de que empiece mi amigo [Carlos Gil](https://www.datanalytics.com/), y dónde seguramente se aprenderá más. 


Este ejemplo viene motivado precisamente por una charla que tuve el otro día con él. 

Sea el siguiente diagrama causal 

```{r}
  library(tidyverse)
  library(dagitty)
  library(ggdag)
  
  g <- dagitty("dag{ 
  x -> y ;
  z -> y ;
  x -> z
 }")
  
  
  ggdag(g) 
```


Se tiene que `z` es un mediador entre x e y, y la teoría nos dice que si quiero obtener el efecto directo de x sobre y he de condicionar por `z` , y efectivamente, así nos lo dice el backdoor criterio. Mientras que si quiero el efecto total de x sobre y no he de condicionar por `z`.


```{r}
  adjustmentSets(g, exposure = "x", outcome = "y", effect = "total"  )
  adjustmentSets(g, exposure = "x", outcome = "y", effect = "direct"  )

```



## Datos simulados


```{r}

set.seed(155)
N <- 1000 

x <- rnorm(N, 2, 1) 
z <- rnorm(N, 4+ 4*x , 2 ) # a z le ponemos más variabilidad, pero daría igual
y <- rnorm(N, 2+ 3*x + z, 1)

```


**Efecto total de x sobre y **

Tal y como hemos simulado los datos, se esperaría que el efecto *total* de x sobre y fuera 

$$ \dfrac{cov(x,y)} {var(x)} \approx 7 $$

Y qué el efecto *directo* fuera de 3 

Efectivamente 

Efecto total

```{r}
# efecto total
lm(y~x)
```


```{r}
# efecto directo
lm(y~x+z)
```


## Full luxury bayes

Hagamos lo mismo pero estimando el dag completo 

```{r}

library(cmdstanr)
library(rethinking)
set_cmdstan_path("~/Descargas/cmdstan/")

dat <- list(
  N = N,
  x = x,
  y = y,
  z = z
)
set.seed(1908)

flbi <- ulam(
  alist(
    # x model, si quiero estimar la media de x sino, no me hace falta
    x ~ normal(mux, k),
    mux <- a0,
    z ~ normal( mu , sigma ),
    
    mu <- a1 + bx * x,
   
    y ~ normal( nu , tau ),
    nu <- a2 + bx2 * x + bz * z,

    # priors
    
    c(a0,a1,a2,bx,bx2, bz) ~ normal( 0 , 0.5 ),
    c(sigma,tau, k) ~ exponential( 1 )
  ), data=dat , chains=10 , cores=10 , warmup = 500, iter=2000 , cmdstan=TRUE )
```


Y recuperamos los coeficientes y varianzas

```{r}

precis(flbi)
```

```{r}
# extraemos 10000 muestras de la posteriori 
post <- extract.samples(flbi, n = 10000) 
```

Y el efecto directo de x sobre y sería

```{r}
quantile(post$bx2, probs = c(0.025, 0.5, 0.975))
```


En este ejemplo sencillo, podríamos estimar el efecto causal de x sobre y simplemente sumando las posterioris 

```{r}
quantile(post$bx + post$bx2, c(0.025, 0.5, 0.975))
```


También podríamos obtener el efecto causal  total de x sobre y  simulando una intervención. En este caso, al ser la variable continua, lo que queremos obtener como de diferente es y cuando $X = x_i$ versus cuando $X = x_i+1$. 

Siempre podríamos ajustar otro modelo bayesiano dónde no tuviéramos en cuenta a z y obtendríamos la estimación de ese efecto total de x sobre y, pero siguiendo a Rubin y Gelman, la idea es incluir en nuestro modelo toda la información disponible. Y tal y como dice Richard McElreath , [Statistical Rethinking 2022](https://github.com/rmcelreath/stat_rethinking_2022), el efecto causal se puede estimar simulando la intervención. 

Así que el objetivo es dado nuestro modelo que incluye la variable z, simular la intervención cuando $X = x_i$  y  cuando $X = x_i+1$ y una estimación del efecto directo es la resta de ambas distribuciones a posteriori de y. 




Creamos función para calcular el efecto de la intervención `y_do_x`




```{r}
get_total_effect <- function(x_value = 0, incremento = 0.5) {
  n <- length(post$bx)
  with(post, {
    # simulate z, y  for x= x_value
    z_x0 <- rnorm(n, a1 + bx * x_value  , sigma)
    y_x0 <- rnorm(n, a2  + bz * z_x0 + bx * x_value , tau)
    
    # simulate z,y for x= x_value +1 
    z_x1 <- rnorm(n, a1 + bx * (x_value + incremento)  , sigma)
    y_x1 <- rnorm(n, a2  + bz * z_x1 + bx2 * (x_value + incremento) , tau)
    
    
    # compute contrast
    y_do_x <- (y_x1 - y_x0) / incremento
    return(y_do_x)
  })
  
}

```

Dado un valor de x, podemos calcular el efecto total

```{r}
y_do_x_0_2 <- get_total_effect(x_value = 0.2) 

quantile(y_do_x_0_2)

```

Podríamos hacer lo mismo para varios valores de x

```{r}
x_seq <- seq(-0.5, 0.5, length = 1000)
y_do_x <-
  mclapply(x_seq,  function(lambda)
    get_total_effect(x_value = lambda))

```

Y para cada uno de estos 1000 valores tendría 10000 valores de su efecto total de x sobre y. 

```{r}
length(y_do_x[[500]])

head(y_do_x[[500]])
```


Calculamos los intervalos de credibilidad del efecto total de x sobre y para cada valor de x. 

```{r}
# lo hacemos simplemente por cuantiles, aunque podríamos calcular el hdi también, 

intervalos_credibilidad <-  mclapply( y_do_x, function(x) quantile(x, probs = c(0.025, 0.5, 0.975)))

# Media e intervalor de credibilidad para el valor de x_seq en la posición 500 
mean(y_do_x[[500]])
intervalos_credibilidad[[500]]
```

**intervalo de predicción clásico con el lm**

Habría que calcular la predicción de y para un valor de x y para el de x + 1, podemos calcular los intervalos de predicción clásicos parea cada valor de x, pero no para la diferencia ( al menos con la función predict)

```{r}

mt_lm <- lm(y~x)
predict(mt_lm, newdata = list(x= x_seq[[500]]), interval  = "prediction")
predict(mt_lm, newdata = list(x= x_seq[[500]] +1), interval  = "prediction")

```


**Pero como sería obtener el intervalo de credibilidad para la  media de los efectos totales?**

Calculando para cada valor de x la media de la posteriori del efecto global y juntando todas las medias. 

```{r}
slopes_mean <- lapply(y_do_x, mean)

quantile(unlist(slopes_mean), c(0.025, 0.5, 0.975))
```

Que tiene mucha menos variabilidad que el efecto global  en un valor concreto de x, o si juntamos todas las estimaciones

```{r}
quantile(unlist(y_do_x),  c(0.025, 0.5, 0.975))
```

Evidentemente, podríamos simplemente no haber tenido en cuenta la variable z en nuestro modelo bayesiano. 

```{r}
flbi_2 <- ulam(
  alist(
    # x model, si quiero estimar la media de x sino, no me hace falta
    x ~ normal(mux, k),
    mux <- a1,
    
    y ~ normal( nu , tau ),
    nu <- a2 + bx * x ,
    
    # priors
    
    c(a1,a2,bx) ~ normal( 0 , 0.5 ),
    c(tau, k) ~ exponential( 1 )
  ), data=dat , chains=10 , cores=10 , warmup = 500, iter=2000 , cmdstan=TRUE )


```


Y obtenemos directamente el efecto total de x sobre y.

```{r}
precis(flbi_2)
```


```{r}
post2 <- extract.samples(flbi_2,  n = 10000)

quantile(post2$bx, probs = c(0.025, 0.5, 0.975))
```


## Pensamientos finales

* Parece que no es tan mala idea incluir en tu modelo bayesiano toda la información disponible. 
* Ser pluralista es una buena idea, usando el backdoor criterio dado que nuestro dag sea correcto, nos puede llevar a un modelo más simple y fácil de estimar. 
* Como dije en el último [post](https://muestrear-no-es-pecado.netlify.app/2022/02/09/2022-02-09/), estimar todo el dag de forma conjunta puede ser útil en varias situaciones. 

* Ya en 2009 se hablaba de esto [aquí](https://statmodeling.stat.columbia.edu/2009/07/10/rubinism_separa/)




