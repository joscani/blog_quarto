---
title: ¿PCA con ordinales? ¿Y con nominales? Segunda entrega
date: '2020-06-04'
categories:
  - estadística
  - 2020
description: ''
execute: 
  message: false
  warning: false
  echo: true
format: 
  html: 
    fig-height: 5
    fig-dpi: 300
    fig-width: 8.88
    fig-align: center
    code-fold: show
    code-summary: "Mostrar / ocultar código"
knitr:
  opts_chunk:
    out.width: 80%
    fig.showtext: TRUE
    collapse: true
    comment: "#>" 
---


En el post [anterior](https://muestrear-no-es-pecado.netlify.app/2020/06/02/pca-con-ordinales/) se me olvidó comentar que una parte importante es la interpretación. 

```{r}
library(psych)
library(polycor)

datos <- readRDS(here::here("data/science.rds"))
cor_poly <-  hetcor(datos)

res_factorial <-  fa(cor_poly$correlations, nfactors = 3, n.obs = nrow(datos))
diagram(res_factorial)
```

Dónde vemos que MR2 es un factor que tendrá valores altos para todos aqueellos que hayan puntuado alto en las preguntas de su grado de acuerdo con las frases. 

* Technology: _New technology does not depend on basic scientific research._
* Industry: _Scientific and technological research do not play an important role in industrial development._
* Environment: _Scientific and technological research cannot play an important role in protecting the environment and repairing it._

Es decir, los valores altos  en ese factor (MR2) los tendrán aquellos que están de acuerdo con las frases anteriores, básicamente aquellos que piensan que la tecnología no depende de la investigación básica ni que esta juega un rol importante en la industria o en la protección del medio ambiente.

Dicho esto, voy a realizar un análisis parecido, pero utilizando otro tipo de técnica como es la del análisis de correspondencias. Para ver los fundamentos matemáticos del análisis de correspondencias simple aconsejo el libro de Daniel Peña [Análisis Multivariante](https://www.researchgate.net/publication/40944325_Analisis_de_Datos_Multivariantes) o este post de [DisplayR](https://www.displayr.com/math-correspondence-analysis/). 
En R tenemos varios paquetes para hacer análisis de correspondencias simples y múltiples, entre ellos destacan, a mi entender, `ade4`, `FactoMineR`, `homals` o `Gifi` (evolución de `homals`). 

Para estos mismos datos voy a usar el análisis de correspondencias múltiples y la librería `FactoMineR`. 

Nota: En el análisis de correspondencias simple, las matrices que diagonalizan son dos matrices derivadas de la tabla de contingencia entre dos variables categóricas, o más bien, la descomposición del estadístico de la distancia chi-cuadrado entre ambas en cada celda. El análisis de correspondencias múltiples es una generalización del simple para el caso de más variables categóricas. 


Vamos al ejemplo

```{r}
library(FactoMineR)
library(factoextra)

res_mca <- MCA(datos, ncp = 3, graph = FALSE)
summary(res_mca)
  
```
Y en el summary se ve la varianza explicada de cada dimensión y también la coordenada en cada dimensión para cada categoría de cada variable categóricas, así como su contribución a la construcción de la dimensión y su coseno al cuadrado (correlación de esa categoría con la dimensión).

Llama la atención que este análisis sugiere un mayor número de dimensiones que el obtenido utilizando las correlaciones policóricas, esto es así porque en las policóricas se supone que hay una variable latente continua y que la observada es ordinal. En un MCA no hay tal restricción y no se impone un orden a las categorías de cada variable.

En realidad, un correspondencias es equivalente en su objetivo a hacer un embedding utilizando deep learning, de hecho en este artículo [Wor2vec is a special case of kernel correspondence analysis](https://arxiv.org/abs/1605.05087) se habla de la relación entre ambas técnicas. La diferencia, para mi, es que el correspondencias parte de la geometría y del álgebra lineal y los embedding buscan optimizar una función mediante otros métodos, pero en esencia, es lo mismo. 


Veamos los `eigen values` y la varianza explicada por cada dimensión

```{r}
fviz_screeplot(res_mca, addlabels = TRUE)

```


La proyección de las categorías en el plano de la dos primeras dimensions
```{r, fig.width=10}
fviz_mca_var(res_mca)
```

Podemos restringir el gráfico para ver solo las que más contribuyen a la formación de los ejes

```{r}
fviz_mca_var(res_mca, select.var = list(contrib = 15), repel = TRUE, col.var = "cos2")
```

O ver el eje 1 y 3 

```{r}
fviz_mca_var(res_mca, select.var = list(contrib = 15), repel = TRUE, col.var = "cos2", axes = c(1,3))
```

Podemos ver la puntuación (coordenadas) en cada dimensión de las diferentes categorías.

```{r}
res_mca$var$coord
```

Y también las puntuaciones de los individuos. 

```{r}
head(res_mca$ind$coord)
```
A los individuos con mismos valores en las variables categóricas les ha asignado las mismas "puntuaciones" factoriales. Con esos valores ya podríamos hacer por ejemplo un clustering o utilizarlos en otros procedimiento.


Otras funciones útiles de las librerías `FactoMineR` y `factoextra` son `dimdesc` o `fviz_contrib` que nos ayudan a interpretar las dimensiones obtenidas. 

Por ejemplo, vemos qué variables categóricas están bien representadas en la Dimensión 1,  que son *Industry* y *Future*  y también la estimación de la correlación de cada categoria con la dimensión. 


```{r}
descripcion_dimensiones <- dimdesc(res_mca)
descripcion_dimensiones$`Dim 1`
```

También se puede ver qué categorías contribuyen  y en qué grado a la formación de las dimensiones. que es lo que nos ayuda a darle sentido a la dimensión. Así vemos que categorías asociadas a Work, Future o  Benefit son las que más contribuyen. 

```{r}
res_mca$var$contrib
```

Gráficamente.

```{r}
fviz_contrib(res_mca, choice = "var")
```
Claramente la dimensión 1 viene definida por quienes contestan strongly agree en Future, Benefit, work, Industry o comfort.

Para interpretar hay que irse a las coordenadas y ver dónde se sitúan estas categorías. 

Future: Strongly agree tiene un valor alto positivo, al igual que Benefit: Strongly agree o Work: Strongly agree. 

```{r}
res_mca$var$coord
```


Recordemos las frases sobre las que se preguntaba.


* Comfort: _Science and technology are making our lives healthier, easier and more comfortable._

* Environment: _Scientific and technological research cannot play an important role in protecting the environment and repairing it._

* Work: _The application of science and new technology will make work more interesting._

* Future: _Thanks to science and technology, there will be more opportunities for the future generations._

* Technology: _New technology does not depend on basic scientific research._

* Industry: _Scientific and technological research do not play an important role in industrial development._

* Benefit: _The benefits of science are greater than any harmful effect it may_ have.


Luego la dimension 1 nos va a separar a la gente que está muy de acuerdo con las frases de Future, Benefit o Work frente a los que no. 

El resto de dimensiones se interpretaría de la misma forma, viendo qué categorías contribuyen a la formación de la dimensión y qué coordenadas tienen (positivos y negativos) y contra qué categorías se contraponen.


Cabría preguntarse si estas dimensiones tienen alguna relación con las calculadas en el post anterior mediante correlaciones policóricas y análisis factorial.


```{r}
science.num <- data.frame(sapply(datos, as.numeric))
```

## Relación entre FA policóricas y MCA


```{r}
puntuaciones <- factor.scores(science.num, res_factorial)
dimensiones_factorial <- puntuaciones$scores
dimensiones_mca <- res_mca$ind$coord

df_dimensiones <- cbind(dimensiones_factorial, dimensiones_mca)
round(cor(df_dimensiones),2)

```


Y existe cierta relación, pero no tanta como se podría esperar. La dimensión 3 del MCA tiene una correlación de -0.8 con la MR2 del análisis factorial, y la Dimensión 2 ua correlación de -0.7 con la MR1 del factorial. 

Nótese  factorial se permitía que los factores no fueran ortogonales mientras que en MCA si lo son. 

Y bueno, usando las correlaciones policóricas asumimos que existen variables latentes continuas, mientras que con un CA o un MCA se consideran las tablas de contigencia y la distancia chi-cuadrado. El supuesto subyacente es ver cuánto se aleja el valor de cada distancia chi-cuadrado en cada celda respecto del valor esperado bajo la hipótesis de independencia de las variables. 

El próximo día veremos otra forma de hacer el MCA y el PCA con ordinales bajo el prisma de los Gifi Methods. 








