---
title: Cachitos 2023. Tercera parte
date: '2024-01-08'
categories: 
  - estadística
  - polémica
  - 2024
  - textmining
  - ocr
  - linux
  - cachitos
description: ''
execute: 
  message: false
  warning: false
  echo: true
format: 
  html: 
    fig-height: 5
    fig-dpi: 300
    fig-width: 8
    fig-align: center
    code-fold: show
    code-summary: "Show the code"
knitr:
  opts_chunk:
    out.width: 80%
    fig.showtext: TRUE
    collapse: true
    comment: "#>"
image: "topic_modelling_IA.jpeg"
---

Vamos ya con la última entrada del cachitos de este año. Las anteriores,
las tenemos en
[esta](/2024/01/cachitos_2023/cachitos_2023_primera_parte.html) y [esta
otra](/2024/01/cachitos_2023/cachitos_2023_segunda_parte.html)

El csv con el texto de los rótulos para 2023 lo tenemos en este
[enlace](https://drive.google.com/file/d/1pv5GUCp-6IteiplpCL9LWmA20sfd7kHy/view?usp=sharing)

Vamos al lío

::: callout-tip
## Aviso:

Esta entrada ejecuta  casi sin revisar la [entrada de 2023](2023/01/04/cachitos-2022-tercera-parte/)  Lo poco que he cambiado es añadir alguna palabra polémica como
`amnistía` o `puigdemont` al listado de palabras polémicas o hacer 5 topics en lugar de 7 en algún modelo
:::

## Librerías

```{r}

    suppressPackageStartupMessages({
        library(tidyverse) 
        library(tidytext)
        library(quanteda)
        library(magick)
        library(RColorBrewer)
        library(wordcloud)
        library(topicmodels)
        
        }
    )

```

## Lectura de datos, y vistazo datos

```{r}
root_directory = "~/proyecto_cachitos/"
anno <- "2023"
```

Leemos el csv. Uso DT y así podéis ver todos los datos o buscar cosas,
por ejemplo `amnistía` o `crispación`

```{r}
subtitulos_proces <-  read_csv(str_glue("{root_directory}{anno}_txt_unido.csv"))

subtitulos_proces %>% 
  select(texto, n_fichero, n_caracteres) %>% 
  DT::datatable()

```

Pues nos valdría con esto para buscar términos polémicos.

## Algo de minería de texto

Quitamos stopwords y tokenizamos de forma que tengamos cada palabra en
una fila manteniendo de qué rótulo proviene

```{r}

to_remove <- c(tm::stopwords("es"),
               "110", "4","1","2","7","10","0","ñ","of",
               "5","á","i","the","3", "n", "p",
               "ee","uu","mm","ema", "zz",
               "wr","wop","wy","x","xi","xl","xt",
               "xte","yí", "your")



subtitulos_proces_one_word <- subtitulos_proces %>% 
    unnest_tokens(input = texto,
                  output = word) %>% 
    filter(! word %in% to_remove) %>% 
    filter(nchar(word) > 1)

dim(subtitulos_proces_one_word)

```

```{r}
DT::datatable(subtitulos_proces_one_word)
```

Contar ocurrencias de cosas es lo más básico.

```{r}

palabras_ordenadas_1 <- subtitulos_proces_one_word %>% 
    group_by(word) %>% 
    summarise(veces = n()) %>% 
    arrange(desc(veces))

palabras_ordenadas_1 %>% 
    slice(1:20) %>% 
    ggplot(aes(x = reorder(word, veces), y = veces)) +
    geom_col(show.legend = FALSE) +
    ylab("veces") +
    xlab("") +
    coord_flip() +
    theme_bw()

```

Y como el año pasado una de las palabras más comunes es "canción" . ¿Y si añadimos
las 20 palabras como stopword, junto con algunas como \["tan",
"sólo","así", "aquí", "hoy"\] . La tarea de añadir palabras como
stopwords requiere trabajo, tampoco nos vamos a parar tanto.

```{r}
(add_to_stop_words <- palabras_ordenadas_1 %>% 
    slice(1:25) %>% 
    pull(word) )


to_remove <- unique(c(to_remove,
                      add_to_stop_words,
                      "tan", 
                      "sólo", 
                      "así",
                      "aquí", 
                      "hoy",
                      "va"))


subtitulos_proces_one_word <- subtitulos_proces %>% 
    unnest_tokens(input = texto,
                  output = word) %>% 
    filter(! word %in% to_remove) %>% 
    filter(nchar(word) > 1)

```

```{r}

palabras_ordenadas_2 <- subtitulos_proces_one_word %>% 
    group_by(word) %>% 
    summarise(veces = n()) %>% 
    arrange(desc(veces))

palabras_ordenadas_2 %>% 
    slice(1:20) %>% 
    ggplot(aes(x = reorder(word, veces), y = veces)) +
    geom_col(show.legend = FALSE) +
    ylab("veces") +
    xlab("") +
    coord_flip() +
    theme_bw()

```

También podemos ver ahora una nube de palabras

```{r, fig.width=14}

pal <- brewer.pal(8,"Dark2")

subtitulos_proces_one_word %>% 
    group_by(word) %>% 
    count() %>% 
    with(wordcloud(word, n, random.order = FALSE, max.words = 110, colors=pal))    

```

## ¿Polémicos?

Creamos lista de palabras polémicas (se aceptan otras, podéis poner en
los comentarios). 


```{r}

palabras_polem <-
    c(
        "abascal",
        "almeida",
        "amnistía",
        "ayuso",
        "belarra",
        "bloqueo",
        "brusel",
        "catal",
        "ciudada",
        "comunidad",
        "constitucional",
        "coron",
        "crispación",
        "democr",
        "democracia",
        "derech",
        "díaz",
        "dioni",
        "errejon",
        "extremadura",
        "fach",
        "falcon",
        "fasc",
        "feij",
        "feijóo",
        "gobierno",
        "guardia",
        "guerra",
        "iglesias",
        "izquier",
        "ley",
        "madrid",
        "manipulador",
        "militares",
        "minist",
        "monarca",
        "montero",
        "oposición",
        "page",
        "pandem",
        "polarización",
        "polarizados",
        "pp",
        "principe",
        "prisión",
        "psoe",
        "sumar",
        "puigdemont",
        "republic",
        "rey",
        "rufián",
        "sánchez",
        "sanz",
        "tezanos",
        "toled",
        "transición",
        "ultra",
        "vicepre",
        "vox",
        "yolanda",
        "zarzu",
        "zarzuela"
    )

```

Y construimos una regex simple

```{r}
(exp_regx <- paste0("^",paste(palabras_polem, collapse = "|^")))

```

Y nos creamos una variable para identificar si es palabra polémica

```{r}
subtitulos_proces_one_word <- subtitulos_proces_one_word %>% 
    mutate(polemica= str_detect(word, exp_regx))


subtitulos_polemicos <- subtitulos_proces_one_word %>% 
    filter(polemica) %>% 
    pull(n_fichero) %>% 
    unique()

subtitulos_polemicos

```

Y podemos ver en el texto original antes de tokenizar qué rótulos hemos
considerado polémicos y qué texto

```{r}
subtitulos_proces %>% 
    filter(n_fichero %in% subtitulos_polemicos) %>% 
    arrange(n_fichero) %>% 
    pull(texto) %>% 
    unique()
```

Escribimos en un fichero los subtítulos polémicos , por si hago lo que estoy pensando hacer . 

```{r}
subtitulos_proces %>% 
    filter(n_fichero %in% subtitulos_polemicos) %>% 
    arrange(n_fichero) %>% 
    write_csv(file = "~/proyecto_cachitos/2023_solo_polem.csv")

```


Y podemos ver los fotogramas.

```{r}
# identificamos nombre del archivo jpg con los rótulos polémicos
polemica_1_fotogramas <- unique(substr(subtitulos_polemicos, 1,9))

head(polemica_1_fotogramas)

# creamos la ruta completa donde están
polemica_1_fotogramas_full <- paste0(str_glue("{root_directory}video/{anno}_jpg/"), polemica_1_fotogramas, "jpg")


# añadimos sufijo subtitulo.tif para tenr localizado la imagen que tiene solo los rótulos
subtitulos_polemicos_1_full <- paste0(polemica_1_fotogramas_full,".subtitulo.tif")

```

Con la función `image_read` del paquete `magick` leemos las imágenes
polémicas y los rótulos

```{r}
fotogramas_polemicos_img <- map(polemica_1_fotogramas_full, image_read)
subtitulos_polemicos_img <- map(subtitulos_polemicos_1_full, image_read)

```

```{r}

subtitulos_polemicos_img[[24]]

```

```{r}
fotogramas_polemicos_img[[24]]
```

Podemos ver una muestra de algunos de ellos.

No es perfecto, esto requiere más trabajo pero por el momento nos podria valer. Vemos una muestra de los rótulos polémicos

```{r}
set.seed(42)
indices <- sort(sample(1:length(fotogramas_polemicos_img), 9))

lista_fotogram_polemicos <- lapply(fotogramas_polemicos_img[indices], grid::rasterGrob)
gridExtra::grid.arrange(grobs=lista_fotogram_polemicos )
```

Y el recorte de los subtítulos que hicimos enla primera entrega.

```{r}
lista_subtitulos <-  lapply(subtitulos_polemicos_img[indices], grid::rasterGrob)
gridExtra::grid.arrange(grobs=lista_subtitulos)

```

## Tópicos

Aquí no me refiero a los tópicos de este país nuestro, sino a
identificar si hay temas comunes a varios documentos.

Ya aviso que con tan pocos "documentos",  y siendo tan cortos
cada rótulo, es muy probable que no salga mucho..

### Tópicos usando conteo de palabras.

Contamos palabras con 3 caracteres o más.

Guardamos la variable `name` que nos indica en qué rótulo ha aparecido

```{r}

word_counts <- subtitulos_proces_one_word %>% 
    group_by(name, word) %>% 
    count(sort=TRUE) %>% 
    mutate(ncharacters = nchar(word)) %>% 
    filter(
        ncharacters >= 3) %>% 
    select(-ncharacters) %>% 
    ungroup()


length(unique(word_counts$name))

head(word_counts, 15)

```

Ahora convertimos este `data.frame` a un `DocumentTermMatrix`

```{r}
# usamos como peso la TermFrequency de la palabra
rotulos_dtm <- word_counts %>%
    cast_dtm(name, word, n, weighting = tm::weightTf)


rotulos_dtm
```

Podríamos haberlo visto en forma de filas = palabras y columnas = rótulo

```{r}
word_counts  %>%
    cast_dfm(word, name, n)

```

Vamos a ver si sale algo haciendo un LDA (Latent Dirichlet Allocation)

Considero 20 tópicos porque sí.  El que quiera elegir
con algo más de criterio que se mire
[esto](https://cran.r-project.org/web/packages/ldatuning/vignettes/topics.html)

```{r}

# Cons

rotulos_lda <- LDA(rotulos_dtm, k = 20, control = list(seed = 1234))
rotulos_lda

rotulos_lda_td <- tidy(rotulos_lda)
rotulos_lda_td

# se suele ordenar por beta que ahora mismo no recuerdo que era, 

top_terms <- rotulos_lda_td %>%
    group_by(topic) %>%
    top_n(3, beta) %>%
    ungroup() %>%
    arrange(topic, -beta)

top_terms


top_terms %>%
    mutate(term = reorder_within(term, beta, topic)) %>%
    ggplot(aes(term, beta)) +
    geom_bar(stat = "identity") +
    scale_x_reordered() +
    facet_wrap(~ topic, scales = "free_x") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```

Pues la verdad es que yo no veo nada interesante

### Tópicos usando tfidf como peso

Vamos a probar usando [tfidf](https://es.wikipedia.org/wiki/Tf-idf)

Como la función `LDA` no permite usar un `DocumentTermMatrix` que se
haya construido con `cast_dtm` y usando como parámetro de `weighting` el
peso `tm::weightTfIdf` nos construimos los datos de otra forma.

```{r, warning=FALSE, message=FALSE}

tf_idf_data <- subtitulos_proces_one_word %>% 
    filter(nchar(word)>2) %>% 
    group_by(name,word) %>% 
    summarise(veces_palabra = n()) %>% 
    bind_tf_idf(word, name, veces_palabra) %>% 
    ungroup()

tf_idf_data %>% 
    arrange(desc(veces_palabra)) %>%
    head()

```

Para cada palabra tenemos su `tf_idf` dentro de cada rótulo en el que
aparece

```{r}
tf_idf_data %>% 
    filter(word== "amnistía")

```

Como de nuevo LDA solo acepta peso con valores enteros, pues simplemente
multiplicamos por 100 el `tf_idf` y redondeamos

```{r}
dtm_long <- tf_idf_data %>% 
    mutate(tf_idf_integer = round(100*tf_idf)) %>% 
    cast_dfm(name, word, tf_idf_integer)
```

```{r}
lda_model_long_1 <- LDA(dtm_long, k = 20, control = list(seed = 1234))
```

```{r}
result <- tidy(lda_model_long_1, 'beta')

result %>%
    group_by(topic) %>%
    top_n(5, beta) %>%
    ungroup() %>%
    arrange(topic, -beta) %>% 
    mutate(term = reorder(term, beta)) %>%
    ggplot(aes(term, beta, fill = factor(topic))) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~ topic, scales = "free", ncol = 4) +
    coord_flip()
```

Y claramente , yo sigo sin ver nada claro. Aunque me daría pistas para
añadir más palabras a las `stopwords` y para aceptar que para el tamaño
de los documentos (unas pocas palabras por rótulo), quizá no valga el
LDA.

> Esta es la vida del analista de datos, prueba y error y sólo de vez en
> cuándo algún éxito.

### Sólo con los rótulos polémicos

Asumiendo que parece que no tiene sentido hacer `topicmodelling` sobre
estos datos, me picó la curiosidad de ver qué pasaba si sólo usaba los
rótulos polémicos.

```{r, message=FALSE}

tf_idf_data_polem <- subtitulos_proces_one_word %>% 
    filter(nchar(word)>2, polemica == TRUE) %>% 
    group_by(name,word) %>% 
    summarise(veces_palabra = n()) %>% 
    bind_tf_idf(word, name, veces_palabra) %>% 
    ungroup() 


tf_idf_data_polem %>% 
    arrange(desc(veces_palabra)) %>%
    head()
```

#### Topic modelling usando conteo de palabras

```{r}
dtm_long_polem <- tf_idf_data_polem %>% 
    # filter(tf_idf > 0.00006) %>% 
    # filter(veces_palabra>1) %>%
    cast_dtm(name, word, veces_palabra)

lda_model_long_polem <- LDA(dtm_long_polem, k = 5, control = list(seed = 1234))

result_polem <- tidy(lda_model_long_polem, 'beta')

```

```{r, fig.width= 12, fig.height=6}
result_polem %>%
    group_by(topic) %>%
    top_n(5, beta) %>%
    ungroup() %>%
    arrange(topic, -beta) %>% 
    mutate(term = reorder(term, beta)) %>%
    ggplot(aes(term, beta, fill = factor(topic))) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~ topic, scales = "free", ncol = 4) +
    coord_flip()
```

Y bueno parece que en el tópico 1 vemos palabras como amnistía, puigdemont, rey o sánchez. 
O en el 2 iglesias, amnistía, catalana. 

Si vemos en qué tópico cae cada documento.

```{r}
result_documento_polem <-  tidy(lda_model_long_polem, 'gamma')


result_documento_polem %>%
    group_by(topic) %>%
    top_n(7, gamma) %>%
    ungroup() %>%
    arrange(topic, -gamma) %>% 
    mutate(document = reorder(document, gamma)) %>%
    ggplot(aes(document, gamma, fill = factor(topic))) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~ topic, scales = "free", ncol = 4) +
    coord_flip()

```

Veamos algunos subtítulos del tópico 1

```{r}
subtitulos_proces %>% 
    filter(name %in% c(175, 385, 334, 598, 321, 13, 408)) %>% 
    pull(texto)
```

Veamos más documentos relacionados con este tópico

```{r}

top_10_topic3 <-  result_documento_polem %>%
    group_by(topic) %>% 
    top_n(12, gamma) %>% 
    filter(topic==1) %>% 
    pull(document)

subtitulos_proces %>% 
    filter(name %in% top_10_topic3) %>% 
    pull(texto)

```

Y bueno si que parece que ha agrupado algunos rótulos relacionados con
la amnistía

#### Topic modelling usando tf_idf

```{r}
dtm_long_polem_tf_idf <- tf_idf_data_polem %>%
    mutate(tf_idf_integer = round(100 * tf_idf)) %>%
    cast_dfm(name, word, tf_idf_integer)

lda_model_long_polem_tf_idf <- LDA(dtm_long_polem_tf_idf, k = 5, control = list(seed = 1234))

result_polem_tf_idf <- tidy(lda_model_long_polem_tf_idf, 'beta')

```

```{r}
result_polem_tf_idf %>%
    group_by(topic) %>%
    top_n(5, beta) %>%
    ungroup() %>%
    arrange(topic, -beta) %>% 
    mutate(term = reorder(term, beta)) %>%
    ggplot(aes(term, beta, fill = factor(topic))) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~ topic, scales = "free", ncol = 4) +
    coord_flip()
```

Y bueno más o menos igual. 

### Otras pruebas realizadas

-   En vez de considerar que cada rótulo es un documento, consideré los
    rótulos correspondientes a la primera parte del programa, a la
    segunda, y así hasta 10. pero no se obtuvo nada consistente

Y bueno aquí acaba el análisis del cachitos de este año, salvo que
alguien tenga interés en que haga alguna prueba o mejore algo.

### IA's

Probando que me decía ChatGPT 3.5, (no tengo versión de pago). le he
pasado la mitad de los rótulos de este año y le digo que me saque los 7
puntos más importantes y me devuelve esto.

Aquí están los 7 puntos más importantes del texto proporcionado:

1.  **Variedad de Temas y Artistas**: El texto aborda una amplia
    variedad de temas y artistas de la música, tocando géneros y décadas
    diferentes.

2.  **Anécdotas y Curiosidades**: Se presentan anécdotas y curiosidades
    sobre algunos artistas, como detalles sobre sus canciones, momentos
    destacados de sus carreras y datos interesantes.

3.  **Comentarios Irónicos y Humor**: El texto utiliza un tono irónico y
    humorístico para comentar sobre diversos aspectos de la música y los
    artistas, proporcionando un enfoque entretenido.

4.  **Referencias Históricas y Culturales**: Se realizan referencias a
    eventos históricos, políticos y culturales, situando a los artistas
    y sus obras en un contexto más amplio.

5.  **Comentarios Socio-políticos**: Se incluyen comentarios que tocan
    temas sociales y políticos, como la referencia a la amnistía y
    menciones a personajes políticos.

6.  **Observaciones sobre la Industria Musical**: El texto realiza
    observaciones sobre la industria musical, como la evolución de los
    formatos de música, la viralidad en las redes sociales y la temática
    de algunas canciones.

7.  **Diversidad de Géneros Musicales**: Se abordan diversos géneros
    musicales, desde el pop y la música urbana hasta el rock y el
    flamenco, mostrando la diversidad en la escena musical española.

Luego he probado lo mismo usando [Chat
Arena](https://chat.lmsys.org/?arena) que lo acabo de leer en el blog de
[Carlos Gil
Bellosta](https://www.datanalytics.com/2024/01/02/stealthflation/) y le
he podido pasar todos los rótulos y el resultado de ChatGpt 4 y demás,
me ha decepcionado bastante. Os animo a probarlo


Si hago una próxima entrada exploraré a ver si puedo conectarme a algún
modelo de huggin face y ver qué tal lo hace.

### Transformers

Voy a probar a hacer topic modelling usando [`BERTopic`](https://maartengr.github.io/BERTopic/index.html) que utiliza cosas como reducción de dimensionalidad con embeddings, `hdbscan` y los conocidos `transformers` 

Para eso, he instalado lo necesario en un entorno de miniconda. El script en python es este 

```{python}
import os
os.environ["TOKENIZERS_PARALLELISM"] = "false"

from bertopic import BERTopic
from bertopic.vectorizers import ClassTfidfTransformer
import pandas as pd
from matplotlib import pyplot as plt
import plotly.express as px
from sklearn.feature_extraction.text import CountVectorizer
from spacy.lang.es.stop_words import STOP_WORDS
```


```{python}
## rotulos 
rotulos = pd.read_csv("/home/jose/proyecto_cachitos/2023_txt_unido.csv")
polemicos = pd.read_csv("/home/jose/proyecto_cachitos/2023_solo_polem.csv")
```


Stop words en español y ajustar modelo de Bert

```{python}

lista_stop = list(STOP_WORDS) 

vectorizer_model = CountVectorizer(stop_words= lista_stop)

topic_model = BERTopic(verbose=True, 
    vectorizer_model = vectorizer_model, 
    embedding_model='paraphrase-multilingual-MiniLM-L12-v2',
    min_topic_size= 5)

## ajustr modelo con el texto de los rotulos
topicos, _ = topic_model.fit_transform(rotulos.texto)

```

Y no consigo ver este plotly correctamente. Otros plotly desde python si me deja. 

``` {python}

import plotly.express as px
fig = topic_model.visualize_barchart(top_n_topics=20)
##fig.show() # el show no me funciona


```



```{r, echo=FALSE, fig.width=16}
htmltools::includeHTML("topic1.html")
```




Ahora solo con los rótulos polémicos 


```{python}
## solo polémicos


model_polem =  BERTopic(verbose=True, 
    vectorizer_model = vectorizer_model,
    embedding_model='paraphrase-multilingual-MiniLM-L12-v2',
    min_topic_size= 2)

topicos_polem, _ = model_polem.fit_transform(polemicos.texto)


freq = model_polem.get_topic_info()
print("Number of topics: {}".format( len(freq)))
freq.head()
```


```{python, eval = FALSE}

fig_polem = model_polem.visualize_barchart(top_n_topics=20)
# fig_polem.show() no funciona incrusto el html con el plotly
```


```{r, echo=FALSE, fig.width=16}
htmltools::includeHTML("topic2.html")
```


Para ver los rótulos del topic 0 
 
```{python}
df = pd.DataFrame({'topic': topicos_polem, 'document': polemicos.texto})

df.loc[df.topic == 0, 'document']
```


Y vemos que BERtopic es una buena herramienta para este tipo de cosas, y que seguramente en análisis de texto más complejos sea muy útil. 


## Coda

En esta serie de post he dejado reflejado como bajar el video, extraer fotogramas, recortar rótulos, hacer ocrs y un pequeño análisis de los rótulos. Queda para cada cual discernir si los rótulos de este año se meten más con el gobierno, la oposición , los nacionalistas o con otros personajes.  Sea como fuere en la serie de post se dan herramientas para que el que quiera realice su propio análisis y se forme una opinión propia.

Sin más, os deseo un  **Feliz 2024 a todos** y espero el año que viene seguir cumpliendo con la ya casi tradición del análisis de **Nochevieja a Cachitos**
