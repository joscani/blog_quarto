---
title: Vuelta a la facultad. SVD
date: '2023-12-03'
date-modified: last-modified
categories:
  - 2023
  - R
  - Álgebra
execute: 
  message: false
  warning: false
  echo: true
format: 
  html: 
    fig-height: 5
    fig-dpi: 300
    fig-width: 9
    fig-align: center
knitr:
  opts_chunk:
    out.width: 80%
    fig.showtext: TRUE
    collapse: true
    comment: "#>"
---

Unos compis del trabajo están haciendo cosas muy chulas utilizando SVD (Descomposición en valores singulares) y me ha recordado a los tiempos de la universidad.

La SVD es una factorización de una matriz rectangular tal que así.

$$ \mathbf{X} = \mathbf{U} \mathbf{\Sigma} \mathbf{V^T} $$


Veamos un ejemplo, dónde tenemos una matriz de 5x4


```{r}
X <- matrix(c( 10, -1, -2, 2,
               4,  8, -1, 3,
               -2,  5, -3, 4,
               -7, -8,  6, -2,
               -2 , 5, 4, -4
               ),
            byrow = T, nrow = 5, ncol = 4,
            dimnames = list(c("P1", "P2", "P3", "P4","P5"),
                            c("V1", "V2", "V3","V4")))
X
```

Hacemos la svd

```{r}
dvs <- svd(X)
dvs
```


Y vemos que efectivamente 

```{r}
dvs$u %*% diag(dvs$d) %*% t(dvs$v)


```



Ahora, la proyección de las filas en el espacio vectorial definido por la descomposión en valores singulares sería 

$$  Proj = \mathbf{X} \mathbf{V} $$

De forma que si tenemos unos nuevos datos y queremos proyectarlos sobre la estructura definida por la DVS ya calculada  se haría así. 

```{r}
nuevaX <- matrix(c( 20, -2, -3, 2.1,
               5,  2, -1, 3
               ),
            byrow = T, nrow = 2, ncol = 4,
            dimnames = list(c("P6", "P7"),
                            c("V1", "V2", "V3","V4")))

nuevaX

(proyeccion = nuevaX %*% dvs$v)

```

Y para proyectar los valores de X originales, podemos hacer lo mismo o como sabemos que 

$$ \mathbf{X} = \mathbf{U} \mathbf{\Sigma} \mathbf{V^T} $$

entonces 

$$ Proj = \mathbf{X} \mathbf{V} =  \mathbf{U} \mathbf{\Sigma} \mathbf{V^T} \mathbf{V} = \mathbf{U} \mathbf{\Sigma} \mathbf{I} = \mathbf{U} \mathbf{\Sigma} $$ 

Es decir, la proyección de las filas son los vectores singulares izquierdos por la matriz diagonal de los valores singulares. 


__¿Y para qué sirve esto?__  Pues una cosa interesante de la SVD es que nos sirve para reducir la dimensión de los datos, quedándonos con los k primeros valores singulares y los respectivos k primeros vectores singulares. 

Supongamos que queremos quedarnos con k = 3


```{r}
dvs_red <- svd(X, nu = 3, nv = 3)
dvs_red
```

Podemos reconstruir la matriz original  tal que así


```{r}
# matriz original
X

# reconstrucción 

dvs_red$u %*% diag(dvs_red$d[1:3]) %*% t(dvs_red$v)

```


Y así almacenando U, d y V podemos tener una aproximación de X ocupando menos espacio. 

Una utilidad de esto es que si pensamos en las filas como observaciones y las columnnas como variables, la SVD nos sirve para hacer una reducción de la dimensionalidad, de hecho los valores singulares al cuadrado son los autovalores de $\mathbf{X^T} \mathbf{X}$

```{r}
Z = t(X) %*% X

eigen(Z)

dvs_red$d^2
```

Si nos quedamos con los k primeros singulares podríamos querer tener por ejemplo la proyección de las filas en ese subespacio, y usar esas coordenadas para ver distancias entre filas. 
Una propiedad deseable de ese subespacio es que las distancias entre los individuos sean parecidas o al menos ordenen de la misma forma que en el espacio original.  


Por ejemplo las distancias euclídeas entre las filas de X 


```{r}
dist(X)
```

Vemos que P5 está más cerca de P3 que de P2. 


Si usamos sólo la matriz $\mathbf{U_{n \times k}}$ para ver distancias tenemos que no se mantiene esa relación entre las distancias

```{r}
dist(dvs_red$u)
```

En cambio si utilizamos la proyección  tenemos que las distancias son del mismo orden que en los datos originales y que se mantiene la relación entre las diferentes filas. 


```{r}

proyeccion <- (dvs_red$u %*% diag(dvs_red$d[1:3]))

dist(proyeccion)

```

Por eso, si queremos utilizar SVD para hacer una reducción de dimensionalidad y posteriormente utilizar técnicas que utilicen distancias puede tener más sentido utilizar la proyección $\mathbf{U_{n\times k}} \mathbf{\Sigma_{k \times k}}$  que sólo $\mathbf{U_{n\times k}}$

