---
title: Big data para pobres II. ¿AUC?
author: jlcr
date: '2021-05-21'
slug: big-data-pobres-ii-auc
categories:
  - estadística
  - 2021
  - big data
description: ''
execute: 
  message: false
  warning: false
  echo: true
format: 
  html: 
    fig-height: 5
    fig-dpi: 300
    fig-width: 8.88
    fig-align: center
knitr:
  opts_chunk:
    out.width: 80%
    fig.showtext: TRUE
    collapse: true
    comment: "#>"
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE
)
```

 
Bueno, pues voy a ampliar el ejemplo del [último día](https://muestrear-no-es-pecado.netlify.app/2021/05/14/cosas-viejunas-o-big-data-para-pobres/), como es viernes, estoy cansado y me iré a tomar una birra pronto, intentaré ser breve.

Levantamos una sesión de spark y leemos los mismos datos del otro día. Ya de paso voy a probar el operador pipe nativo en R base `|>`. Si tienes la nueva versión de R instalada y la versión de Rstudio preview,  en global options puedes poner para que al hacer Ctrl + Shift +M aparezca el nuevo operador o el antiguo. 


```{r}
library(tidyverse)
library(sparklyr)

sc <- spark_connect(master = "local", spark_home = "~/spark/spark-3.0.0-bin-hadoop2.7")

tmp <- sc |> 
  spark_read_parquet(path = here::here("data/bd_pobres.parquet" ))

```

```{r}
# en el nuevo operador es necesario el paréntesis. 
tmp |> head()
```


Discretizamos la edad. 


```{r}
df_spark <-  tmp |> 
  mutate(
         edad_cat = case_when(
           edad <= 20 ~ "<21",
           edad <= 40 ~ "21- 40",
           edad <= 50 ~ "41-50", 
           edad <= 60 ~ "40-60",
           edad > 60 ~ ">60"
         )
         )

head(df_spark)
```


Y ahora vamos a crear conjunto de train y de test 


```{r}
particiones <-  df_spark |> sdf_random_split(training = 0.6, test = 0.4)

train <- particiones$training
test <- particiones$test 
```



Y ahora procedemos a agregar los datos y traerlos a local. Y seguro que alguno se pregunta ¿por qué no haces el modelo en spark?. Podría hacerlo, ya he contado en este blog como hacer modelos usando sparkling water por ejemplo, pero podría querer ajustar un tipo de modelo que no esté en distribuido, no sé, un modelo mixto con `glmer` o con `stan` . De hecho es eso lo que voy a hacer, un `glmer`. 



```{r}
train_local <- train |>
  group_by(segmento,
           tipo,
           valor_cliente,
           edad_cat) |>
  count()  |>
  collect() |> 
  # ponemos las variables categóricas a tipo factor
  mutate(across(where(is.character), as_factor))

DT::datatable(train_local)
```


Tenemos `r nrow(train_local)` filas con la info de `r round(sum(train_local$n))` observaciones

Agregamos y bajamos el test 

```{r}
test_local <- test |>
  group_by(segmento,
           tipo,
           valor_cliente,
           edad_cat) |>
  count()  |>
  collect() |> 
  # ponemos las variables categóricas a tipo factor
  mutate(across(where(is.character), as_factor))


DT::datatable(test_local)
```


Tenemos `r nrow(test_local)` con la info de `r round(sum(test_local$n))` observaciones


```{r}
# desconectamos spark
spark_disconnect(sc)
```



## glmer 

Hacemos un par de modelos mixtos como en el post anterior, pero en los datos de train


```{r}
library(lme4)

modA <- glmer(segmento == "Best" ~ (1 | edad_cat) + (1 | valor_cliente) + (1 | tipo),
              data = train_local, family= binomial, weights= train_local$n)  

modB <-  glmer(segmento == "No_way" ~(1 | edad_cat) + (1  |valor_cliente) + (1 | tipo),
               data = train_local, family= binomial, weights= train_local$n)  
```


Podemos ver el modelo A por ejemplo

```{r}
summary(modA)
```

```{r}
sjPlot::plot_model(modA, type = "re")
```


### Predicción del glmer 

Ahora hacemos predicción sobre el conjunto de test, que recordemos también está en formato de datos agregados.



```{r}
test_local$Apredict  <- predict(modA, newdata = test_local,
                    allow.new.levels= TRUE,
                    type= "response")

test_local$Bpredict <-  predict(modB, newdata = test_local,
                    allow.new.levels= TRUE,
                    type= "response")

 
```

```{r}
test_local |> 
  select(segmento, n, Apredict, Bpredict) |> 
  DT::datatable()
  
```


### AUC

Si calculamos el AUC con las librerías normales no se va a tener en cuenta que tenemos datos agrupados, sino que considera cada fila como una observación. En este caso los AUC's son como si fuera un modelo aleatorio. 


```{r}
pROC::auc(test_local$segmento=="Best", test_local$Apredict)
pROC::auc(test_local$segmento=="No_way", test_local$Bpredict)
```


Con los datos agregados se tiene por ejemplo que  si en una fila n vale 1000 y la probabilidad de A es 0.2, la estimación de gente en segmento "Best" sería de 200, y podríamos calcular un test de bondad de ajuste de la Chi de Pearson, para comparar la frecuencia observada con la esperada. 

$$\chi^2 = \sum_i\dfrac{(observada_i- estimada_i)^2}{estimada_i}$$ 


```{r}
test_local |> 
  filter(segmento == "Best" & n > 100) |> 
  select(segmento, n, Apredict) |> 
  arrange( - Apredict) |> 
  mutate(A_estimate_num = Apredict * n) |> 
  DT::datatable()
```


Pero seguramente, muchos están más acostumbrados a tener un AUC. Podemos tener en cuenta las frecuencias de cada fila usando la librería `WeightedROC` 


```{r}
library(WeightedROC)
# requiere que la etiqueta esté en 1 y 0 
rocA <- WeightedROC::WeightedROC(test_local$Apredict,
                               ifelse(test_local$segmento== "Best",1,0),
                               weight = test_local$n)

WeightedROC::WeightedAUC(rocA)


```

Y vemos que el AUC teniendo en cuenta los pesos ya no es tan malo (con tan pocas variables tampoco era esperable un auc de 0.83)

Y para el modeloB 


```{r}
rocB <- WeightedROC::WeightedROC(test_local$Bpredict,
                               ifelse(test_local$segmento == "No_way",1,0),
                               weight = test_local$n)

WeightedROC::WeightedAUC(rocB)
```


Y vemos que para el segmento "No_way" nuestro modelo mixto no está mal del todo. 

El próximo día, quiza lo haga con `Stan` usando `brms` que la sintaxis es bastante sencilla. 

