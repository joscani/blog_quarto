{
  "hash": "21c492dc98aeadd0c0552abb1bfcbc5f",
  "result": {
    "markdown": "---\ntitle:  ¬øY si ... ? Parte III \ndate: '2023-09-10'\ndate-modified: last-modified\ncategories:\n    - 2023\n    - estad√≠stica\n    - causal inference\n \nexecute: \n  message: false\n  warning: false\n  echo: true\nformat: \n  html: \n    fig-height: 5\n    fig-dpi: 300\n    fig-width: 8.88\n    fig-align: center\nknitr:\n  opts_chunk:\n    out.width: 80%\n    fig.showtext: TRUE\n    collapse: true\n    comment: \"#>\"\neditor_options:\n  markdown:\n    wrap: none\n---\n\n\n## Introducci√≥n\n\nYa estuve hablando anteriormente de los Metalearners o como se diga [aqu√≠](../2020/11/15/y-si-parte-i/) y [aqu√≠](../2020/12/30/y-si-parte-ii/). Pero ahora vamos a ver si lo utilizamos en unos datos reales.\n\nLa [encuestas de estructura salarial](https://www.ine.es/dyngs/INEbase/es/operacion.htm?c=Estadistica_C&cid=1254736177025&menu=resultados&idp=1254735976596#!tabs-1254736061996) se ha usado muchas veces para ver la brecha salarial entre hombre y mujeres. No obstante yo me hago la pregunta de si es posible y c√≥mo estimar la brecha salarial entre sector p√∫blico y sector privado.\n\n¬øC√≥mo podr√≠amos hacerlo? Est√° claro que son dos sectores muy distintos y que comparar las medias, tal y como hacen (mal) algunos para comparar brecha salarial de g√©nero, no es lo m√°s adecuado.\n\nMi idea aqu√≠ es contar un poco como lo har√≠amos **estilo compadre** usando un modelo lineal de toda la vida, luego ver como se har√≠a utilizando *metalearners* y tambi√©n usando *doubly robust estimator* .\n\n## Datos\n\nVamos a utilizar los microdatos de la [encuestas de estructura salarial](https://www.ine.es/dyngs/INEbase/es/operacion.htm?c=Estadistica_C&cid=1254736177025&menu=resultados&idp=1254735976596#!tabs-1254736061996) del INE. A pesar de ser una encuesta anual, los √∫ltimos resultados publicados son de 2021 y los √∫ltimos microdatos disponibles los de 2018. La verdad es que me gustar√≠a entender por qu√© el INE publica tan tarde los microdatos üò•. La [nota de prensa](https://www.ine.es/prensa/ees_2021.pdf) con los resultados de 2021 es del 20 de junio de 2023. Y si ya tienen resultados de 2021, ¬øpor qu√© los √∫ltimos microdatos disponibles son los de hace 5 a√±os?\n\nSea como fuere vamos a lo nuestro.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(haven) # Para leer los datos de SPSS\n\n\nlibrary(survey) # para obtener estimadores correctos por ser una muestra\nlibrary(sjPlot) # plot de los modelos, \n# library(causact) # usar alguna cosa de numpyro desde R , quiero probar este paquete\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n\ness <- read_spss(here::here(\"data/INE/datos_2018/SPSS/EES_2018.sav\"))\ness <- janitor::clean_names(ess)\n\nhead(ess)\n#> # A tibble: 6 √ó 56\n#>   idenccc  ordentra nuts1   cnace    estrato2 control mercado regulacion sexo   \n#>   <chr>    <chr>    <chr+l> <chr+lb> <chr+lb> <chr+l> <chr+l> <chr+lbl>  <chr+l>\n#> 1 00000025 01       1 [NOR‚Ä¶ H1 [Tra‚Ä¶ 1 [DE 1‚Ä¶ 2 [PRI‚Ä¶ 3 [UNI‚Ä¶ 2 [SECTOR‚Ä¶ 1 [HOM‚Ä¶\n#> 2 00000025 02       1 [NOR‚Ä¶ H1 [Tra‚Ä¶ 1 [DE 1‚Ä¶ 2 [PRI‚Ä¶ 3 [UNI‚Ä¶ 2 [SECTOR‚Ä¶ 1 [HOM‚Ä¶\n#> 3 00000025 03       1 [NOR‚Ä¶ H1 [Tra‚Ä¶ 1 [DE 1‚Ä¶ 2 [PRI‚Ä¶ 3 [UNI‚Ä¶ 2 [SECTOR‚Ä¶ 6 [MUJ‚Ä¶\n#> 4 00000025 04       1 [NOR‚Ä¶ H1 [Tra‚Ä¶ 1 [DE 1‚Ä¶ 2 [PRI‚Ä¶ 3 [UNI‚Ä¶ 2 [SECTOR‚Ä¶ 1 [HOM‚Ä¶\n#> 5 00000025 05       1 [NOR‚Ä¶ H1 [Tra‚Ä¶ 1 [DE 1‚Ä¶ 2 [PRI‚Ä¶ 3 [UNI‚Ä¶ 2 [SECTOR‚Ä¶ 1 [HOM‚Ä¶\n#> 6 00000025 06       1 [NOR‚Ä¶ H1 [Tra‚Ä¶ 1 [DE 1‚Ä¶ 2 [PRI‚Ä¶ 3 [UNI‚Ä¶ 2 [SECTOR‚Ä¶ 1 [HOM‚Ä¶\n#> # ‚Ñπ 47 more variables: tipopais <chr+lbl>, cno1 <chr+lbl>, responsa <chr+lbl>,\n#> #   estu <chr+lbl>, anoanti <dbl>, mesanti <dbl>, tipojor <chr+lbl>,\n#> #   tipocon <chr+lbl>, fijodism <dbl>, fijodisd <dbl>, val <dbl>, van <dbl>,\n#> #   puentes <dbl>, jap <dbl>, jsp1 <dbl>, jsp2 <dbl>, hextra <dbl>,\n#> #   drelabm <dbl>, siespm1 <chr+lbl>, dsiespm1 <dbl>, siespm2 <chr+lbl>,\n#> #   dsiespm2 <dbl>, salbase <dbl>, extraorm <dbl>, phextra <dbl>, comsal <dbl>,\n#> #   comsaltt <dbl>, irpfmes <dbl>, cotiza <dbl>, base <dbl>, drelabam <dbl>, ‚Ä¶\n```\n:::\n\n\nDejo enlace al dise√±o del registro para ver qu√© es cada variable en los microdatos.\n\n[{{< fa table >}} `dis_registro`](https://docs.google.com/spreadsheets/d/1H_wcDX_SfXQmpLyf0Kj9lKvwMhph7Gv7/edit?usp=sharing&ouid=110673697043754248174&rtpof=true&sd=true)\n\nLo que quiero comparar es el salario neto mensual, ¬øpor qu√©? porque me da la gana y porque en la docu del INE explican como se calcula el salario neto partiendo de los microdatos.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\ness <- ess |>\n  mutate(\n    diasmes    = drelabm - dsiespm2,\n    diasrelaba = drelabam * 30.42 + drelabad,\n    diasrelaba = ifelse(diasrelaba > 365, 365, diasrelaba),\n    diasano    = diasrelaba - dsiespa2 - dsiespa4,\n    salbase    = ifelse(siespm1 == \"6\", (31 / diasmes) * salbase, salbase),\n    comsal     = ifelse(siespm1 == \"6\", (31 / diasmes) * comsal, comsal),\n    comsaltt   = ifelse(siespm1 == \"6\", (31 / diasmes) * comsaltt, comsaltt),\n    salmes     = salbase + comsal + extraorm + phextra,\n    salmor     = salbase + comsal + phextra,\n    salneto    = salmes - cotiza - irpfmes,\n    salanual   = (365 / diasano) * (retrinoin + retriin + vespnoin + vespin),\n    salaor     = (365 / diasano) * ((retrinoin + retriin) - gextra),\n    vespnoin   = (365 / diasano) * vespnoin,\n    jmp1       = (jsp1 + jsp2 / 60) * 4.35 + hextra,\n    salhora    = salmes / jmp1\n  )\n```\n:::\n\n\n## Estimando cosas..\n\nLa variable d√≥nde se consigna si el sector es p√∫blico o privado es `control`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\ness |> \n    group_by(control) |>    \n    count()\n#> # A tibble: 2 √ó 2\n#> # Groups:   control [2]\n#>   control          n\n#>   <chr+lbl>    <int>\n#> 1 1 [PUBLICO]  35553\n#> 2 2 [PRIVADO] 181173\n```\n:::\n\n\nVoy a crearme variable `treatment` **que valga 1 cuando sea sector p√∫blico y 0 para el sector privado**\n\n\n::: {.cell}\n\n```{.r .cell-code}\ness$treatment = ess$control\ness$treatment = ifelse(ess$control == \"1\", 1, 0)\n# tambi√©n llamo outcome al salario neto\ness$outcome = ess$salneto\n```\n:::\n\n\n### Group by\n\nLo m√°s simple , hacemos un group by y calculamos medias\n\n\n::: {.cell}\n\n```{.r .cell-code}\ness |> \n    group_by(treatment) |>  \n    summarise(\n        mean = mean(outcome),\n        n = n()\n    )   \n#> # A tibble: 2 √ó 3\n#>   treatment  mean      n\n#>       <dbl> <dbl>  <int>\n#> 1         0 1561. 181173\n#> 2         1 1864.  35553\n```\n:::\n\n\nAs√≠ de primeras, pues parece que se gana m√°s en el sector p√∫blico que en el privado, pero ¬°ojo! que la encuesta tiene una variable de ponderaci√≥n, que el INE ha calculado para que los resultados sean representativos de la poblaci√≥n. En la nota metodol√≥gica el INE dice lo siguiente sobre el plan de muestreo\n\nEl procedimiento de selecci√≥n aleatoria de unidades corresponde a un muestreo biet√°pico estratificado, donde las unidades de primera etapa son las cuentas de cotizaci√≥n a la Seguridad Social (CC), mientras que las de segunda etapa son los trabajadores (asalariados). En la primera etapa tanto el dise√±o muestral como la muestra obtenida de CC coincide con la ETCL (para una mayor informaci√≥n consultar la metodolog√≠a de la ETCL). Las unidades de primera etapa se estratifican seg√∫n las siguientes variables:\n\n-   Comunidad aut√≥noma\n-   Rama de actividad econ√≥mica (divisi√≥n de la CNAE-09)\n-   Tama√±o, medido por el n√∫mero de asalariados en cada CC\n\nEn los microdatos tenemos la variable `factotal` que es la ponderaci√≥n que el INE dice que hay que usar a la hora de hacer estimaciones.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\ness |> \n    group_by(treatment) |>  \n    summarise(\n        media_ponderada = weighted.mean(outcome, w = factotal)\n    )   \n#> # A tibble: 2 √ó 2\n#>   treatment media_ponderada\n#>       <dbl>           <dbl>\n#> 1         0           1351.\n#> 2         1           1799.\n```\n:::\n\n\n### Modelo lineal\n\nPero sabemos que la media tal cual puede no ser un buen indicador, lo suyo ser√≠a *controlar* (condicionar) por otras variables, tales como el sexo, nivel de estudio, edad, a√±os de antig√ºedad , tipo de jornada laboral, y cosas as√≠.\n\nHag√°moslo, pero usando que tenemos pesos en la encuesta.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\ndisenno <- svydesign(id = ~1, weight = ~factotal, data = ess)\n```\n:::\n\n\nModelo simple d√≥nde uso variables como edad, tipo contrato, √°rea nuts, antig√ºedad, nivel de estudios, etc..\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_simple <- svyglm(outcome ~ treatment + sexo + anos2 +   estu + cnace + cno1 + estrato2  + tipojor  + anoanti + mesanti + tipocon  + nuts1, design = disenno)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mod_simple)\n#> \n#> Call:\n#> svyglm(formula = outcome ~ treatment + sexo + anos2 + estu + \n#>     cnace + cno1 + estrato2 + tipojor + anoanti + mesanti + tipocon + \n#>     nuts1, design = disenno)\n#> \n#> Survey design:\n#> svydesign(id = ~1, weight = ~factotal, data = ess)\n#> \n#> Coefficients:\n#>               Estimate Std. Error  t value Pr(>|t|)    \n#> (Intercept)  2267.4873    58.5408   38.733  < 2e-16 ***\n#> treatment     112.7778     8.1697   13.804  < 2e-16 ***\n#> sexo6        -158.0960     5.4276  -29.128  < 2e-16 ***\n#> anos202        21.0286    25.4780    0.825 0.409167    \n#> anos203       101.1315    25.4521    3.973 7.09e-05 ***\n#> anos204       149.8967    25.3798    5.906 3.51e-09 ***\n#> anos205       176.1458    25.6102    6.878 6.09e-12 ***\n#> anos206        52.5466    27.0543    1.942 0.052106 .  \n#> estu2          29.6478    14.4793    2.048 0.040601 *  \n#> estu3          38.1183    14.3801    2.651 0.008031 ** \n#> estu4         142.3435    14.8437    9.590  < 2e-16 ***\n#> estu5         166.5131    15.9282   10.454  < 2e-16 ***\n#> estu6         265.4148    17.3323   15.313  < 2e-16 ***\n#> estu7         510.3787    18.1827   28.070  < 2e-16 ***\n#> cnaceC1      -324.1132    25.8960  -12.516  < 2e-16 ***\n#> cnaceC2      -278.7694    31.4639   -8.860  < 2e-16 ***\n#> cnaceC3      -366.8802    28.5581  -12.847  < 2e-16 ***\n#> cnaceC4      -107.0397    26.9400   -3.973 7.09e-05 ***\n#> cnaceC5      -252.2397    27.0669   -9.319  < 2e-16 ***\n#> cnaceC6      -167.9342    26.4826   -6.341 2.28e-10 ***\n#> cnaceC7      -180.7201    28.5478   -6.330 2.45e-10 ***\n#> cnaceC8      -171.5305    25.6146   -6.697 2.14e-11 ***\n#> cnaceD0       323.7104    36.5705    8.852  < 2e-16 ***\n#> cnaceE0      -282.7253    26.5709  -10.640  < 2e-16 ***\n#> cnaceF0      -222.3453    25.6119   -8.681  < 2e-16 ***\n#> cnaceG1      -266.4662    27.1602   -9.811  < 2e-16 ***\n#> cnaceG2      -409.9509    28.0075  -14.637  < 2e-16 ***\n#> cnaceH1      -231.9251    27.2267   -8.518  < 2e-16 ***\n#> cnaceH2      -288.5758    26.5848  -10.855  < 2e-16 ***\n#> cnaceI0      -314.6540    26.9575  -11.672  < 2e-16 ***\n#> cnaceJ0      -305.2619    27.9572  -10.919  < 2e-16 ***\n#> cnaceK0       -26.9416    29.4084   -0.916 0.359606    \n#> cnaceL0      -426.2992    31.8821  -13.371  < 2e-16 ***\n#> cnaceM0      -382.3510    26.5815  -14.384  < 2e-16 ***\n#> cnaceN0      -426.7819    26.7070  -15.980  < 2e-16 ***\n#> cnaceO0      -489.0672    26.5529  -18.419  < 2e-16 ***\n#> cnaceP0      -677.0378    28.3344  -23.895  < 2e-16 ***\n#> cnaceQ0      -417.2582    26.2085  -15.921  < 2e-16 ***\n#> cnaceR0      -446.4843    27.0788  -16.488  < 2e-16 ***\n#> cnaceS0      -441.9862    25.9167  -17.054  < 2e-16 ***\n#> cno1B0       -564.2450    40.6680  -13.874  < 2e-16 ***\n#> cno1C0       -581.5582    40.3270  -14.421  < 2e-16 ***\n#> cno1D0       -772.4413    38.8858  -19.864  < 2e-16 ***\n#> cno1E0       -964.0718    38.7102  -24.905  < 2e-16 ***\n#> cno1F0       -963.2193    39.0883  -24.642  < 2e-16 ***\n#> cno1G0       -944.6769    40.6941  -23.214  < 2e-16 ***\n#> cno1H0      -1007.1839    39.2405  -25.667  < 2e-16 ***\n#> cno1I0       -805.5218    41.4801  -19.419  < 2e-16 ***\n#> cno1J0       -833.4489    50.5645  -16.483  < 2e-16 ***\n#> cno1K0       -971.3301    39.7779  -24.419  < 2e-16 ***\n#> cno1L0       -948.3725    38.9086  -24.374  < 2e-16 ***\n#> cno1M0       -977.4409    38.9573  -25.090  < 2e-16 ***\n#> cno1N0       -976.4017    40.1926  -24.293  < 2e-16 ***\n#> cno1O0      -1009.1702    40.1926  -25.108  < 2e-16 ***\n#> cno1P0      -1033.0883    39.0592  -26.449  < 2e-16 ***\n#> cno1Q0       -981.9190    65.8301  -14.916  < 2e-16 ***\n#> estrato21      25.7381    28.0871    0.916 0.359476    \n#> estrato22     130.3521    28.3970    4.590 4.43e-06 ***\n#> estrato23     208.3260    28.3907    7.338 2.18e-13 ***\n#> estrato24     130.3223    29.7704    4.378 1.20e-05 ***\n#> tipojor2     -593.8166     5.3784 -110.408  < 2e-16 ***\n#> anoanti        12.3393     0.3434   35.929  < 2e-16 ***\n#> mesanti         2.0881     0.6091    3.428 0.000608 ***\n#> tipocon2     -119.7352     5.0449  -23.734  < 2e-16 ***\n#> nuts12        139.1728     8.4611   16.449  < 2e-16 ***\n#> nuts13         97.8708     9.3378   10.481  < 2e-16 ***\n#> nuts14         -4.8016     7.8750   -0.610 0.542040    \n#> nuts15        104.8487     7.5335   13.918  < 2e-16 ***\n#> nuts16         48.8032     8.2790    5.895 3.76e-09 ***\n#> nuts17         17.5482    10.3777    1.691 0.090848 .  \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for gaussian family taken to be 373331.4)\n#> \n#> Number of Fisher Scoring iterations: 2\n```\n:::\n\n\nY el coeficiente asociaso al sector p√∫blico indica que se gana en media unos 112 euros m√°s que en el sector privado, seg√∫n este modelo.\n\n¬øCu√°nto ser√≠a para alguien que trabaja a jornada completa, nivel de estudios superior o igual a licenciado?\n\nPara eso podemos hacer lo que se conoce como una \"intervenci√≥n\", que es crear dos conjuntos de datos copias del original, con la diferencia de que en uno todo el mundo es del sector privado y en el otro todos del sector p√∫blico y comparamos las medias estimadas de salario neto que nos da el modelo para el subgrupo de poblaci√≥n que queramos.\n\nA esto se le conoce por los modernos como un **S-learner**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\ness_fake_publico  <- ess  \n\ness_fake_publico$treatment  <- 1\n\nestim_publico <- predict(mod_simple, newdata = ess_fake_publico |>  filter(tipojor == \"1\", estu == \"7\", sexo == \"1\"  ) )\n\n\ness_fake_privado <- ess \n\ness_fake_privado$treatment  <- 0\n\nestim_privado <- predict(mod_simple, newdata = ess_fake_privado |>  filter(tipojor == \"1\", estu == \"7\", sexo == \"1\") )\n\n\nmean(estim_publico)\n#> [1] 2516.276\nmean(estim_privado)\n#> [1] 2403.498\n\n(s_learner_with_pond <- mean(estim_publico) - mean(estim_privado))\n#> [1] 112.7778\n```\n:::\n\n\nY coincide con el coeficiente que daba el modelo. Y eso es as√≠ porque no he metido interacciones en el modelo. Si metemos una simple interacci√≥n entre ser del sector p√∫blico y privado con la zona Nuts1.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ness |> \n    group_by(nuts1) |>  \n    count()\n#> # A tibble: 7 √ó 2\n#> # Groups:   nuts1 [7]\n#>   nuts1                       n\n#>   <chr+lbl>               <int>\n#> 1 1 [NOROESTE]            24806\n#> 2 2 [NORESTE]             33624\n#> 3 3 [COMUNIDAD DE MADRID] 34269\n#> 4 4 [CENTRO]              26428\n#> 5 5 [ESTE]                58852\n#> 6 6 [SUR]                 29413\n#> 7 7 [CANARIAS]             9334\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_inter_con_nuts <- svyglm(outcome ~ treatment* nuts1 + sexo + anos2 +   estu + cnace + cno1 + estrato2  + tipojor  + anoanti + mesanti + tipocon , design = disenno)\n\nsummary(mod_inter_con_nuts)\n#> \n#> Call:\n#> svyglm(formula = outcome ~ treatment * nuts1 + sexo + anos2 + \n#>     estu + cnace + cno1 + estrato2 + tipojor + anoanti + mesanti + \n#>     tipocon, design = disenno)\n#> \n#> Survey design:\n#> svydesign(id = ~1, weight = ~factotal, data = ess)\n#> \n#> Coefficients:\n#>                    Estimate Std. Error  t value Pr(>|t|)    \n#> (Intercept)       2267.0375    58.7580   38.583  < 2e-16 ***\n#> treatment          139.5808    16.4879    8.466  < 2e-16 ***\n#> nuts12             136.3734     9.6420   14.144  < 2e-16 ***\n#> nuts13             109.8222    10.5875   10.373  < 2e-16 ***\n#> nuts14             -13.0969     8.7817   -1.491 0.135862    \n#> nuts15             115.8699     8.4975   13.636  < 2e-16 ***\n#> nuts16              50.2008     9.4214    5.328 9.92e-08 ***\n#> nuts17              11.3094    11.6282    0.973 0.330765    \n#> sexo6             -157.8517     5.4260  -29.092  < 2e-16 ***\n#> anos202             22.9645    25.5775    0.898 0.369272    \n#> anos203            103.1094    25.5532    4.035 5.46e-05 ***\n#> anos204            151.6792    25.4825    5.952 2.65e-09 ***\n#> anos205            177.3203    25.7096    6.897 5.32e-12 ***\n#> anos206             53.6148    27.1482    1.975 0.048282 *  \n#> estu2               29.8615    14.4816    2.062 0.039207 *  \n#> estu3               37.3601    14.3817    2.598 0.009384 ** \n#> estu4              142.6627    14.8458    9.610  < 2e-16 ***\n#> estu5              167.2457    15.9296   10.499  < 2e-16 ***\n#> estu6              264.4340    17.3311   15.258  < 2e-16 ***\n#> estu7              510.9210    18.1818   28.101  < 2e-16 ***\n#> cnaceC1           -322.4719    25.8565  -12.472  < 2e-16 ***\n#> cnaceC2           -277.8307    31.4386   -8.837  < 2e-16 ***\n#> cnaceC3           -368.1116    28.5083  -12.912  < 2e-16 ***\n#> cnaceC4           -107.5481    26.8992   -3.998 6.38e-05 ***\n#> cnaceC5           -251.5735    27.0238   -9.309  < 2e-16 ***\n#> cnaceC6           -165.5994    26.4505   -6.261 3.84e-10 ***\n#> cnaceC7           -179.9980    28.5076   -6.314 2.72e-10 ***\n#> cnaceC8           -170.7310    25.5703   -6.677 2.45e-11 ***\n#> cnaceD0            323.6055    36.5367    8.857  < 2e-16 ***\n#> cnaceE0           -281.1503    26.5217  -10.601  < 2e-16 ***\n#> cnaceF0           -221.8244    25.5641   -8.677  < 2e-16 ***\n#> cnaceG1           -266.6874    27.1071   -9.838  < 2e-16 ***\n#> cnaceG2           -410.0799    27.9517  -14.671  < 2e-16 ***\n#> cnaceH1           -228.7886    27.1892   -8.415  < 2e-16 ***\n#> cnaceH2           -287.2581    26.5307  -10.827  < 2e-16 ***\n#> cnaceI0           -314.4745    26.9273  -11.679  < 2e-16 ***\n#> cnaceJ0           -307.8448    27.9093  -11.030  < 2e-16 ***\n#> cnaceK0            -25.9796    29.3654   -0.885 0.376318    \n#> cnaceL0           -428.7358    31.8459  -13.463  < 2e-16 ***\n#> cnaceM0           -382.9944    26.5201  -14.442  < 2e-16 ***\n#> cnaceN0           -427.5663    26.6470  -16.046  < 2e-16 ***\n#> cnaceO0           -491.1736    26.4855  -18.545  < 2e-16 ***\n#> cnaceP0           -679.4070    28.3151  -23.995  < 2e-16 ***\n#> cnaceQ0           -418.4000    26.1469  -16.002  < 2e-16 ***\n#> cnaceR0           -446.9767    27.0305  -16.536  < 2e-16 ***\n#> cnaceS0           -441.7225    25.8682  -17.076  < 2e-16 ***\n#> cno1B0            -563.9700    40.6603  -13.870  < 2e-16 ***\n#> cno1C0            -580.4722    40.3078  -14.401  < 2e-16 ***\n#> cno1D0            -771.5835    38.8634  -19.854  < 2e-16 ***\n#> cno1E0            -963.6523    38.6908  -24.907  < 2e-16 ***\n#> cno1F0            -962.4620    39.0754  -24.631  < 2e-16 ***\n#> cno1G0            -943.1722    40.6791  -23.186  < 2e-16 ***\n#> cno1H0           -1006.9339    39.2172  -25.676  < 2e-16 ***\n#> cno1I0            -799.1017    41.4442  -19.281  < 2e-16 ***\n#> cno1J0            -833.4729    50.5531  -16.487  < 2e-16 ***\n#> cno1K0            -970.9199    39.7730  -24.412  < 2e-16 ***\n#> cno1L0            -946.7735    38.8851  -24.348  < 2e-16 ***\n#> cno1M0            -975.6476    38.9286  -25.062  < 2e-16 ***\n#> cno1N0            -974.9346    40.1732  -24.268  < 2e-16 ***\n#> cno1O0           -1008.8982    40.1716  -25.115  < 2e-16 ***\n#> cno1P0           -1032.8826    39.0379  -26.458  < 2e-16 ***\n#> cno1Q0            -941.5737    66.0825  -14.248  < 2e-16 ***\n#> estrato21           18.7235    28.1838    0.664 0.506476    \n#> estrato22          122.1463    28.5034    4.285 1.83e-05 ***\n#> estrato23          201.3305    28.4886    7.067 1.59e-12 ***\n#> estrato24          126.1192    29.8559    4.224 2.40e-05 ***\n#> tipojor2          -593.1639     5.3768 -110.318  < 2e-16 ***\n#> anoanti             12.3334     0.3434   35.921  < 2e-16 ***\n#> mesanti              2.0871     0.6094    3.425 0.000615 ***\n#> tipocon2          -119.0692     5.0451  -23.601  < 2e-16 ***\n#> treatment:nuts12    15.2013    19.3060    0.787 0.431056    \n#> treatment:nuts13   -71.6951    20.4396   -3.508 0.000452 ***\n#> treatment:nuts14    27.4429    19.1259    1.435 0.151329    \n#> treatment:nuts15   -66.6916    17.9164   -3.722 0.000197 ***\n#> treatment:nuts16    -8.9706    19.3186   -0.464 0.642398    \n#> treatment:nuts17    39.0070    25.1314    1.552 0.120634    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for gaussian family taken to be 373097.8)\n#> \n#> Number of Fisher Scoring iterations: 2\n```\n:::\n\n\nEstimamos diferencias entre sector p√∫blico y privado para Madrid y Andaluc√≠a, para un hombre a jornada completa y con estudios de licenciatura o superior.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\nestim_publico_madrid <- predict(mod_inter_con_nuts, newdata = ess_fake_publico |>  filter(tipojor == \"1\", estu == \"7\", sexo == \"1\" , nuts1 == \"3\" ) )\n\nestim_privado_madrid <- predict(mod_inter_con_nuts, newdata = ess_fake_privado |>  filter(tipojor == \"1\", estu == \"7\", sexo == \"1\", nuts1 == \"3\") )\n\n\nmean(estim_publico_madrid)\n#> [1] 2533.962\nmean(estim_privado_madrid)\n#> [1] 2466.076\n\n(s_learner_with_pond_madrid <- mean(estim_publico_madrid) - mean(estim_privado_madrid))\n#> [1] 67.88572\n\n\n\nestim_publico_sur <- predict(mod_inter_con_nuts, newdata = ess_fake_publico |>  filter(tipojor == \"1\", estu == \"7\", sexo == \"1\" , nuts1 == \"1\" ) )\n\nestim_privado_sur <- predict(mod_inter_con_nuts, newdata = ess_fake_privado |>  filter(tipojor == \"1\", estu == \"7\", sexo == \"1\", nuts1 == \"1\") )\n\n\nmean(estim_publico_sur)\n#> [1] 2449.94\nmean(estim_privado_sur)\n#> [1] 2310.359\n\n(s_learner_with_pond_sur <- mean(estim_publico_sur) - mean(estim_privado_sur))\n#> [1] 139.5808\n```\n:::\n\n\nBueno, pues seg√∫n esto, parece que para ese perfil, d√≥nde se ha tenido en cuenta edad, a√±os de antig√ºedad y dem√°s, se gana un poco m√°s en el sector p√∫blico que en el privado, aunque esa diferencia es mayor en el Sur que en Madrid.\n\n## T- learner\n\nOtro de los metalearners empleados es el T-learner, ya explicado en post anteriores. Aqu√≠ vamos a usarlo sin tener en cuenta la ponderaci√≥n de la encuesta.\n\nEn el T-learner se ajusta un modelo para cuando sea sector p√∫blico y otro para cuando sea sector privado y se ve la diferencia de las medias de sus estimaciones.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\nmodpublico <- lm(outcome ~ sexo  + anos2  +  estu + cno1 + estrato2  + tipojor  + anoanti + mesanti + tipocon  + nuts1, data = ess[ess$treatment==1, ])\nmodprivado <-  lm(outcome ~ sexo +  anos2  +  estu  + cno1 + estrato2  + tipojor  + anoanti + mesanti + tipocon  + nuts1, data = ess[ess$treatment==0, ])\n\ness_sub <- ess  %>% \n  filter(tipojor == \"1\", estu == \"7\", sexo == \"1\") \n\n# t-learner\n(t_learner <- mean(predict(modpublico, ess_sub)) - \n  mean(predict(modprivado, ess_sub)) )\n#> [1] -175.951\n\ness_sub_madrid <- ess  %>% \n  filter(tipojor == \"1\", estu == \"7\", sexo == \"1\", nuts1 == \"3\")\n\n# t-learner\n(t_learner_madrid <- mean(predict(modpublico, ess_sub_madrid)) - \n  mean(predict(modprivado, ess_sub_madrid)) )\n#> [1] -296.4373\n\n\n\ness_sub_sur <- ess  %>% \n  filter(tipojor == \"1\", estu == \"7\", sexo == \"1\", nuts1 == \"1\")\n\n# t-learner\n(t_learner_sur <- mean(predict(modpublico, ess_sub_sur)) - \n  mean(predict(modprivado, ess_sub_sur)) )\n#> [1] -159.0581\n```\n:::\n\n\nEn este caso, nos sale que se ganar√≠a m√°s en el sector p√∫blico que en el privado. ¬øCon qu√© nos quedamos?\n\n## X-learner\n\nYa expliqu√© en su d√≠a en que consiste un [X-learner] (../2020/12/30/y-si-parte-ii/#x-learner)\n\nB√°sicamente, usas el modelo ajustado con treatment = 1 para predecir las observaciones con treatment = 0 y al rev√©s en un intento de estimar el *potential outcome*. Luego haces dos modelos para modelar las diferencias entre el *outcome* y las predicciones anteriores y otro modelo de propensity score que se usar√° para ponderar esas dos predicciones.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\n\nm1 <- lm(outcome ~ sexo   + anos2 +   estu + estrato2  + tipojor  + anoanti + mesanti + tipocon  + nuts1, data = ess[ess$treatment==1, ])\nm2 <- lm(outcome ~ sexo   + anos2 +   estu  + estrato2  + tipojor  + anoanti + mesanti + tipocon  + nuts1, data = ess[ess$treatment==0, ])\n\n\n# Usamos modelo 1 para estimar cuando W=0 y el modelo 2 para estimar cuando W = 1\n\n# Con el viejo R-base ser√≠a \ness$Difer[ess$treatment==0] <- ess$outcome[ess$treatment==0] - predict(m1, ess[ess$treatment==0, ])\nhead(ess[ess$treatment==0, c(\"outcome\", \"Difer\")])\n#> # A tibble: 6 √ó 2\n#>   outcome Difer\n#>     <dbl> <dbl>\n#> 1    302. -267.\n#> 2   1181. -263.\n#> 3   1314. -784.\n#> 4   1210. -285.\n#> 5   1152. -201.\n#> 6   1184. -237.\n\n\ness$Difer[ess$treatment==1] <- ess$outcome[ess$treatment==1] - predict(m2, ess[ess$treatment==1, ])\nhead(ess[ess$treatment==1, c(\"outcome\", \"Difer\")])\n#> # A tibble: 6 √ó 2\n#>   outcome  Difer\n#>     <dbl>  <dbl>\n#> 1   2112.  288. \n#> 2   1989. -405. \n#> 3   2183.  -36.2\n#> 4   1954. -212. \n#> 5   1779. -483. \n#> 6   1738. -447.\n\n# Modelamos las diferencias\n\n\nm3 <- lm(Difer ~ sexo   + anos2 +   estu + estrato2  + tipojor  + anoanti + mesanti + tipocon  + nuts1, data = ess[ess$treatment==1, ])\nm4 <- lm(Difer ~ sexo   + anos2 +   estu + estrato2  + tipojor  + anoanti + mesanti + tipocon  + nuts1, data = ess[ess$treatment==0, ])\n\n# Combinamos\n\nglm1 <- glm(treatment ~ sexo   + anos2 +   estu + estrato2  + tipojor  + anoanti + mesanti + tipocon  + nuts1, data = ess, family= binomial)\ness$pesos <- predict(glm1, ess, type = \"response\")\n\n\n\ness$combinado <- ess$pesos * predict(m4, ess) + (1-ess$pesos) * predict(m3, ess) \n\nhead(ess[, c(\"outcome\", \"treatment\",\"Difer\", \"pesos\", \"combinado\")])\n#> # A tibble: 6 √ó 5\n#>   outcome treatment Difer  pesos combinado\n#>     <dbl>     <dbl> <dbl>  <dbl>     <dbl>\n#> 1    302.         0 -267. 0.111     -254. \n#> 2   1181.         0 -263. 0.0238     125. \n#> 3   1314.         0 -784. 0.0591      93.2\n#> 4   1210.         0 -285. 0.0332      74.0\n#> 5   1152.         0 -201. 0.0107     -19.7\n#> 6   1184.         0 -237. 0.0201     -62.1\n\n(x_learner <- ess  %>% \n  filter(tipojor == \"1\", estu == \"7\", sexo == \"1\") |> \n  group_by(treatment)  %>%\n  summarise(mean = mean(outcome)) |> \n  pivot_wider(names_from = treatment, values_from = mean, names_prefix = \"mean_\") |> \n  mutate(\n    estim_xlearner = mean_1 - mean_0) |> \n  pull(estim_xlearner))\n#> [1] -228.745\n\n\n\n(x_learner_madrid <- ess  %>% \n  filter(tipojor == \"1\", estu == \"7\", sexo == \"1\", nuts1==\"3\") |> \n  group_by(treatment)  %>%\n  summarise(mean = mean(outcome)) |> \n  pivot_wider(names_from = treatment, values_from = mean, names_prefix = \"mean_\") |> \n  mutate(\n    estim_xlearner = mean_1 - mean_0) |> \n  pull(estim_xlearner))\n#> [1] -501.2355\n\n\n(x_learner_sur <- ess  %>% \n  filter(tipojor == \"1\", estu == \"7\", sexo == \"1\", nuts1==\"1\") |> \n  group_by(treatment)  %>%\n  summarise(mean = mean(outcome)) |> \n  pivot_wider(names_from = treatment, values_from = mean, names_prefix = \"mean_\") |> \n  mutate(\n    estim_xlearner = mean_1 - mean_0) |> \n  pull(estim_xlearner))\n#> [1] -55.67715\n```\n:::\n\n\n## Doubly robust estimator\n\nCon idea parecida al X-learner , en el sentido de mezclar las estrategias de usar Inverse probability weighting y el de hacer un modelo de la respuesta condicionando por los counfounders.\n\nDe nuevo, al igual que con el T-Learner o el X-Learner no vamos a tener en cuenta la variable de ponderaci√≥n de casos.\n\nEl estimador ser√≠a algo as√≠ como\n\n$$\\dfrac{1}{n} \\sum_{i=1}^n \\left[ \\dfrac{Y_i \\cdot A_i - \\color{red}{ \\left(A_i -\\pi(X_i)\\right) \\mu(X_i, A_i)})} {\\pi(X_i)}  - \\dfrac{Y_i \\cdot (1-A_i) - \\color{red}{ \\left(A_i -\\pi(X_i)\\right) \\mu(X_i,A_i)})} {1-\\pi(X_i)}  \\right ]$$ {#eq-dre}\n\nD√≥nde $\\mu$ hace referencia al modelo para estimar el *outcome* y $\\pi$ al modelo de propensity score.\n\nEste *Doubly robust estimator* es una combinaci√≥n entre usar inverse probability weighting y el modelo de la media del outcome. Este estimador suele ser consistnete si al menos uno de los dos modelos es correcto. A la expresi√≥n coloreda en rojo se le denomina *augmented IPW estimator*\n\nEn c√≥digo es bastante sencillo.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndr_estimator <- function(data, prop_model, mean_model){\ndata %>% \nmutate(\n  prob = predict(prop_model, newdata = data, type = \"response\"),\n  pred = predict(mean_model, newdata = data, type = \"response\"), \n  augm = (treatment - prob) * pred \n  ) %>%\nsummarise(\n  EYpublico = mean((outcome * treatment -augm) / prob),\n  EYprivado= mean((outcome * (1 - treatment) - augm) / (1 - prob))\n)  %>%\nmutate(dre = EYpublico - EYprivado)\n}\n```\n:::\n\n\nY si usamos ese estimador tenemos\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\nprop_model  <- glm(treatment ~  sexo + anos2+ cnace + cno1 + estrato2 +  estu + tipojor  + anoanti + mesanti + tipocon  + nuts1, data = ess, family = binomial)\nmean_model <- glm(outcome ~ treatment +  sexo + anos2+ cnace + cno1 + estrato2 +  estu + tipojor  + anoanti + mesanti + tipocon  + nuts1 , data = ess, family = gaussian)\n\n\nsummary(prop_model)\n#> \n#> Call:\n#> glm(formula = treatment ~ sexo + anos2 + cnace + cno1 + estrato2 + \n#>     estu + tipojor + anoanti + mesanti + tipocon + nuts1, family = binomial, \n#>     data = ess)\n#> \n#> Coefficients:\n#>               Estimate Std. Error z value Pr(>|z|)    \n#> (Intercept) -8.090e+00  5.934e-01 -13.634  < 2e-16 ***\n#> sexo6        2.674e-01  2.116e-02  12.637  < 2e-16 ***\n#> anos202      8.244e-01  5.243e-01   1.572 0.115866    \n#> anos203      1.488e+00  5.233e-01   2.844 0.004459 ** \n#> anos204      1.817e+00  5.233e-01   3.473 0.000515 ***\n#> anos205      1.981e+00  5.235e-01   3.785 0.000154 ***\n#> anos206      2.064e+00  5.242e-01   3.937 8.24e-05 ***\n#> cnaceC1     -2.069e+00  1.909e-01 -10.835  < 2e-16 ***\n#> cnaceC2     -2.340e+00  2.854e-01  -8.200 2.41e-16 ***\n#> cnaceC3      4.823e-01  1.773e-01   2.720 0.006533 ** \n#> cnaceC4     -1.680e+01  1.053e+02  -0.160 0.873244    \n#> cnaceC5     -1.634e+01  1.897e+02  -0.086 0.931349    \n#> cnaceC6     -2.705e+00  2.597e-01 -10.416  < 2e-16 ***\n#> cnaceC7     -1.649e+01  1.280e+02  -0.129 0.897495    \n#> cnaceC8     -6.740e-01  1.545e-01  -4.363 1.28e-05 ***\n#> cnaceD0     -5.031e+00  7.223e-01  -6.964 3.30e-12 ***\n#> cnaceE0      1.948e+00  1.483e-01  13.139  < 2e-16 ***\n#> cnaceF0      2.271e-01  1.511e-01   1.503 0.132789    \n#> cnaceG1     -1.622e+01  1.124e+02  -0.144 0.885252    \n#> cnaceG2     -1.600e+01  9.413e+01  -0.170 0.865012    \n#> cnaceH1      1.437e+00  1.507e-01   9.534  < 2e-16 ***\n#> cnaceH2      2.936e+00  1.482e-01  19.808  < 2e-16 ***\n#> cnaceI0     -7.434e-01  1.783e-01  -4.170 3.04e-05 ***\n#> cnaceJ0      3.013e-01  1.472e-01   2.047 0.040683 *  \n#> cnaceK0      1.752e-02  1.484e-01   0.118 0.905995    \n#> cnaceL0      6.883e-01  1.787e-01   3.852 0.000117 ***\n#> cnaceM0      1.066e+00  1.455e-01   7.326 2.38e-13 ***\n#> cnaceN0     -7.697e-01  1.550e-01  -4.966 6.85e-07 ***\n#> cnaceO0      2.246e+01  9.488e+01   0.237 0.812845    \n#> cnaceP0      2.748e+00  1.487e-01  18.482  < 2e-16 ***\n#> cnaceQ0      2.013e+00  1.464e-01  13.750  < 2e-16 ***\n#> cnaceR0      1.759e+00  1.487e-01  11.834  < 2e-16 ***\n#> cnaceS0      5.370e-01  1.554e-01   3.455 0.000550 ***\n#> cno1B0       1.487e+00  6.226e-02  23.887  < 2e-16 ***\n#> cno1C0       8.397e-01  5.779e-02  14.529  < 2e-16 ***\n#> cno1D0       4.886e-01  5.826e-02   8.386  < 2e-16 ***\n#> cno1E0       3.641e-01  6.314e-02   5.767 8.08e-09 ***\n#> cno1F0       2.401e-02  6.783e-02   0.354 0.723379    \n#> cno1G0      -2.950e-01  1.191e-01  -2.476 0.013269 *  \n#> cno1H0       4.008e-01  6.743e-02   5.944 2.79e-09 ***\n#> cno1I0       5.683e-01  1.077e-01   5.277 1.31e-07 ***\n#> cno1J0       1.599e+00  1.437e-01  11.121  < 2e-16 ***\n#> cno1K0       4.359e-01  9.292e-02   4.691 2.72e-06 ***\n#> cno1L0       2.333e-01  7.777e-02   2.999 0.002705 ** \n#> cno1M0      -8.548e-01  1.435e-01  -5.956 2.59e-09 ***\n#> cno1N0       2.546e-01  7.800e-02   3.264 0.001098 ** \n#> cno1O0       3.076e-01  7.608e-02   4.043 5.27e-05 ***\n#> cno1P0      -8.458e-01  9.808e-02  -8.624  < 2e-16 ***\n#> cno1Q0       3.002e+00  1.482e+03   0.002 0.998384    \n#> estrato21   -9.996e-01  2.206e-01  -4.531 5.87e-06 ***\n#> estrato22    9.719e-02  2.202e-01   0.441 0.658908    \n#> estrato23    9.132e-01  2.202e-01   4.147 3.37e-05 ***\n#> estrato24    5.801e-01  2.244e-01   2.585 0.009724 ** \n#> estu2        2.584e-01  1.589e-01   1.626 0.103944    \n#> estu3        1.217e+00  1.575e-01   7.727 1.10e-14 ***\n#> estu4        1.253e+00  1.582e-01   7.917 2.43e-15 ***\n#> estu5        1.644e+00  1.600e-01  10.275  < 2e-16 ***\n#> estu6        1.470e+00  1.607e-01   9.145  < 2e-16 ***\n#> estu7        1.858e+00  1.603e-01  11.593  < 2e-16 ***\n#> tipojor2    -1.526e+00  3.257e-02 -46.857  < 2e-16 ***\n#> anoanti      7.184e-02  1.209e-03  59.437  < 2e-16 ***\n#> mesanti      3.078e-02  2.627e-03  11.718  < 2e-16 ***\n#> tipocon2     1.800e+00  2.660e-02  67.697  < 2e-16 ***\n#> nuts12      -7.224e-02  3.819e-02  -1.891 0.058560 .  \n#> nuts13      -5.637e-01  3.770e-02 -14.952  < 2e-16 ***\n#> nuts14       5.716e-01  3.905e-02  14.636  < 2e-16 ***\n#> nuts15      -3.778e-01  3.500e-02 -10.795  < 2e-16 ***\n#> nuts16       3.272e-01  3.778e-02   8.660  < 2e-16 ***\n#> nuts17       1.661e-02  5.427e-02   0.306 0.759563    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for binomial family taken to be 1)\n#> \n#>     Null deviance: 193458  on 216725  degrees of freedom\n#> Residual deviance:  76006  on 216657  degrees of freedom\n#> AIC: 76144\n#> \n#> Number of Fisher Scoring iterations: 18\nsummary(mean_model)\n#> \n#> Call:\n#> glm(formula = outcome ~ treatment + sexo + anos2 + cnace + cno1 + \n#>     estrato2 + estu + tipojor + anoanti + mesanti + tipocon + \n#>     nuts1, family = gaussian, data = ess)\n#> \n#> Coefficients:\n#>               Estimate Std. Error  t value Pr(>|t|)    \n#> (Intercept)  2877.5791    61.1896   47.027  < 2e-16 ***\n#> treatment      17.9283     8.3590    2.145  0.03197 *  \n#> sexo6        -240.4080     4.9123  -48.940  < 2e-16 ***\n#> anos202        22.1784    43.0544    0.515  0.60647    \n#> anos203        89.1187    42.8391    2.080  0.03750 *  \n#> anos204       178.3491    42.8356    4.164 3.13e-05 ***\n#> anos205       240.2115    42.9841    5.588 2.29e-08 ***\n#> anos206        99.7613    43.5939    2.288  0.02211 *  \n#> cnaceC1      -362.2154    26.7350  -13.548  < 2e-16 ***\n#> cnaceC2      -336.6893    29.3593  -11.468  < 2e-16 ***\n#> cnaceC3      -407.7262    33.1492  -12.300  < 2e-16 ***\n#> cnaceC4      -142.3327    26.9322   -5.285 1.26e-07 ***\n#> cnaceC5      -320.6788    30.9230  -10.370  < 2e-16 ***\n#> cnaceC6      -214.7569    28.1272   -7.635 2.26e-14 ***\n#> cnaceC7      -295.1496    27.9070  -10.576  < 2e-16 ***\n#> cnaceC8      -304.6001    26.3723  -11.550  < 2e-16 ***\n#> cnaceD0       315.2232    33.1870    9.498  < 2e-16 ***\n#> cnaceE0      -368.5855    27.9188  -13.202  < 2e-16 ***\n#> cnaceF0      -251.8171    26.4790   -9.510  < 2e-16 ***\n#> cnaceG1      -317.1349    27.2848  -11.623  < 2e-16 ***\n#> cnaceG2      -443.6205    28.1035  -15.785  < 2e-16 ***\n#> cnaceH1       -24.2486    28.2536   -0.858  0.39076    \n#> cnaceH2      -252.9940    28.3037   -8.939  < 2e-16 ***\n#> cnaceI0      -364.2829    27.7660  -13.120  < 2e-16 ***\n#> cnaceJ0      -399.0452    26.5212  -15.046  < 2e-16 ***\n#> cnaceK0      -184.2903    27.1146   -6.797 1.07e-11 ***\n#> cnaceL0      -376.1283    34.1175  -11.025  < 2e-16 ***\n#> cnaceM0      -481.0621    26.1363  -18.406  < 2e-16 ***\n#> cnaceN0      -465.0980    26.1408  -17.792  < 2e-16 ***\n#> cnaceO0      -498.8197    27.9612  -17.840  < 2e-16 ***\n#> cnaceP0      -785.3254    28.6574  -27.404  < 2e-16 ***\n#> cnaceQ0      -448.4801    26.8000  -16.734  < 2e-16 ***\n#> cnaceR0      -286.1541    27.6853  -10.336  < 2e-16 ***\n#> cnaceS0      -523.3793    28.0319  -18.671  < 2e-16 ***\n#> cno1B0      -1061.3503    16.4387  -64.564  < 2e-16 ***\n#> cno1C0      -1133.4003    13.6831  -82.832  < 2e-16 ***\n#> cno1D0      -1275.7747    13.3916  -95.267  < 2e-16 ***\n#> cno1E0      -1533.8695    14.7719 -103.837  < 2e-16 ***\n#> cno1F0      -1503.8142    15.1869  -99.020  < 2e-16 ***\n#> cno1G0      -1478.8524    17.2092  -85.934  < 2e-16 ***\n#> cno1H0      -1541.8639    16.5003  -93.444  < 2e-16 ***\n#> cno1I0      -1498.1010    20.0039  -74.890  < 2e-16 ***\n#> cno1J0      -1517.7995    36.9359  -41.093  < 2e-16 ***\n#> cno1K0      -1527.8727    18.7324  -81.563  < 2e-16 ***\n#> cno1L0      -1494.9651    15.1867  -98.439  < 2e-16 ***\n#> cno1M0      -1549.5391    16.7938  -92.269  < 2e-16 ***\n#> cno1N0      -1589.9336    17.9925  -88.367  < 2e-16 ***\n#> cno1O0      -1570.6894    16.5873  -94.692  < 2e-16 ***\n#> cno1P0      -1595.2569    16.1226  -98.945  < 2e-16 ***\n#> cno1Q0      -1530.0462   138.3092  -11.063  < 2e-16 ***\n#> estrato21     -26.9047    30.6473   -0.878  0.38001    \n#> estrato22      93.7567    30.8162    3.042  0.00235 ** \n#> estrato23     189.6530    30.7961    6.158 7.36e-10 ***\n#> estrato24      99.0138    33.0210    2.999  0.00271 ** \n#> estu2          17.6977    22.9002    0.773  0.43963    \n#> estu3          31.8206    22.8239    1.394  0.16326    \n#> estu4         146.0304    23.0680    6.330 2.45e-10 ***\n#> estu5         188.1811    23.7531    7.922 2.34e-15 ***\n#> estu6         340.0061    24.1380   14.086  < 2e-16 ***\n#> estu7         629.4307    23.9967   26.230  < 2e-16 ***\n#> tipojor2     -632.4750     6.1453 -102.921  < 2e-16 ***\n#> anoanti        13.7806     0.2783   49.511  < 2e-16 ***\n#> mesanti         1.9103     0.5911    3.232  0.00123 ** \n#> tipocon2     -105.5518     5.9315  -17.795  < 2e-16 ***\n#> nuts12        112.1766     8.2021   13.677  < 2e-16 ***\n#> nuts13        159.6686     8.4096   18.986  < 2e-16 ***\n#> nuts14         -0.7868     8.6804   -0.091  0.92778    \n#> nuts15        115.6430     7.5034   15.412  < 2e-16 ***\n#> nuts16         70.6160     8.4813    8.326  < 2e-16 ***\n#> nuts17         13.0092    12.1986    1.066  0.28622    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> (Dispersion parameter for gaussian family taken to be 955907.9)\n#> \n#>     Null deviance: 3.0241e+11  on 216725  degrees of freedom\n#> Residual deviance: 2.0710e+11  on 216656  degrees of freedom\n#> AIC: 3599521\n#> \n#> Number of Fisher Scoring iterations: 2\n(dre_estimator <-  ess  %>%\n  filter(tipojor == \"1\", estu == \"7\", sexo == \"1\") %>%\n  dr_estimator(prop_model, mean_model) |> \n  pull(dre))\n#> [1] 153.843\n\n\n(dre_estimator_madrid <-  ess  %>%\n  filter(tipojor == \"1\", estu == \"7\", sexo == \"1\", nuts1 == \"3\") %>%\n  dr_estimator(prop_model, mean_model) |> \n  pull(dre))\n#> [1] 168.0452\n\n\n\n(dre_estimator_sur <-  ess  %>%\n  filter(tipojor == \"1\", estu == \"7\", sexo == \"1\", nuts1 == \"1\") %>%\n  dr_estimator(prop_model, mean_model) |> \n  pull(dre))\n#> [1] 183.358\n```\n:::\n\n\n## Resumiendo\n\nEl S-learner usando ponderaci√≥n de observaciones y el doubly robust estimator (sin usar ponderaciones) nos dan estimaciones diciendo que se gana m√°s en el sector p√∫blico que en el privado, mientras que el t-learner y el x-learner nos dicen lo contrario.\n\nAs√≠ que, no me queda claro la respueta a la pregunta inicial.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\nres <- data.frame(s_learner_with_pond_madrid = s_learner_with_pond_madrid,\n           s_learner_with_pond_sur = s_learner_with_pond_sur,\n           t_learner_madrid= t_learner_madrid, t_learner_sur = t_learner_sur, \n           x_learner_madrid = x_learner_madrid, x_learner_sur = x_learner_sur, \n           dre_estimator_madrid = dre_estimator_madrid, dre_estimator_sur = dre_estimator_sur )\n\n\nres |> \n    pivot_longer(everything(), names_to = \"estimador\", values_to = \"valor\") \n#> # A tibble: 8 √ó 2\n#>   estimador                   valor\n#>   <chr>                       <dbl>\n#> 1 s_learner_with_pond_madrid   67.9\n#> 2 s_learner_with_pond_sur     140. \n#> 3 t_learner_madrid           -296. \n#> 4 t_learner_sur              -159. \n#> 5 x_learner_madrid           -501. \n#> 6 x_learner_sur               -55.7\n#> 7 dre_estimator_madrid        168. \n#> 8 dre_estimator_sur           183.\n```\n:::\n\n\n## Coda\n\n-   Es complicado dar una respuesta concluyente a la pregunta inicial.\n-   Mi objetivo era s√≥lo contaros algunas formas de estimar \"efectos causales\", o si es gusta m√°s, diferencias entre grupos condicionando por variables\n-   La inferencia causal es complicada, ha de sustentarse en un an√°lisis te√≥rico previo. Yo he decidido que no hab√≠a colliders por ejemplo\n-   He obviado variables que podr√≠an influir tanto en la variable respuesta como en el tratamiento (sector p√∫blico o privado), pero estos son datos reales, no una simulaci√≥n ad hoc, y en el mundo real tienes que tomar decisiones y apechugar con ellas.\n-   Para escribir este post lo he hecho con Rstudio y con el github copilot activado y la verdad es que ayuda bastante, incluso a completar las f√≥rmulas en latex.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}