{
  "hash": "cc6b4fb04b3efda9d5f21839776f075d",
  "result": {
    "markdown": "---\ntitle: Una regresión de poisson, plagiando a Carlos\ndate: '2023-01-21'\ncategories: \n  - estadística\n  - brms\n  - análisis bayesiano\n  - 2023\n\ndescription: ''\nexecute: \n  message: false\n  warning: false\n  echo: true\nformat: \n  html: \n    fig-height: 5\n    fig-dpi: 300\n    fig-width: 8.88\n    fig-align: center\nknitr:\n  opts_chunk:\n    out.width: 80%\n    fig.showtext: TRUE\n    collapse: true\n    comment: \"#>\"\nimage: \"imagen_post.png\"\n---\n\n\n\nMe llamó la atención ayer el excelento post de Carlos sobre [regresión de poisson casi trivival con numpyro](https://www.datanalytics.com/2023/01/18/regresion-poisson-numpyro/) y le dije que iba a ver si podía replicarlo usando `brms` u otra cosa que se comunique con [stan](https://mc-stan.org/). \nTambién estuve bicheando su código que tiene colgado [aquí](https://github.com/cjgb/datanalytics_code/blob/main/exercise_numpyro_00.ipynb)\n\n\nLo primero, es que se trata de un ejercicio relativamente común, que es la de estimar el punto en que una serie de datos cambia de tendencia. Existen cosas como [prophet](https://facebook.github.io/prophet/) (que por debajo es Stan) o librerías como `mcp` `cmp` o `changepoint` en R específicas para este tipo de cosas.  Pero a Carlos le gusta , con buen criterio, especificar directamente el modelo. \n\nHe de reconocer que me ha gustado la sintaxis de `numpyro`.. \n\nBueno vamos al lío. \n\n## Datos y librerías\n\nVoy implementar los dos primeros modelos que hay en el notebook de Carlos usando la función `ulam` de la librería [`rethinking`](https://github.com/rmcelreath/rethinking)  de Richard McElreath. Dicha librería es un interfaz, incompleto aunque didáctico, de hacer modelos bayesianos con Stan.    El último modelo, el que detecta el punto de cambio no he sido capaz de hacerlo con esta librería, pero se podría hacer usando `stan` directamente, como [aquí](https://mc-stan.org/docs/2_21/stan-users-guide/change-point-section.html). \n\n\nLos datos, aunque Carlos ha puesto la variable del tiempo de 1 a 23, yo la voy a poner de 1999 a 2021, porque intuía a qué datos se refería y que los he buscado. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rethinking) \nlibrary(cmdstanr)\nlibrary(brms)\n\n# por si uso splines\nlibrary(mgcv)\n\n\n# uso cmdstan como backend para stan desde R en vez de rstan\nset_cmdstan_path(\"/home/jose/cmdstan\")\nset_ulam_cmdstan(TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n\nd  <- list(\n      y = c(54, 63, 50, 54, 71, 72, 57, 69, 71, \n    76, 57, 73, 62, 51, 54, 55, 60, 49, \n    50, 53, 56, 49, 48),\n\n    t = 1999:2021\n\n)\n```\n:::\n\n\n\n## Modelo lambda constante\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm0 <- ulam(\n    alist(y ~ poisson(lambda),\n          lambda <- a    ,\n          a ~ normal(60, 5)\n          ) ,\n    data = d,\n    chains = 2,\n    cores = 2 ,\n    sample = TRUE,\n    iter = 3000\n    \n)\n#> Running MCMC with 2 parallel chains, with 1 thread(s) per chain...\n#> \n#> Chain 1 Iteration:    1 / 3000 [  0%]  (Warmup) \n#> Chain 1 Iteration:  100 / 3000 [  3%]  (Warmup) \n#> Chain 1 Iteration:  200 / 3000 [  6%]  (Warmup) \n#> Chain 1 Iteration:  300 / 3000 [ 10%]  (Warmup) \n#> Chain 1 Iteration:  400 / 3000 [ 13%]  (Warmup) \n#> Chain 1 Iteration:  500 / 3000 [ 16%]  (Warmup) \n#> Chain 1 Iteration:  600 / 3000 [ 20%]  (Warmup) \n#> Chain 1 Iteration:  700 / 3000 [ 23%]  (Warmup) \n#> Chain 1 Iteration:  800 / 3000 [ 26%]  (Warmup) \n#> Chain 1 Iteration:  900 / 3000 [ 30%]  (Warmup) \n#> Chain 1 Iteration: 1000 / 3000 [ 33%]  (Warmup) \n#> Chain 1 Iteration: 1100 / 3000 [ 36%]  (Warmup) \n#> Chain 1 Iteration: 1200 / 3000 [ 40%]  (Warmup) \n#> Chain 1 Iteration: 1300 / 3000 [ 43%]  (Warmup) \n#> Chain 1 Iteration: 1400 / 3000 [ 46%]  (Warmup) \n#> Chain 1 Iteration: 1500 / 3000 [ 50%]  (Warmup) \n#> Chain 1 Iteration: 1501 / 3000 [ 50%]  (Sampling) \n#> Chain 1 Iteration: 1600 / 3000 [ 53%]  (Sampling) \n#> Chain 1 Iteration: 1700 / 3000 [ 56%]  (Sampling) \n#> Chain 1 Iteration: 1800 / 3000 [ 60%]  (Sampling) \n#> Chain 1 Iteration: 1900 / 3000 [ 63%]  (Sampling) \n#> Chain 1 Iteration: 2000 / 3000 [ 66%]  (Sampling) \n#> Chain 1 Iteration: 2100 / 3000 [ 70%]  (Sampling) \n#> Chain 1 Iteration: 2200 / 3000 [ 73%]  (Sampling) \n#> Chain 1 Iteration: 2300 / 3000 [ 76%]  (Sampling) \n#> Chain 1 Iteration: 2400 / 3000 [ 80%]  (Sampling) \n#> Chain 1 Iteration: 2500 / 3000 [ 83%]  (Sampling) \n#> Chain 1 Iteration: 2600 / 3000 [ 86%]  (Sampling) \n#> Chain 1 Iteration: 2700 / 3000 [ 90%]  (Sampling) \n#> Chain 1 Iteration: 2800 / 3000 [ 93%]  (Sampling) \n#> Chain 1 Iteration: 2900 / 3000 [ 96%]  (Sampling) \n#> Chain 1 Iteration: 3000 / 3000 [100%]  (Sampling) \n#> Chain 2 Iteration:    1 / 3000 [  0%]  (Warmup) \n#> Chain 2 Iteration:  100 / 3000 [  3%]  (Warmup) \n#> Chain 2 Iteration:  200 / 3000 [  6%]  (Warmup) \n#> Chain 2 Iteration:  300 / 3000 [ 10%]  (Warmup) \n#> Chain 2 Iteration:  400 / 3000 [ 13%]  (Warmup) \n#> Chain 2 Iteration:  500 / 3000 [ 16%]  (Warmup) \n#> Chain 2 Iteration:  600 / 3000 [ 20%]  (Warmup) \n#> Chain 2 Iteration:  700 / 3000 [ 23%]  (Warmup) \n#> Chain 2 Iteration:  800 / 3000 [ 26%]  (Warmup) \n#> Chain 2 Iteration:  900 / 3000 [ 30%]  (Warmup) \n#> Chain 2 Iteration: 1000 / 3000 [ 33%]  (Warmup) \n#> Chain 2 Iteration: 1100 / 3000 [ 36%]  (Warmup) \n#> Chain 2 Iteration: 1200 / 3000 [ 40%]  (Warmup) \n#> Chain 2 Iteration: 1300 / 3000 [ 43%]  (Warmup) \n#> Chain 2 Iteration: 1400 / 3000 [ 46%]  (Warmup) \n#> Chain 2 Iteration: 1500 / 3000 [ 50%]  (Warmup) \n#> Chain 2 Iteration: 1501 / 3000 [ 50%]  (Sampling) \n#> Chain 2 Iteration: 1600 / 3000 [ 53%]  (Sampling) \n#> Chain 2 Iteration: 1700 / 3000 [ 56%]  (Sampling) \n#> Chain 2 Iteration: 1800 / 3000 [ 60%]  (Sampling) \n#> Chain 2 Iteration: 1900 / 3000 [ 63%]  (Sampling) \n#> Chain 2 Iteration: 2000 / 3000 [ 66%]  (Sampling) \n#> Chain 2 Iteration: 2100 / 3000 [ 70%]  (Sampling) \n#> Chain 2 Iteration: 2200 / 3000 [ 73%]  (Sampling) \n#> Chain 2 Iteration: 2300 / 3000 [ 76%]  (Sampling) \n#> Chain 2 Iteration: 2400 / 3000 [ 80%]  (Sampling) \n#> Chain 2 Iteration: 2500 / 3000 [ 83%]  (Sampling) \n#> Chain 2 Iteration: 2600 / 3000 [ 86%]  (Sampling) \n#> Chain 2 Iteration: 2700 / 3000 [ 90%]  (Sampling) \n#> Chain 2 Iteration: 2800 / 3000 [ 93%]  (Sampling) \n#> Chain 2 Iteration: 2900 / 3000 [ 96%]  (Sampling) \n#> Chain 2 Iteration: 3000 / 3000 [100%]  (Sampling) \n#> Chain 1 finished in 0.0 seconds.\n#> Chain 2 finished in 0.0 seconds.\n#> \n#> Both chains finished successfully.\n#> Mean chain execution time: 0.0 seconds.\n#> Total execution time: 0.3 seconds.\n\n\nprecis(m0)\n#>           result\n#> mean   59.003667\n#> sd      1.537978\n#> 5.5%   56.620707\n#> 94.5%  61.441365\n#> n_eff 948.410877\n#> Rhat    1.001973\n```\n:::\n\n\n## Modelo dónde lambda es una recta\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- ulam(\n    alist(\n        y ~ poisson(lambda),\n        lambda <- a + b * t   ,\n        a ~ normal(60, 5),\n        b ~ normal(0, 1)\n        \n    ) ,\n    data = d,\n    chains = 2,\n    cores = 2 ,\n    sample = TRUE,\n    iter = 3000\n    \n)\n#> Running MCMC with 2 parallel chains, with 1 thread(s) per chain...\n#> \n#> Chain 1 Iteration:    1 / 3000 [  0%]  (Warmup) \n#> Chain 1 Iteration:  100 / 3000 [  3%]  (Warmup) \n#> Chain 1 Iteration:  200 / 3000 [  6%]  (Warmup) \n#> Chain 1 Iteration:  300 / 3000 [ 10%]  (Warmup) \n#> Chain 1 Iteration:  400 / 3000 [ 13%]  (Warmup) \n#> Chain 1 Iteration:  500 / 3000 [ 16%]  (Warmup) \n#> Chain 1 Iteration:  600 / 3000 [ 20%]  (Warmup) \n#> Chain 1 Iteration:  700 / 3000 [ 23%]  (Warmup) \n#> Chain 1 Iteration:  800 / 3000 [ 26%]  (Warmup) \n#> Chain 1 Iteration:  900 / 3000 [ 30%]  (Warmup) \n#> Chain 1 Iteration: 1000 / 3000 [ 33%]  (Warmup) \n#> Chain 1 Iteration: 1100 / 3000 [ 36%]  (Warmup) \n#> Chain 1 Iteration: 1200 / 3000 [ 40%]  (Warmup) \n#> Chain 1 Iteration: 1300 / 3000 [ 43%]  (Warmup) \n#> Chain 1 Iteration: 1400 / 3000 [ 46%]  (Warmup) \n#> Chain 1 Iteration: 1500 / 3000 [ 50%]  (Warmup) \n#> Chain 1 Iteration: 1501 / 3000 [ 50%]  (Sampling) \n#> Chain 1 Iteration: 1600 / 3000 [ 53%]  (Sampling) \n#> Chain 1 Iteration: 1700 / 3000 [ 56%]  (Sampling) \n#> Chain 1 Iteration: 1800 / 3000 [ 60%]  (Sampling) \n#> Chain 1 Iteration: 1900 / 3000 [ 63%]  (Sampling) \n#> Chain 1 Iteration: 2000 / 3000 [ 66%]  (Sampling) \n#> Chain 1 Iteration: 2100 / 3000 [ 70%]  (Sampling) \n#> Chain 1 Iteration: 2200 / 3000 [ 73%]  (Sampling) \n#> Chain 2 Iteration:    1 / 3000 [  0%]  (Warmup) \n#> Chain 2 Iteration:  100 / 3000 [  3%]  (Warmup) \n#> Chain 2 Iteration:  200 / 3000 [  6%]  (Warmup) \n#> Chain 2 Iteration:  300 / 3000 [ 10%]  (Warmup) \n#> Chain 2 Iteration:  400 / 3000 [ 13%]  (Warmup) \n#> Chain 2 Iteration:  500 / 3000 [ 16%]  (Warmup) \n#> Chain 2 Iteration:  600 / 3000 [ 20%]  (Warmup) \n#> Chain 2 Iteration:  700 / 3000 [ 23%]  (Warmup) \n#> Chain 2 Iteration:  800 / 3000 [ 26%]  (Warmup) \n#> Chain 2 Iteration:  900 / 3000 [ 30%]  (Warmup) \n#> Chain 2 Iteration: 1000 / 3000 [ 33%]  (Warmup) \n#> Chain 2 Iteration: 1100 / 3000 [ 36%]  (Warmup) \n#> Chain 2 Iteration: 1200 / 3000 [ 40%]  (Warmup) \n#> Chain 2 Iteration: 1300 / 3000 [ 43%]  (Warmup) \n#> Chain 2 Iteration: 1400 / 3000 [ 46%]  (Warmup) \n#> Chain 2 Iteration: 1500 / 3000 [ 50%]  (Warmup) \n#> Chain 2 Iteration: 1501 / 3000 [ 50%]  (Sampling) \n#> Chain 2 Iteration: 1600 / 3000 [ 53%]  (Sampling) \n#> Chain 2 Iteration: 1700 / 3000 [ 56%]  (Sampling) \n#> Chain 2 Iteration: 1800 / 3000 [ 60%]  (Sampling) \n#> Chain 2 Iteration: 1900 / 3000 [ 63%]  (Sampling) \n#> Chain 2 Iteration: 2000 / 3000 [ 66%]  (Sampling) \n#> Chain 2 Iteration: 2100 / 3000 [ 70%]  (Sampling) \n#> Chain 2 Iteration: 2200 / 3000 [ 73%]  (Sampling) \n#> Chain 2 Iteration: 2300 / 3000 [ 76%]  (Sampling) \n#> Chain 2 Iteration: 2400 / 3000 [ 80%]  (Sampling) \n#> Chain 2 Iteration: 2500 / 3000 [ 83%]  (Sampling) \n#> Chain 1 Iteration: 2300 / 3000 [ 76%]  (Sampling) \n#> Chain 1 Iteration: 2400 / 3000 [ 80%]  (Sampling) \n#> Chain 1 Iteration: 2500 / 3000 [ 83%]  (Sampling) \n#> Chain 1 Iteration: 2600 / 3000 [ 86%]  (Sampling) \n#> Chain 1 Iteration: 2700 / 3000 [ 90%]  (Sampling) \n#> Chain 1 Iteration: 2800 / 3000 [ 93%]  (Sampling) \n#> Chain 1 Iteration: 2900 / 3000 [ 96%]  (Sampling) \n#> Chain 1 Iteration: 3000 / 3000 [100%]  (Sampling) \n#> Chain 1 finished in 0.1 seconds.\n#> Chain 2 Iteration: 2600 / 3000 [ 86%]  (Sampling) \n#> Chain 2 Iteration: 2700 / 3000 [ 90%]  (Sampling) \n#> Chain 2 Iteration: 2800 / 3000 [ 93%]  (Sampling) \n#> Chain 2 Iteration: 2900 / 3000 [ 96%]  (Sampling) \n#> Chain 2 Iteration: 3000 / 3000 [100%]  (Sampling) \n#> Chain 2 finished in 0.1 seconds.\n#> \n#> Both chains finished successfully.\n#> Mean chain execution time: 0.1 seconds.\n#> Total execution time: 0.3 seconds.\n\nprecis(m1)\n#>            mean          sd         5.5%        94.5%    n_eff    Rhat4\n#> a 59.9776468000 5.180913793 51.792666000 68.200073000 311.2988 1.017155\n#> b -0.0005508964 0.002685868 -0.004713958  0.003665963 311.4865 1.014834\n```\n:::\n\n\n## Modelo para detectar el punto de cambio. \n\nLa verdad que me habría gustado seguir usando `ulam` para el modelo pero he sido incapaz de replicar este cacho de código de `numpyro`\n\n```python\ndef model02(t, datos):\n\n  knot = numpyro.sample(\"knot\", dist.Normal(len(t)/2, len(t)/4))\n\n  a0 = numpyro.sample(\"a0\", dist.Normal(60, 5))\n  b0 = numpyro.sample(\"b0\", dist.Normal( 0, 1))\n\n  b1 = numpyro.sample(\"b1\", dist.Normal(0, 1))  \n\n  λ = a0 + t * b0 + jnp.where(t > knot, (t - knot) * b1, 0)\n\n  with numpyro.plate(\"data\", len(t)):\n    numpyro.sample(\"obs\", dist.Poisson(λ), obs=datos)\n\n\n```\n\nEl problema reside en  `jnp.where(t > knot, (t - knot) * b1, 0)` para resolverlo habría que programar directamente en `stan` o que `ulam` pudiera usar la función [`step`](https://mc-stan.org/docs/2_26/functions-reference/logical-functions.html)  de Stan, que  si x es menor que 0 vale 0 y 1  en otro caso. El código en `ulam` si funcionara sería así\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm2 <- ulam(\n        alist(\n            y ~ poisson(lambda),\n            lambda <- b0 +  b1 * t + b2 * (t - knot) * step(t - knot) ,\n            knot ~ normal(23/2, 23/4),\n            b0 ~ normal(60, 5),\n            b1 ~ normal(0, 1),\n            b2 ~ normal(0, 1),\n\n        ) ,\n        data=d, chains=2, cores=1 , sample=TRUE, \n        iter = 3000)\n\n```\n:::\n\n\npero no funciona , así que vamos a ver como sería usando `brms` . `brms` tiene una sintaxis digamos que peculiar, y su objetivo es parecerse a la especificación que se hace en R de los modelos lineales con `lm` y la que se hace con `lme4`. Es decir sería algo similar a esto\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\n brm( y ~ x1 + x2 + (1 | var_efecto_aleatorio) , \n                 family = poisson(\"identity\"), \n                 data = df)\n\n```\n:::\n\n\ndónde no se especifican los $\\beta_i$  de forma explícita. Pero también tiene sintaxis para hacerlo explícito. Veamos. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Datos en dataframe\ndf  <- data.frame(y = d$y, t = d$t)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbform <- bf(\n  y ~ b0 + b1 * t + \n  \n  # brms si acepta la función step de Stan \n  # cuando t-change >= 0  entonces step(t-change) = 1, es decir, cuanto t > change y 0 en otro caso     \n  b2 * (t-change) * step( t - change),\n  \n  # Hay que poner que estime el \"intercept\" de los parámetros y el nl = TRUE para que brms sepa que son parámetros\n  # y no variables en los datos \n  b0 ~ 1,\n  b1 ~ 1, \n  b2 ~ 1,\n  change ~ 1, \n  nl = TRUE\n)\n```\n:::\n\n\nEspecificamos las priors. En brms se escriben las priors y se \"concatenan\" mediante +\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbprior <- prior(normal(60, 5), nlpar = \"b0\") +\n          prior(normal(0, 1), nlpar = \"b1\") +\n          prior(normal(0, 1), nlpar = \"b2\") +\n         # para el cambio ponemos como media la mitad del intervalo y unos 5 años de desviación típica\n          prior(normal( 2010, 23/4), nlpar = \"change\")\n```\n:::\n\n\n\nY ya podemos escribir el modelo en brms que lo compilara a stan y hace el mcmc\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmbrm <-\n    brm(\n        bform,\n        family = poisson(\"identity\"), # pongo de link la identidad en vez del log por hacer como en el post original\n        prior = bprior,\n        data = df,\n        backend = \"cmdstanr\",\n        cores = 6,\n        chains = 6,\n        iter = 4000,\n        warmup = 500\n    )\n#> Running MCMC with 6 parallel chains...\n#> \n#> Chain 1 Iteration:    1 / 4000 [  0%]  (Warmup) \n#> Chain 1 Iteration:  100 / 4000 [  2%]  (Warmup) \n#> Chain 2 Iteration:    1 / 4000 [  0%]  (Warmup) \n#> Chain 2 Iteration:  100 / 4000 [  2%]  (Warmup) \n#> Chain 3 Iteration:    1 / 4000 [  0%]  (Warmup) \n#> Chain 3 Iteration:  100 / 4000 [  2%]  (Warmup) \n#> Chain 3 Iteration:  200 / 4000 [  5%]  (Warmup) \n#> Chain 4 Iteration:    1 / 4000 [  0%]  (Warmup) \n#> Chain 4 Iteration:  100 / 4000 [  2%]  (Warmup) \n#> Chain 5 Iteration:    1 / 4000 [  0%]  (Warmup) \n#> Chain 5 Iteration:  100 / 4000 [  2%]  (Warmup) \n#> Chain 5 Iteration:  200 / 4000 [  5%]  (Warmup) \n#> Chain 6 Iteration:    1 / 4000 [  0%]  (Warmup) \n#> Chain 6 Iteration:  100 / 4000 [  2%]  (Warmup) \n#> Chain 6 Iteration:  200 / 4000 [  5%]  (Warmup) \n#> Chain 1 Iteration:  200 / 4000 [  5%]  (Warmup) \n#> Chain 2 Iteration:  200 / 4000 [  5%]  (Warmup) \n#> Chain 1 Iteration:  300 / 4000 [  7%]  (Warmup) \n#> Chain 3 Iteration:  300 / 4000 [  7%]  (Warmup) \n#> Chain 4 Iteration:  200 / 4000 [  5%]  (Warmup) \n#> Chain 5 Iteration:  300 / 4000 [  7%]  (Warmup) \n#> Chain 6 Iteration:  300 / 4000 [  7%]  (Warmup) \n#> Chain 2 Iteration:  300 / 4000 [  7%]  (Warmup) \n#> Chain 1 Iteration:  400 / 4000 [ 10%]  (Warmup) \n#> Chain 3 Iteration:  400 / 4000 [ 10%]  (Warmup) \n#> Chain 4 Iteration:  300 / 4000 [  7%]  (Warmup) \n#> Chain 1 Iteration:  500 / 4000 [ 12%]  (Warmup) \n#> Chain 1 Iteration:  501 / 4000 [ 12%]  (Sampling) \n#> Chain 1 Iteration:  600 / 4000 [ 15%]  (Sampling) \n#> Chain 1 Iteration:  700 / 4000 [ 17%]  (Sampling) \n#> Chain 1 Iteration:  800 / 4000 [ 20%]  (Sampling) \n#> Chain 1 Iteration:  900 / 4000 [ 22%]  (Sampling) \n#> Chain 1 Iteration: 1000 / 4000 [ 25%]  (Sampling) \n#> Chain 2 Iteration:  400 / 4000 [ 10%]  (Warmup) \n#> Chain 3 Iteration:  500 / 4000 [ 12%]  (Warmup) \n#> Chain 3 Iteration:  501 / 4000 [ 12%]  (Sampling) \n#> Chain 1 Iteration: 1100 / 4000 [ 27%]  (Sampling) \n#> Chain 1 Iteration: 1200 / 4000 [ 30%]  (Sampling) \n#> Chain 1 Iteration: 1300 / 4000 [ 32%]  (Sampling) \n#> Chain 1 Iteration: 1400 / 4000 [ 35%]  (Sampling) \n#> Chain 1 Iteration: 1500 / 4000 [ 37%]  (Sampling) \n#> Chain 1 Iteration: 1600 / 4000 [ 40%]  (Sampling) \n#> Chain 3 Iteration:  600 / 4000 [ 15%]  (Sampling) \n#> Chain 3 Iteration:  700 / 4000 [ 17%]  (Sampling) \n#> Chain 3 Iteration:  800 / 4000 [ 20%]  (Sampling) \n#> Chain 3 Iteration:  900 / 4000 [ 22%]  (Sampling) \n#> Chain 3 Iteration: 1000 / 4000 [ 25%]  (Sampling) \n#> Chain 3 Iteration: 1100 / 4000 [ 27%]  (Sampling) \n#> Chain 5 Iteration:  400 / 4000 [ 10%]  (Warmup) \n#> Chain 6 Iteration:  400 / 4000 [ 10%]  (Warmup) \n#> Chain 1 Iteration: 1700 / 4000 [ 42%]  (Sampling) \n#> Chain 1 Iteration: 1800 / 4000 [ 45%]  (Sampling) \n#> Chain 1 Iteration: 1900 / 4000 [ 47%]  (Sampling) \n#> Chain 1 Iteration: 2000 / 4000 [ 50%]  (Sampling) \n#> Chain 1 Iteration: 2100 / 4000 [ 52%]  (Sampling) \n#> Chain 1 Iteration: 2200 / 4000 [ 55%]  (Sampling) \n#> Chain 1 Iteration: 2300 / 4000 [ 57%]  (Sampling) \n#> Chain 2 Iteration:  500 / 4000 [ 12%]  (Warmup) \n#> Chain 2 Iteration:  501 / 4000 [ 12%]  (Sampling) \n#> Chain 2 Iteration:  600 / 4000 [ 15%]  (Sampling) \n#> Chain 2 Iteration:  700 / 4000 [ 17%]  (Sampling) \n#> Chain 2 Iteration:  800 / 4000 [ 20%]  (Sampling) \n#> Chain 3 Iteration: 1200 / 4000 [ 30%]  (Sampling) \n#> Chain 3 Iteration: 1300 / 4000 [ 32%]  (Sampling) \n#> Chain 3 Iteration: 1400 / 4000 [ 35%]  (Sampling) \n#> Chain 3 Iteration: 1500 / 4000 [ 37%]  (Sampling) \n#> Chain 3 Iteration: 1600 / 4000 [ 40%]  (Sampling) \n#> Chain 3 Iteration: 1700 / 4000 [ 42%]  (Sampling) \n#> Chain 3 Iteration: 1800 / 4000 [ 45%]  (Sampling) \n#> Chain 4 Iteration:  400 / 4000 [ 10%]  (Warmup) \n#> Chain 6 Iteration:  500 / 4000 [ 12%]  (Warmup) \n#> Chain 6 Iteration:  501 / 4000 [ 12%]  (Sampling) \n#> Chain 6 Iteration:  600 / 4000 [ 15%]  (Sampling) \n#> Chain 6 Iteration:  700 / 4000 [ 17%]  (Sampling) \n#> Chain 6 Iteration:  800 / 4000 [ 20%]  (Sampling) \n#> Chain 1 Iteration: 2400 / 4000 [ 60%]  (Sampling) \n#> Chain 1 Iteration: 2500 / 4000 [ 62%]  (Sampling) \n#> Chain 1 Iteration: 2600 / 4000 [ 65%]  (Sampling) \n#> Chain 1 Iteration: 2700 / 4000 [ 67%]  (Sampling) \n#> Chain 1 Iteration: 2800 / 4000 [ 70%]  (Sampling) \n#> Chain 1 Iteration: 2900 / 4000 [ 72%]  (Sampling) \n#> Chain 2 Iteration:  900 / 4000 [ 22%]  (Sampling) \n#> Chain 2 Iteration: 1000 / 4000 [ 25%]  (Sampling) \n#> Chain 2 Iteration: 1100 / 4000 [ 27%]  (Sampling) \n#> Chain 2 Iteration: 1200 / 4000 [ 30%]  (Sampling) \n#> Chain 2 Iteration: 1300 / 4000 [ 32%]  (Sampling) \n#> Chain 2 Iteration: 1400 / 4000 [ 35%]  (Sampling) \n#> Chain 3 Iteration: 1900 / 4000 [ 47%]  (Sampling) \n#> Chain 3 Iteration: 2000 / 4000 [ 50%]  (Sampling) \n#> Chain 3 Iteration: 2100 / 4000 [ 52%]  (Sampling) \n#> Chain 3 Iteration: 2200 / 4000 [ 55%]  (Sampling) \n#> Chain 3 Iteration: 2300 / 4000 [ 57%]  (Sampling) \n#> Chain 3 Iteration: 2400 / 4000 [ 60%]  (Sampling) \n#> Chain 4 Iteration:  500 / 4000 [ 12%]  (Warmup) \n#> Chain 4 Iteration:  501 / 4000 [ 12%]  (Sampling) \n#> Chain 4 Iteration:  600 / 4000 [ 15%]  (Sampling) \n#> Chain 5 Iteration:  500 / 4000 [ 12%]  (Warmup) \n#> Chain 5 Iteration:  501 / 4000 [ 12%]  (Sampling) \n#> Chain 6 Iteration:  900 / 4000 [ 22%]  (Sampling) \n#> Chain 6 Iteration: 1000 / 4000 [ 25%]  (Sampling) \n#> Chain 6 Iteration: 1100 / 4000 [ 27%]  (Sampling) \n#> Chain 6 Iteration: 1200 / 4000 [ 30%]  (Sampling) \n#> Chain 6 Iteration: 1300 / 4000 [ 32%]  (Sampling) \n#> Chain 6 Iteration: 1400 / 4000 [ 35%]  (Sampling) \n#> Chain 6 Iteration: 1500 / 4000 [ 37%]  (Sampling) \n#> Chain 6 Iteration: 1600 / 4000 [ 40%]  (Sampling) \n#> Chain 1 Iteration: 3000 / 4000 [ 75%]  (Sampling) \n#> Chain 1 Iteration: 3100 / 4000 [ 77%]  (Sampling) \n#> Chain 1 Iteration: 3200 / 4000 [ 80%]  (Sampling) \n#> Chain 1 Iteration: 3300 / 4000 [ 82%]  (Sampling) \n#> Chain 1 Iteration: 3400 / 4000 [ 85%]  (Sampling) \n#> Chain 1 Iteration: 3500 / 4000 [ 87%]  (Sampling) \n#> Chain 1 Iteration: 3600 / 4000 [ 90%]  (Sampling) \n#> Chain 2 Iteration: 1500 / 4000 [ 37%]  (Sampling) \n#> Chain 2 Iteration: 1600 / 4000 [ 40%]  (Sampling) \n#> Chain 2 Iteration: 1700 / 4000 [ 42%]  (Sampling) \n#> Chain 2 Iteration: 1800 / 4000 [ 45%]  (Sampling) \n#> Chain 2 Iteration: 1900 / 4000 [ 47%]  (Sampling) \n#> Chain 3 Iteration: 2500 / 4000 [ 62%]  (Sampling) \n#> Chain 3 Iteration: 2600 / 4000 [ 65%]  (Sampling) \n#> Chain 3 Iteration: 2700 / 4000 [ 67%]  (Sampling) \n#> Chain 3 Iteration: 2800 / 4000 [ 70%]  (Sampling) \n#> Chain 3 Iteration: 2900 / 4000 [ 72%]  (Sampling) \n#> Chain 3 Iteration: 3000 / 4000 [ 75%]  (Sampling) \n#> Chain 4 Iteration:  700 / 4000 [ 17%]  (Sampling) \n#> Chain 4 Iteration:  800 / 4000 [ 20%]  (Sampling) \n#> Chain 4 Iteration:  900 / 4000 [ 22%]  (Sampling) \n#> Chain 4 Iteration: 1000 / 4000 [ 25%]  (Sampling) \n#> Chain 4 Iteration: 1100 / 4000 [ 27%]  (Sampling) \n#> Chain 6 Iteration: 1700 / 4000 [ 42%]  (Sampling) \n#> Chain 6 Iteration: 1800 / 4000 [ 45%]  (Sampling) \n#> Chain 6 Iteration: 1900 / 4000 [ 47%]  (Sampling) \n#> Chain 6 Iteration: 2000 / 4000 [ 50%]  (Sampling) \n#> Chain 6 Iteration: 2100 / 4000 [ 52%]  (Sampling) \n#> Chain 6 Iteration: 2200 / 4000 [ 55%]  (Sampling) \n#> Chain 6 Iteration: 2300 / 4000 [ 57%]  (Sampling) \n#> Chain 6 Iteration: 2400 / 4000 [ 60%]  (Sampling) \n#> Chain 1 Iteration: 3700 / 4000 [ 92%]  (Sampling) \n#> Chain 1 Iteration: 3800 / 4000 [ 95%]  (Sampling) \n#> Chain 1 Iteration: 3900 / 4000 [ 97%]  (Sampling) \n#> Chain 1 Iteration: 4000 / 4000 [100%]  (Sampling) \n#> Chain 2 Iteration: 2000 / 4000 [ 50%]  (Sampling) \n#> Chain 2 Iteration: 2100 / 4000 [ 52%]  (Sampling) \n#> Chain 2 Iteration: 2200 / 4000 [ 55%]  (Sampling) \n#> Chain 2 Iteration: 2300 / 4000 [ 57%]  (Sampling) \n#> Chain 2 Iteration: 2400 / 4000 [ 60%]  (Sampling) \n#> Chain 2 Iteration: 2500 / 4000 [ 62%]  (Sampling) \n#> Chain 3 Iteration: 3100 / 4000 [ 77%]  (Sampling) \n#> Chain 3 Iteration: 3200 / 4000 [ 80%]  (Sampling) \n#> Chain 3 Iteration: 3300 / 4000 [ 82%]  (Sampling) \n#> Chain 3 Iteration: 3400 / 4000 [ 85%]  (Sampling) \n#> Chain 3 Iteration: 3500 / 4000 [ 87%]  (Sampling) \n#> Chain 3 Iteration: 3600 / 4000 [ 90%]  (Sampling) \n#> Chain 4 Iteration: 1200 / 4000 [ 30%]  (Sampling) \n#> Chain 4 Iteration: 1300 / 4000 [ 32%]  (Sampling) \n#> Chain 4 Iteration: 1400 / 4000 [ 35%]  (Sampling) \n#> Chain 4 Iteration: 1500 / 4000 [ 37%]  (Sampling) \n#> Chain 4 Iteration: 1600 / 4000 [ 40%]  (Sampling) \n#> Chain 5 Iteration:  600 / 4000 [ 15%]  (Sampling) \n#> Chain 6 Iteration: 2500 / 4000 [ 62%]  (Sampling) \n#> Chain 6 Iteration: 2600 / 4000 [ 65%]  (Sampling) \n#> Chain 6 Iteration: 2700 / 4000 [ 67%]  (Sampling) \n#> Chain 6 Iteration: 2800 / 4000 [ 70%]  (Sampling) \n#> Chain 6 Iteration: 2900 / 4000 [ 72%]  (Sampling) \n#> Chain 6 Iteration: 3000 / 4000 [ 75%]  (Sampling) \n#> Chain 6 Iteration: 3100 / 4000 [ 77%]  (Sampling) \n#> Chain 6 Iteration: 3200 / 4000 [ 80%]  (Sampling) \n#> Chain 6 Iteration: 3300 / 4000 [ 82%]  (Sampling) \n#> Chain 1 finished in 1.2 seconds.\n#> Chain 2 Iteration: 2600 / 4000 [ 65%]  (Sampling) \n#> Chain 2 Iteration: 2700 / 4000 [ 67%]  (Sampling) \n#> Chain 2 Iteration: 2800 / 4000 [ 70%]  (Sampling) \n#> Chain 2 Iteration: 2900 / 4000 [ 72%]  (Sampling) \n#> Chain 2 Iteration: 3000 / 4000 [ 75%]  (Sampling) \n#> Chain 2 Iteration: 3100 / 4000 [ 77%]  (Sampling) \n#> Chain 3 Iteration: 3700 / 4000 [ 92%]  (Sampling) \n#> Chain 3 Iteration: 3800 / 4000 [ 95%]  (Sampling) \n#> Chain 3 Iteration: 3900 / 4000 [ 97%]  (Sampling) \n#> Chain 3 Iteration: 4000 / 4000 [100%]  (Sampling) \n#> Chain 4 Iteration: 1700 / 4000 [ 42%]  (Sampling) \n#> Chain 4 Iteration: 1800 / 4000 [ 45%]  (Sampling) \n#> Chain 4 Iteration: 1900 / 4000 [ 47%]  (Sampling) \n#> Chain 4 Iteration: 2000 / 4000 [ 50%]  (Sampling) \n#> Chain 4 Iteration: 2100 / 4000 [ 52%]  (Sampling) \n#> Chain 5 Iteration:  700 / 4000 [ 17%]  (Sampling) \n#> Chain 5 Iteration:  800 / 4000 [ 20%]  (Sampling) \n#> Chain 6 Iteration: 3400 / 4000 [ 85%]  (Sampling) \n#> Chain 6 Iteration: 3500 / 4000 [ 87%]  (Sampling) \n#> Chain 6 Iteration: 3600 / 4000 [ 90%]  (Sampling) \n#> Chain 6 Iteration: 3700 / 4000 [ 92%]  (Sampling) \n#> Chain 6 Iteration: 3800 / 4000 [ 95%]  (Sampling) \n#> Chain 6 Iteration: 3900 / 4000 [ 97%]  (Sampling) \n#> Chain 6 Iteration: 4000 / 4000 [100%]  (Sampling) \n#> Chain 3 finished in 1.3 seconds.\n#> Chain 6 finished in 1.3 seconds.\n#> Chain 2 Iteration: 3200 / 4000 [ 80%]  (Sampling) \n#> Chain 2 Iteration: 3300 / 4000 [ 82%]  (Sampling) \n#> Chain 2 Iteration: 3400 / 4000 [ 85%]  (Sampling) \n#> Chain 2 Iteration: 3500 / 4000 [ 87%]  (Sampling) \n#> Chain 2 Iteration: 3600 / 4000 [ 90%]  (Sampling) \n#> Chain 2 Iteration: 3700 / 4000 [ 92%]  (Sampling) \n#> Chain 2 Iteration: 3800 / 4000 [ 95%]  (Sampling) \n#> Chain 4 Iteration: 2200 / 4000 [ 55%]  (Sampling) \n#> Chain 4 Iteration: 2300 / 4000 [ 57%]  (Sampling) \n#> Chain 4 Iteration: 2400 / 4000 [ 60%]  (Sampling) \n#> Chain 4 Iteration: 2500 / 4000 [ 62%]  (Sampling) \n#> Chain 4 Iteration: 2600 / 4000 [ 65%]  (Sampling) \n#> Chain 4 Iteration: 2700 / 4000 [ 67%]  (Sampling) \n#> Chain 5 Iteration:  900 / 4000 [ 22%]  (Sampling) \n#> Chain 2 Iteration: 3900 / 4000 [ 97%]  (Sampling) \n#> Chain 2 Iteration: 4000 / 4000 [100%]  (Sampling) \n#> Chain 4 Iteration: 2800 / 4000 [ 70%]  (Sampling) \n#> Chain 4 Iteration: 2900 / 4000 [ 72%]  (Sampling) \n#> Chain 4 Iteration: 3000 / 4000 [ 75%]  (Sampling) \n#> Chain 4 Iteration: 3100 / 4000 [ 77%]  (Sampling) \n#> Chain 4 Iteration: 3200 / 4000 [ 80%]  (Sampling) \n#> Chain 5 Iteration: 1000 / 4000 [ 25%]  (Sampling) \n#> Chain 2 finished in 1.5 seconds.\n#> Chain 4 Iteration: 3300 / 4000 [ 82%]  (Sampling) \n#> Chain 4 Iteration: 3400 / 4000 [ 85%]  (Sampling) \n#> Chain 4 Iteration: 3500 / 4000 [ 87%]  (Sampling) \n#> Chain 4 Iteration: 3600 / 4000 [ 90%]  (Sampling) \n#> Chain 4 Iteration: 3700 / 4000 [ 92%]  (Sampling) \n#> Chain 4 Iteration: 3800 / 4000 [ 95%]  (Sampling) \n#> Chain 5 Iteration: 1100 / 4000 [ 27%]  (Sampling) \n#> Chain 4 Iteration: 3900 / 4000 [ 97%]  (Sampling) \n#> Chain 4 Iteration: 4000 / 4000 [100%]  (Sampling) \n#> Chain 5 Iteration: 1200 / 4000 [ 30%]  (Sampling) \n#> Chain 5 Iteration: 1300 / 4000 [ 32%]  (Sampling) \n#> Chain 4 finished in 1.7 seconds.\n#> Chain 5 Iteration: 1400 / 4000 [ 35%]  (Sampling) \n#> Chain 5 Iteration: 1500 / 4000 [ 37%]  (Sampling) \n#> Chain 5 Iteration: 1600 / 4000 [ 40%]  (Sampling) \n#> Chain 5 Iteration: 1700 / 4000 [ 42%]  (Sampling) \n#> Chain 5 Iteration: 1800 / 4000 [ 45%]  (Sampling) \n#> Chain 5 Iteration: 1900 / 4000 [ 47%]  (Sampling) \n#> Chain 5 Iteration: 2000 / 4000 [ 50%]  (Sampling) \n#> Chain 5 Iteration: 2100 / 4000 [ 52%]  (Sampling) \n#> Chain 5 Iteration: 2200 / 4000 [ 55%]  (Sampling) \n#> Chain 5 Iteration: 2300 / 4000 [ 57%]  (Sampling) \n#> Chain 5 Iteration: 2400 / 4000 [ 60%]  (Sampling) \n#> Chain 5 Iteration: 2500 / 4000 [ 62%]  (Sampling) \n#> Chain 5 Iteration: 2600 / 4000 [ 65%]  (Sampling) \n#> Chain 5 Iteration: 2700 / 4000 [ 67%]  (Sampling) \n#> Chain 5 Iteration: 2800 / 4000 [ 70%]  (Sampling) \n#> Chain 5 Iteration: 2900 / 4000 [ 72%]  (Sampling) \n#> Chain 5 Iteration: 3000 / 4000 [ 75%]  (Sampling) \n#> Chain 5 Iteration: 3100 / 4000 [ 77%]  (Sampling) \n#> Chain 5 Iteration: 3200 / 4000 [ 80%]  (Sampling) \n#> Chain 5 Iteration: 3300 / 4000 [ 82%]  (Sampling) \n#> Chain 5 Iteration: 3400 / 4000 [ 85%]  (Sampling) \n#> Chain 5 Iteration: 3500 / 4000 [ 87%]  (Sampling) \n#> Chain 5 Iteration: 3600 / 4000 [ 90%]  (Sampling) \n#> Chain 5 Iteration: 3700 / 4000 [ 92%]  (Sampling) \n#> Chain 5 Iteration: 3800 / 4000 [ 95%]  (Sampling) \n#> Chain 5 Iteration: 3900 / 4000 [ 97%]  (Sampling) \n#> Chain 5 Iteration: 4000 / 4000 [100%]  (Sampling) \n#> Chain 5 finished in 3.8 seconds.\n#> \n#> All 6 chains finished successfully.\n#> Mean chain execution time: 1.8 seconds.\n#> Total execution time: 3.9 seconds.\n```\n:::\n\n\nY bueno, no ha tardado mucho, unos 3 segundos por cadena. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mbrm)\n#>  Family: poisson \n#>   Links: mu = identity \n#> Formula: y ~ b0 + b1 * t + b2 * (t - change) * step(t - change) \n#>          b0 ~ 1\n#>          b1 ~ 1\n#>          b2 ~ 1\n#>          change ~ 1\n#>    Data: df (Number of observations: 23) \n#>   Draws: 6 chains, each with iter = 4000; warmup = 500; thin = 1;\n#>          total post-warmup draws = 21000\n#> \n#> Population-Level Effects: \n#>                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> b0_Intercept        60.06      4.94    50.35    69.89 1.00     4931     4757\n#> b1_Intercept         0.00      0.00    -0.00     0.01 1.00     5808     6372\n#> b2_Intercept        -1.08      0.42    -1.95    -0.32 1.00     7811     7251\n#> change_Intercept  2008.79      2.84  2002.99  2014.44 1.00     8202     7091\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n\nPodemos pintar la curva media estimada y su intervalo de credibilidad\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(conditional_effects(mbrm),\n     points = TRUE)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=80%}\n:::\n:::\n\n\nTambién la posterior predict function de los diferentes puntos. Evidentemente esto tiene más variabilidad que la posterior predict de la media condicionada que era el gráfico anterior. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(conditional_effects(mbrm, method = \"posterior_predict\"),\n     points = TRUE)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=80%}\n:::\n:::\n\n\nY básicamente, obtenermos los mismo resultados que Carlo con numpyro. \n\n\nPodemos obtener un histograma de la posterior del punto de cambio\n\n\n::: {.cell}\n\n```{.r .cell-code}\npunto_cambio_posterior <- as_draws_df(mbrm, variable = \"b_change_Intercept\")\n\nggplot2::ggplot(punto_cambio_posterior, aes(x =b_change_Intercept ))   +\n    ggplot2::geom_histogram()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=80%}\n:::\n:::\n\n\n\nUna cosa interesante de `brms` es que nos construye código en Stan que luego nosotros podemos modificar\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmake_stancode(bform, data = df,prior= bprior, family = poisson(\"identity\"))\n#> // generated with brms 2.18.0\n#> functions {\n#> }\n#> data {\n#>   int<lower=1> N;  // total number of observations\n#>   int Y[N];  // response variable\n#>   int<lower=1> K_b0;  // number of population-level effects\n#>   matrix[N, K_b0] X_b0;  // population-level design matrix\n#>   int<lower=1> K_b1;  // number of population-level effects\n#>   matrix[N, K_b1] X_b1;  // population-level design matrix\n#>   int<lower=1> K_b2;  // number of population-level effects\n#>   matrix[N, K_b2] X_b2;  // population-level design matrix\n#>   int<lower=1> K_change;  // number of population-level effects\n#>   matrix[N, K_change] X_change;  // population-level design matrix\n#>   // covariate vectors for non-linear functions\n#>   int C_1[N];\n#>   int prior_only;  // should the likelihood be ignored?\n#> }\n#> transformed data {\n#> }\n#> parameters {\n#>   vector[K_b0] b_b0;  // population-level effects\n#>   vector[K_b1] b_b1;  // population-level effects\n#>   vector[K_b2] b_b2;  // population-level effects\n#>   vector[K_change] b_change;  // population-level effects\n#> }\n#> transformed parameters {\n#>   real lprior = 0;  // prior contributions to the log posterior\n#>   lprior += normal_lpdf(b_b0 | 60, 5);\n#>   lprior += normal_lpdf(b_b1 | 0, 1);\n#>   lprior += normal_lpdf(b_b2 | 0, 1);\n#>   lprior += normal_lpdf(b_change | 2010, 23/4);\n#> }\n#> model {\n#>   // likelihood including constants\n#>   if (!prior_only) {\n#>     // initialize linear predictor term\n#>     vector[N] nlp_b0 = rep_vector(0.0, N);\n#>     // initialize linear predictor term\n#>     vector[N] nlp_b1 = rep_vector(0.0, N);\n#>     // initialize linear predictor term\n#>     vector[N] nlp_b2 = rep_vector(0.0, N);\n#>     // initialize linear predictor term\n#>     vector[N] nlp_change = rep_vector(0.0, N);\n#>     // initialize non-linear predictor term\n#>     vector[N] mu;\n#>     nlp_b0 += X_b0 * b_b0;\n#>     nlp_b1 += X_b1 * b_b1;\n#>     nlp_b2 += X_b2 * b_b2;\n#>     nlp_change += X_change * b_change;\n#>     for (n in 1:N) {\n#>       // compute non-linear predictor values\n#>       mu[n] = nlp_b0[n] + nlp_b1[n] * C_1[n] + nlp_b2[n] * (C_1[n] - nlp_change[n]) * step(C_1[n] - nlp_change[n]);\n#>     }\n#>     target += poisson_lpmf(Y | mu);\n#>   }\n#>   // priors including constants\n#>   target += lprior;\n#> }\n#> generated quantities {\n#> }\n```\n:::\n\n\n\n### Notas \n\nUna forma fácil de ajustar estos datos es usando splines. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nm_spline  <- brm(\n                 y ~ s(t), \n                 family = poisson(\"identity\"), \n                 data = df, \n                 backend= \"cmdstanr\"\n)\n#> Running MCMC with 4 sequential chains...\n#> \n#> Chain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \n#> Chain 1 Iteration:  100 / 2000 [  5%]  (Warmup) \n#> Chain 1 Iteration:  200 / 2000 [ 10%]  (Warmup) \n#> Chain 1 Iteration:  300 / 2000 [ 15%]  (Warmup) \n#> Chain 1 Iteration:  400 / 2000 [ 20%]  (Warmup) \n#> Chain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \n#> Chain 1 Iteration:  600 / 2000 [ 30%]  (Warmup) \n#> Chain 1 Iteration:  700 / 2000 [ 35%]  (Warmup) \n#> Chain 1 Iteration:  800 / 2000 [ 40%]  (Warmup) \n#> Chain 1 Iteration:  900 / 2000 [ 45%]  (Warmup) \n#> Chain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \n#> Chain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n#> Chain 1 Iteration: 1100 / 2000 [ 55%]  (Sampling) \n#> Chain 1 Iteration: 1200 / 2000 [ 60%]  (Sampling) \n#> Chain 1 Iteration: 1300 / 2000 [ 65%]  (Sampling) \n#> Chain 1 Iteration: 1400 / 2000 [ 70%]  (Sampling) \n#> Chain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \n#> Chain 1 Iteration: 1600 / 2000 [ 80%]  (Sampling) \n#> Chain 1 Iteration: 1700 / 2000 [ 85%]  (Sampling) \n#> Chain 1 Iteration: 1800 / 2000 [ 90%]  (Sampling) \n#> Chain 1 Iteration: 1900 / 2000 [ 95%]  (Sampling) \n#> Chain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \n#> Chain 1 finished in 0.2 seconds.\n#> Chain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \n#> Chain 2 Iteration:  100 / 2000 [  5%]  (Warmup) \n#> Chain 2 Iteration:  200 / 2000 [ 10%]  (Warmup) \n#> Chain 2 Iteration:  300 / 2000 [ 15%]  (Warmup) \n#> Chain 2 Iteration:  400 / 2000 [ 20%]  (Warmup) \n#> Chain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \n#> Chain 2 Iteration:  600 / 2000 [ 30%]  (Warmup) \n#> Chain 2 Iteration:  700 / 2000 [ 35%]  (Warmup) \n#> Chain 2 Iteration:  800 / 2000 [ 40%]  (Warmup) \n#> Chain 2 Iteration:  900 / 2000 [ 45%]  (Warmup) \n#> Chain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \n#> Chain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n#> Chain 2 Iteration: 1100 / 2000 [ 55%]  (Sampling) \n#> Chain 2 Iteration: 1200 / 2000 [ 60%]  (Sampling) \n#> Chain 2 Iteration: 1300 / 2000 [ 65%]  (Sampling) \n#> Chain 2 Iteration: 1400 / 2000 [ 70%]  (Sampling) \n#> Chain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \n#> Chain 2 Iteration: 1600 / 2000 [ 80%]  (Sampling) \n#> Chain 2 Iteration: 1700 / 2000 [ 85%]  (Sampling) \n#> Chain 2 Iteration: 1800 / 2000 [ 90%]  (Sampling) \n#> Chain 2 Iteration: 1900 / 2000 [ 95%]  (Sampling) \n#> Chain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \n#> Chain 2 finished in 0.2 seconds.\n#> Chain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \n#> Chain 3 Iteration:  100 / 2000 [  5%]  (Warmup) \n#> Chain 3 Iteration:  200 / 2000 [ 10%]  (Warmup) \n#> Chain 3 Iteration:  300 / 2000 [ 15%]  (Warmup) \n#> Chain 3 Iteration:  400 / 2000 [ 20%]  (Warmup) \n#> Chain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \n#> Chain 3 Iteration:  600 / 2000 [ 30%]  (Warmup) \n#> Chain 3 Iteration:  700 / 2000 [ 35%]  (Warmup) \n#> Chain 3 Iteration:  800 / 2000 [ 40%]  (Warmup) \n#> Chain 3 Iteration:  900 / 2000 [ 45%]  (Warmup) \n#> Chain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \n#> Chain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n#> Chain 3 Iteration: 1100 / 2000 [ 55%]  (Sampling) \n#> Chain 3 Iteration: 1200 / 2000 [ 60%]  (Sampling) \n#> Chain 3 Iteration: 1300 / 2000 [ 65%]  (Sampling) \n#> Chain 3 Iteration: 1400 / 2000 [ 70%]  (Sampling) \n#> Chain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \n#> Chain 3 Iteration: 1600 / 2000 [ 80%]  (Sampling) \n#> Chain 3 Iteration: 1700 / 2000 [ 85%]  (Sampling) \n#> Chain 3 Iteration: 1800 / 2000 [ 90%]  (Sampling) \n#> Chain 3 Iteration: 1900 / 2000 [ 95%]  (Sampling) \n#> Chain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \n#> Chain 3 finished in 0.2 seconds.\n#> Chain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \n#> Chain 4 Iteration:  100 / 2000 [  5%]  (Warmup) \n#> Chain 4 Iteration:  200 / 2000 [ 10%]  (Warmup) \n#> Chain 4 Iteration:  300 / 2000 [ 15%]  (Warmup) \n#> Chain 4 Iteration:  400 / 2000 [ 20%]  (Warmup) \n#> Chain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \n#> Chain 4 Iteration:  600 / 2000 [ 30%]  (Warmup) \n#> Chain 4 Iteration:  700 / 2000 [ 35%]  (Warmup) \n#> Chain 4 Iteration:  800 / 2000 [ 40%]  (Warmup) \n#> Chain 4 Iteration:  900 / 2000 [ 45%]  (Warmup) \n#> Chain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \n#> Chain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n#> Chain 4 Iteration: 1100 / 2000 [ 55%]  (Sampling) \n#> Chain 4 Iteration: 1200 / 2000 [ 60%]  (Sampling) \n#> Chain 4 Iteration: 1300 / 2000 [ 65%]  (Sampling) \n#> Chain 4 Iteration: 1400 / 2000 [ 70%]  (Sampling) \n#> Chain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \n#> Chain 4 Iteration: 1600 / 2000 [ 80%]  (Sampling) \n#> Chain 4 Iteration: 1700 / 2000 [ 85%]  (Sampling) \n#> Chain 4 Iteration: 1800 / 2000 [ 90%]  (Sampling) \n#> Chain 4 Iteration: 1900 / 2000 [ 95%]  (Sampling) \n#> Chain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \n#> Chain 4 finished in 0.2 seconds.\n#> \n#> All 4 chains finished successfully.\n#> Mean chain execution time: 0.2 seconds.\n#> Total execution time: 1.1 seconds.\n\nsummary(m_spline)\n#>  Family: poisson \n#>   Links: mu = identity \n#> Formula: y ~ s(t) \n#>    Data: df (Number of observations: 23) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 4000\n#> \n#> Smooth Terms: \n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sds(st_1)    13.00      7.82     1.23    32.04 1.00     1218     1257\n#> \n#> Population-Level Effects: \n#>           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> Intercept    58.83      1.54    55.92    61.94 1.01     4359     2584\n#> st_1         -3.33     34.12   -60.23    78.27 1.00     1238     1061\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n\nplot(conditional_smooths(m_spline, method = \"posterior_predict\") \n    ) \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=80%}\n:::\n:::\n\n\nY tendríamos la posterior del spline , pero la verdad, ahora no tengo ganas de buscar como interpretar ese spline para traducir a punto de cambio de tendencia.\n\n\nPor otro lado, leyendo por ahí he visto una implementación un pelín diferente \n\n\n::: {.cell}\n\n```{.r .cell-code}\nbform_alt <- bf(\n    y ~ b0 +\n        # aqui es donde cambia un poco\n        b1 * (t - change) * step(change - t) +\n        # post cambio\n        b2 * (t - change) * step(t - change),\n    b0 + b1 + b2 + change ~ 1,\n    nl = TRUE\n)\n\nbprior <- prior(normal(60, 5), nlpar = \"b0\") +\n    prior(normal(0, 1), nlpar = \"b1\") +\n    prior(normal(0, 1), nlpar = \"b2\") +\n    prior(normal(2010, 23 / 4), nlpar = \"change\")\n\n\nmbrm_alt <-\n    brm(\n        bform_alt, family = poisson(\"identity\"),\n        prior = bprior,\n        data = df,\n        backend = \"cmdstanr\",\n        cores = 6,\n        chains = 6,\n        iter = 4000,\n        warmup = 500\n    )\n#> Running MCMC with 6 parallel chains...\n#> \n#> Chain 1 Iteration:    1 / 4000 [  0%]  (Warmup) \n#> Chain 1 Iteration:  100 / 4000 [  2%]  (Warmup) \n#> Chain 2 Iteration:    1 / 4000 [  0%]  (Warmup) \n#> Chain 2 Iteration:  100 / 4000 [  2%]  (Warmup) \n#> Chain 3 Iteration:    1 / 4000 [  0%]  (Warmup) \n#> Chain 3 Iteration:  100 / 4000 [  2%]  (Warmup) \n#> Chain 4 Iteration:    1 / 4000 [  0%]  (Warmup) \n#> Chain 4 Iteration:  100 / 4000 [  2%]  (Warmup) \n#> Chain 5 Iteration:    1 / 4000 [  0%]  (Warmup) \n#> Chain 5 Iteration:  100 / 4000 [  2%]  (Warmup) \n#> Chain 6 Iteration:    1 / 4000 [  0%]  (Warmup) \n#> Chain 6 Iteration:  100 / 4000 [  2%]  (Warmup) \n#> Chain 6 Iteration:  200 / 4000 [  5%]  (Warmup) \n#> Chain 1 Iteration:  200 / 4000 [  5%]  (Warmup) \n#> Chain 2 Iteration:  200 / 4000 [  5%]  (Warmup) \n#> Chain 5 Iteration:  200 / 4000 [  5%]  (Warmup) \n#> Chain 3 Iteration:  200 / 4000 [  5%]  (Warmup) \n#> Chain 4 Iteration:  200 / 4000 [  5%]  (Warmup) \n#> Chain 5 Iteration:  300 / 4000 [  7%]  (Warmup) \n#> Chain 1 Iteration:  300 / 4000 [  7%]  (Warmup) \n#> Chain 1 Iteration:  400 / 4000 [ 10%]  (Warmup) \n#> Chain 1 Iteration:  500 / 4000 [ 12%]  (Warmup) \n#> Chain 1 Iteration:  501 / 4000 [ 12%]  (Sampling) \n#> Chain 1 Iteration:  600 / 4000 [ 15%]  (Sampling) \n#> Chain 1 Iteration:  700 / 4000 [ 17%]  (Sampling) \n#> Chain 1 Iteration:  800 / 4000 [ 20%]  (Sampling) \n#> Chain 2 Iteration:  300 / 4000 [  7%]  (Warmup) \n#> Chain 2 Iteration:  400 / 4000 [ 10%]  (Warmup) \n#> Chain 2 Iteration:  500 / 4000 [ 12%]  (Warmup) \n#> Chain 2 Iteration:  501 / 4000 [ 12%]  (Sampling) \n#> Chain 2 Iteration:  600 / 4000 [ 15%]  (Sampling) \n#> Chain 2 Iteration:  700 / 4000 [ 17%]  (Sampling) \n#> Chain 2 Iteration:  800 / 4000 [ 20%]  (Sampling) \n#> Chain 2 Iteration:  900 / 4000 [ 22%]  (Sampling) \n#> Chain 1 Iteration:  900 / 4000 [ 22%]  (Sampling) \n#> Chain 1 Iteration: 1000 / 4000 [ 25%]  (Sampling) \n#> Chain 1 Iteration: 1100 / 4000 [ 27%]  (Sampling) \n#> Chain 1 Iteration: 1200 / 4000 [ 30%]  (Sampling) \n#> Chain 1 Iteration: 1300 / 4000 [ 32%]  (Sampling) \n#> Chain 1 Iteration: 1400 / 4000 [ 35%]  (Sampling) \n#> Chain 1 Iteration: 1500 / 4000 [ 37%]  (Sampling) \n#> Chain 1 Iteration: 1600 / 4000 [ 40%]  (Sampling) \n#> Chain 1 Iteration: 1700 / 4000 [ 42%]  (Sampling) \n#> Chain 1 Iteration: 1800 / 4000 [ 45%]  (Sampling) \n#> Chain 1 Iteration: 1900 / 4000 [ 47%]  (Sampling) \n#> Chain 1 Iteration: 2000 / 4000 [ 50%]  (Sampling) \n#> Chain 2 Iteration: 1000 / 4000 [ 25%]  (Sampling) \n#> Chain 2 Iteration: 1100 / 4000 [ 27%]  (Sampling) \n#> Chain 2 Iteration: 1200 / 4000 [ 30%]  (Sampling) \n#> Chain 2 Iteration: 1300 / 4000 [ 32%]  (Sampling) \n#> Chain 2 Iteration: 1400 / 4000 [ 35%]  (Sampling) \n#> Chain 2 Iteration: 1500 / 4000 [ 37%]  (Sampling) \n#> Chain 2 Iteration: 1600 / 4000 [ 40%]  (Sampling) \n#> Chain 2 Iteration: 1700 / 4000 [ 42%]  (Sampling) \n#> Chain 2 Iteration: 1800 / 4000 [ 45%]  (Sampling) \n#> Chain 2 Iteration: 1900 / 4000 [ 47%]  (Sampling) \n#> Chain 2 Iteration: 2000 / 4000 [ 50%]  (Sampling) \n#> Chain 2 Iteration: 2100 / 4000 [ 52%]  (Sampling) \n#> Chain 3 Iteration:  300 / 4000 [  7%]  (Warmup) \n#> Chain 3 Iteration:  400 / 4000 [ 10%]  (Warmup) \n#> Chain 3 Iteration:  500 / 4000 [ 12%]  (Warmup) \n#> Chain 3 Iteration:  501 / 4000 [ 12%]  (Sampling) \n#> Chain 3 Iteration:  600 / 4000 [ 15%]  (Sampling) \n#> Chain 3 Iteration:  700 / 4000 [ 17%]  (Sampling) \n#> Chain 3 Iteration:  800 / 4000 [ 20%]  (Sampling) \n#> Chain 3 Iteration:  900 / 4000 [ 22%]  (Sampling) \n#> Chain 3 Iteration: 1000 / 4000 [ 25%]  (Sampling) \n#> Chain 3 Iteration: 1100 / 4000 [ 27%]  (Sampling) \n#> Chain 3 Iteration: 1200 / 4000 [ 30%]  (Sampling) \n#> Chain 3 Iteration: 1300 / 4000 [ 32%]  (Sampling) \n#> Chain 3 Iteration: 1400 / 4000 [ 35%]  (Sampling) \n#> Chain 5 Iteration:  400 / 4000 [ 10%]  (Warmup) \n#> Chain 6 Iteration:  300 / 4000 [  7%]  (Warmup) \n#> Chain 1 Iteration: 2100 / 4000 [ 52%]  (Sampling) \n#> Chain 1 Iteration: 2200 / 4000 [ 55%]  (Sampling) \n#> Chain 1 Iteration: 2300 / 4000 [ 57%]  (Sampling) \n#> Chain 1 Iteration: 2400 / 4000 [ 60%]  (Sampling) \n#> Chain 1 Iteration: 2500 / 4000 [ 62%]  (Sampling) \n#> Chain 1 Iteration: 2600 / 4000 [ 65%]  (Sampling) \n#> Chain 1 Iteration: 2700 / 4000 [ 67%]  (Sampling) \n#> Chain 1 Iteration: 2800 / 4000 [ 70%]  (Sampling) \n#> Chain 1 Iteration: 2900 / 4000 [ 72%]  (Sampling) \n#> Chain 1 Iteration: 3000 / 4000 [ 75%]  (Sampling) \n#> Chain 1 Iteration: 3100 / 4000 [ 77%]  (Sampling) \n#> Chain 2 Iteration: 2200 / 4000 [ 55%]  (Sampling) \n#> Chain 2 Iteration: 2300 / 4000 [ 57%]  (Sampling) \n#> Chain 2 Iteration: 2400 / 4000 [ 60%]  (Sampling) \n#> Chain 2 Iteration: 2500 / 4000 [ 62%]  (Sampling) \n#> Chain 2 Iteration: 2600 / 4000 [ 65%]  (Sampling) \n#> Chain 2 Iteration: 2700 / 4000 [ 67%]  (Sampling) \n#> Chain 2 Iteration: 2800 / 4000 [ 70%]  (Sampling) \n#> Chain 2 Iteration: 2900 / 4000 [ 72%]  (Sampling) \n#> Chain 2 Iteration: 3000 / 4000 [ 75%]  (Sampling) \n#> Chain 2 Iteration: 3100 / 4000 [ 77%]  (Sampling) \n#> Chain 2 Iteration: 3200 / 4000 [ 80%]  (Sampling) \n#> Chain 3 Iteration: 1500 / 4000 [ 37%]  (Sampling) \n#> Chain 3 Iteration: 1600 / 4000 [ 40%]  (Sampling) \n#> Chain 3 Iteration: 1700 / 4000 [ 42%]  (Sampling) \n#> Chain 3 Iteration: 1800 / 4000 [ 45%]  (Sampling) \n#> Chain 3 Iteration: 1900 / 4000 [ 47%]  (Sampling) \n#> Chain 3 Iteration: 2000 / 4000 [ 50%]  (Sampling) \n#> Chain 3 Iteration: 2100 / 4000 [ 52%]  (Sampling) \n#> Chain 3 Iteration: 2200 / 4000 [ 55%]  (Sampling) \n#> Chain 3 Iteration: 2300 / 4000 [ 57%]  (Sampling) \n#> Chain 3 Iteration: 2400 / 4000 [ 60%]  (Sampling) \n#> Chain 3 Iteration: 2500 / 4000 [ 62%]  (Sampling) \n#> Chain 3 Iteration: 2600 / 4000 [ 65%]  (Sampling) \n#> Chain 3 Iteration: 2700 / 4000 [ 67%]  (Sampling) \n#> Chain 4 Iteration:  300 / 4000 [  7%]  (Warmup) \n#> Chain 6 Iteration:  400 / 4000 [ 10%]  (Warmup) \n#> Chain 1 Iteration: 3200 / 4000 [ 80%]  (Sampling) \n#> Chain 1 Iteration: 3300 / 4000 [ 82%]  (Sampling) \n#> Chain 1 Iteration: 3400 / 4000 [ 85%]  (Sampling) \n#> Chain 1 Iteration: 3500 / 4000 [ 87%]  (Sampling) \n#> Chain 1 Iteration: 3600 / 4000 [ 90%]  (Sampling) \n#> Chain 1 Iteration: 3700 / 4000 [ 92%]  (Sampling) \n#> Chain 1 Iteration: 3800 / 4000 [ 95%]  (Sampling) \n#> Chain 1 Iteration: 3900 / 4000 [ 97%]  (Sampling) \n#> Chain 1 Iteration: 4000 / 4000 [100%]  (Sampling) \n#> Chain 2 Iteration: 3300 / 4000 [ 82%]  (Sampling) \n#> Chain 2 Iteration: 3400 / 4000 [ 85%]  (Sampling) \n#> Chain 2 Iteration: 3500 / 4000 [ 87%]  (Sampling) \n#> Chain 2 Iteration: 3600 / 4000 [ 90%]  (Sampling) \n#> Chain 2 Iteration: 3700 / 4000 [ 92%]  (Sampling) \n#> Chain 2 Iteration: 3800 / 4000 [ 95%]  (Sampling) \n#> Chain 2 Iteration: 3900 / 4000 [ 97%]  (Sampling) \n#> Chain 2 Iteration: 4000 / 4000 [100%]  (Sampling) \n#> Chain 3 Iteration: 2800 / 4000 [ 70%]  (Sampling) \n#> Chain 3 Iteration: 2900 / 4000 [ 72%]  (Sampling) \n#> Chain 3 Iteration: 3000 / 4000 [ 75%]  (Sampling) \n#> Chain 3 Iteration: 3100 / 4000 [ 77%]  (Sampling) \n#> Chain 3 Iteration: 3200 / 4000 [ 80%]  (Sampling) \n#> Chain 3 Iteration: 3300 / 4000 [ 82%]  (Sampling) \n#> Chain 3 Iteration: 3400 / 4000 [ 85%]  (Sampling) \n#> Chain 3 Iteration: 3500 / 4000 [ 87%]  (Sampling) \n#> Chain 3 Iteration: 3600 / 4000 [ 90%]  (Sampling) \n#> Chain 3 Iteration: 3700 / 4000 [ 92%]  (Sampling) \n#> Chain 3 Iteration: 3800 / 4000 [ 95%]  (Sampling) \n#> Chain 3 Iteration: 3900 / 4000 [ 97%]  (Sampling) \n#> Chain 3 Iteration: 4000 / 4000 [100%]  (Sampling) \n#> Chain 4 Iteration:  400 / 4000 [ 10%]  (Warmup) \n#> Chain 4 Iteration:  500 / 4000 [ 12%]  (Warmup) \n#> Chain 4 Iteration:  501 / 4000 [ 12%]  (Sampling) \n#> Chain 4 Iteration:  600 / 4000 [ 15%]  (Sampling) \n#> Chain 4 Iteration:  700 / 4000 [ 17%]  (Sampling) \n#> Chain 5 Iteration:  500 / 4000 [ 12%]  (Warmup) \n#> Chain 5 Iteration:  501 / 4000 [ 12%]  (Sampling) \n#> Chain 5 Iteration:  600 / 4000 [ 15%]  (Sampling) \n#> Chain 5 Iteration:  700 / 4000 [ 17%]  (Sampling) \n#> Chain 5 Iteration:  800 / 4000 [ 20%]  (Sampling) \n#> Chain 5 Iteration:  900 / 4000 [ 22%]  (Sampling) \n#> Chain 5 Iteration: 1000 / 4000 [ 25%]  (Sampling) \n#> Chain 5 Iteration: 1100 / 4000 [ 27%]  (Sampling) \n#> Chain 5 Iteration: 1200 / 4000 [ 30%]  (Sampling) \n#> Chain 5 Iteration: 1300 / 4000 [ 32%]  (Sampling) \n#> Chain 5 Iteration: 1400 / 4000 [ 35%]  (Sampling) \n#> Chain 5 Iteration: 1500 / 4000 [ 37%]  (Sampling) \n#> Chain 5 Iteration: 1600 / 4000 [ 40%]  (Sampling) \n#> Chain 5 Iteration: 1700 / 4000 [ 42%]  (Sampling) \n#> Chain 6 Iteration:  500 / 4000 [ 12%]  (Warmup) \n#> Chain 6 Iteration:  501 / 4000 [ 12%]  (Sampling) \n#> Chain 6 Iteration:  600 / 4000 [ 15%]  (Sampling) \n#> Chain 6 Iteration:  700 / 4000 [ 17%]  (Sampling) \n#> Chain 6 Iteration:  800 / 4000 [ 20%]  (Sampling) \n#> Chain 6 Iteration:  900 / 4000 [ 22%]  (Sampling) \n#> Chain 6 Iteration: 1000 / 4000 [ 25%]  (Sampling) \n#> Chain 6 Iteration: 1100 / 4000 [ 27%]  (Sampling) \n#> Chain 6 Iteration: 1200 / 4000 [ 30%]  (Sampling) \n#> Chain 6 Iteration: 1300 / 4000 [ 32%]  (Sampling) \n#> Chain 6 Iteration: 1400 / 4000 [ 35%]  (Sampling) \n#> Chain 1 finished in 0.9 seconds.\n#> Chain 2 finished in 0.8 seconds.\n#> Chain 3 finished in 0.9 seconds.\n#> Chain 4 Iteration:  800 / 4000 [ 20%]  (Sampling) \n#> Chain 4 Iteration:  900 / 4000 [ 22%]  (Sampling) \n#> Chain 4 Iteration: 1000 / 4000 [ 25%]  (Sampling) \n#> Chain 4 Iteration: 1100 / 4000 [ 27%]  (Sampling) \n#> Chain 4 Iteration: 1200 / 4000 [ 30%]  (Sampling) \n#> Chain 4 Iteration: 1300 / 4000 [ 32%]  (Sampling) \n#> Chain 4 Iteration: 1400 / 4000 [ 35%]  (Sampling) \n#> Chain 4 Iteration: 1500 / 4000 [ 37%]  (Sampling) \n#> Chain 4 Iteration: 1600 / 4000 [ 40%]  (Sampling) \n#> Chain 4 Iteration: 1700 / 4000 [ 42%]  (Sampling) \n#> Chain 4 Iteration: 1800 / 4000 [ 45%]  (Sampling) \n#> Chain 4 Iteration: 1900 / 4000 [ 47%]  (Sampling) \n#> Chain 5 Iteration: 1800 / 4000 [ 45%]  (Sampling) \n#> Chain 5 Iteration: 1900 / 4000 [ 47%]  (Sampling) \n#> Chain 5 Iteration: 2000 / 4000 [ 50%]  (Sampling) \n#> Chain 5 Iteration: 2100 / 4000 [ 52%]  (Sampling) \n#> Chain 5 Iteration: 2200 / 4000 [ 55%]  (Sampling) \n#> Chain 5 Iteration: 2300 / 4000 [ 57%]  (Sampling) \n#> Chain 5 Iteration: 2400 / 4000 [ 60%]  (Sampling) \n#> Chain 5 Iteration: 2500 / 4000 [ 62%]  (Sampling) \n#> Chain 5 Iteration: 2600 / 4000 [ 65%]  (Sampling) \n#> Chain 5 Iteration: 2700 / 4000 [ 67%]  (Sampling) \n#> Chain 5 Iteration: 2800 / 4000 [ 70%]  (Sampling) \n#> Chain 5 Iteration: 2900 / 4000 [ 72%]  (Sampling) \n#> Chain 5 Iteration: 3000 / 4000 [ 75%]  (Sampling) \n#> Chain 5 Iteration: 3100 / 4000 [ 77%]  (Sampling) \n#> Chain 5 Iteration: 3200 / 4000 [ 80%]  (Sampling) \n#> Chain 5 Iteration: 3300 / 4000 [ 82%]  (Sampling) \n#> Chain 6 Iteration: 1500 / 4000 [ 37%]  (Sampling) \n#> Chain 6 Iteration: 1600 / 4000 [ 40%]  (Sampling) \n#> Chain 6 Iteration: 1700 / 4000 [ 42%]  (Sampling) \n#> Chain 6 Iteration: 1800 / 4000 [ 45%]  (Sampling) \n#> Chain 6 Iteration: 1900 / 4000 [ 47%]  (Sampling) \n#> Chain 6 Iteration: 2000 / 4000 [ 50%]  (Sampling) \n#> Chain 6 Iteration: 2100 / 4000 [ 52%]  (Sampling) \n#> Chain 6 Iteration: 2200 / 4000 [ 55%]  (Sampling) \n#> Chain 6 Iteration: 2300 / 4000 [ 57%]  (Sampling) \n#> Chain 6 Iteration: 2400 / 4000 [ 60%]  (Sampling) \n#> Chain 6 Iteration: 2500 / 4000 [ 62%]  (Sampling) \n#> Chain 6 Iteration: 2600 / 4000 [ 65%]  (Sampling) \n#> Chain 6 Iteration: 2700 / 4000 [ 67%]  (Sampling) \n#> Chain 6 Iteration: 2800 / 4000 [ 70%]  (Sampling) \n#> Chain 6 Iteration: 2900 / 4000 [ 72%]  (Sampling) \n#> Chain 6 Iteration: 3000 / 4000 [ 75%]  (Sampling) \n#> Chain 4 Iteration: 2000 / 4000 [ 50%]  (Sampling) \n#> Chain 4 Iteration: 2100 / 4000 [ 52%]  (Sampling) \n#> Chain 4 Iteration: 2200 / 4000 [ 55%]  (Sampling) \n#> Chain 4 Iteration: 2300 / 4000 [ 57%]  (Sampling) \n#> Chain 4 Iteration: 2400 / 4000 [ 60%]  (Sampling) \n#> Chain 4 Iteration: 2500 / 4000 [ 62%]  (Sampling) \n#> Chain 4 Iteration: 2600 / 4000 [ 65%]  (Sampling) \n#> Chain 4 Iteration: 2700 / 4000 [ 67%]  (Sampling) \n#> Chain 4 Iteration: 2800 / 4000 [ 70%]  (Sampling) \n#> Chain 4 Iteration: 2900 / 4000 [ 72%]  (Sampling) \n#> Chain 4 Iteration: 3000 / 4000 [ 75%]  (Sampling) \n#> Chain 4 Iteration: 3100 / 4000 [ 77%]  (Sampling) \n#> Chain 5 Iteration: 3400 / 4000 [ 85%]  (Sampling) \n#> Chain 5 Iteration: 3500 / 4000 [ 87%]  (Sampling) \n#> Chain 5 Iteration: 3600 / 4000 [ 90%]  (Sampling) \n#> Chain 5 Iteration: 3700 / 4000 [ 92%]  (Sampling) \n#> Chain 5 Iteration: 3800 / 4000 [ 95%]  (Sampling) \n#> Chain 5 Iteration: 3900 / 4000 [ 97%]  (Sampling) \n#> Chain 5 Iteration: 4000 / 4000 [100%]  (Sampling) \n#> Chain 6 Iteration: 3100 / 4000 [ 77%]  (Sampling) \n#> Chain 6 Iteration: 3200 / 4000 [ 80%]  (Sampling) \n#> Chain 6 Iteration: 3300 / 4000 [ 82%]  (Sampling) \n#> Chain 6 Iteration: 3400 / 4000 [ 85%]  (Sampling) \n#> Chain 6 Iteration: 3500 / 4000 [ 87%]  (Sampling) \n#> Chain 6 Iteration: 3600 / 4000 [ 90%]  (Sampling) \n#> Chain 6 Iteration: 3700 / 4000 [ 92%]  (Sampling) \n#> Chain 6 Iteration: 3800 / 4000 [ 95%]  (Sampling) \n#> Chain 6 Iteration: 3900 / 4000 [ 97%]  (Sampling) \n#> Chain 6 Iteration: 4000 / 4000 [100%]  (Sampling) \n#> Chain 5 finished in 1.0 seconds.\n#> Chain 6 finished in 1.0 seconds.\n#> Chain 4 Iteration: 3200 / 4000 [ 80%]  (Sampling) \n#> Chain 4 Iteration: 3300 / 4000 [ 82%]  (Sampling) \n#> Chain 4 Iteration: 3400 / 4000 [ 85%]  (Sampling) \n#> Chain 4 Iteration: 3500 / 4000 [ 87%]  (Sampling) \n#> Chain 4 Iteration: 3600 / 4000 [ 90%]  (Sampling) \n#> Chain 4 Iteration: 3700 / 4000 [ 92%]  (Sampling) \n#> Chain 4 Iteration: 3800 / 4000 [ 95%]  (Sampling) \n#> Chain 4 Iteration: 3900 / 4000 [ 97%]  (Sampling) \n#> Chain 4 Iteration: 4000 / 4000 [100%]  (Sampling) \n#> Chain 4 finished in 1.1 seconds.\n#> \n#> All 6 chains finished successfully.\n#> Mean chain execution time: 0.9 seconds.\n#> Total execution time: 1.2 seconds.\n```\n:::\n\n\nY sale prácticamente lo mismo \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mbrm_alt)\n#>  Family: poisson \n#>   Links: mu = identity \n#> Formula: y ~ b0 + b1 * (t - change) * step(change - t) + b2 * (t - change) * step(t - change) \n#>          b0 ~ 1\n#>          b1 ~ 1\n#>          b2 ~ 1\n#>          change ~ 1\n#>    Data: df (Number of observations: 23) \n#>   Draws: 6 chains, each with iter = 4000; warmup = 500; thin = 1;\n#>          total post-warmup draws = 21000\n#> \n#> Population-Level Effects: \n#>                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> b0_Intercept        63.38      2.95    56.65    68.65 1.00     5884     4208\n#> b1_Intercept         0.50      0.67    -0.69     1.90 1.00     6690     9219\n#> b2_Intercept        -1.05      0.44    -1.89    -0.25 1.00     7597     5919\n#> change_Intercept  2008.00      2.97  2002.89  2015.02 1.00     5832     4019\n#> \n#> Draws were sampled using sample(hmc). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n\nMe queda pendiente hacerlo con Turing.jl \nSaludos\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}