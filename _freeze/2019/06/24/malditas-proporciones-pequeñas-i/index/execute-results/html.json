{
  "hash": "96c55dc050fe5eded9e96c58dad34ccd",
  "result": {
    "markdown": "---\ntitle: 'Malditas proporciones pequeñas I '\ndate: '2019-06-24'\ncategories:\n  - 2019\n  - estadística\n  - R\ndescription: ''\nexecute: \n  message: false\n  warning: false\n  echo: true\nformat: \n  html: \n    fig-height: 5\n    fig-dpi: 300\n    fig-width: 8.88\n    fig-align: center\nknitr:\n  opts_chunk:\n    out.width: 80%\n    fig.showtext: TRUE\n    collapse: true\n    comment: \"#>\"\n---\n\n\n\n\nCuando uno está en esto de ganarse la vida mediante la ciencia de datos, se da cuenta de que la vida no es tan maravillosa como lo cuentan los libros de texto ni los cursos de los másters y ni siquiera los concursos de kaggle. \n\nRecientemente en un proyecto nos piden detectar un efecto de un incremento del **15%** en una proporción entre dos grupos, digamos en forma canónica, grupo de control y tratamiento.  Hasta aquí todo normal y uno podría hacer calcular intervalos de confianza (o de credibilidad si nos vamos al mundo bayesiano) de manera más o menos fácil. Veamos como sería utilizando simulación.\n\nSupongamos una p1 = 0.5 y una p2 = p1 * 1.16 ( un pelín superior al 15%) Supongamos también que nuestros grupos tienen tamaño n1 = n2 = 100000. Así que vamos a calcular mediante simulación la probabilidad que p2/p1 >= 1.15. ¿Fácil, verdad? \n\np1 y p2 los simulamos suponiendo una distribución beta. Supongamos que p2 es un 16% mayor que p1\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(-1) # prueba a poner una semilla negativa en python a ver que pasa\np1 <- 0.5\np2 <- p1 * 1.16\nn <- 1E5\nsim <- 1E6\n\nsim_beta1 <- rbeta(sim, p1 * n, n - p1 * n)\nsim_beta2 <- rbeta(sim, p2*n, n - p2 * n)\n\nmedian(sim_beta1)\n#> [1] 0.5000039\nmedian(sim_beta2)\n#> [1] 0.5800018\n```\n:::\n\n\nSi dibujamos sus funciones de densidad con R base sin muchas zirigoncias.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(density(sim_beta1), main = \"prop\", col = \"darkblue\", lty = 2, xlim = c(0.45, 0.6))\n\nlines(density(sim_beta2), col = \"darkred\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=80%}\n:::\n:::\n\n\nY claramente si que parece que están separadas. Podemos estimar la probabilidad de que p2 sea un 15% mayor como la proporción de veces que p2/p1 >= 1.15 en el millón de simulaciones\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(sim_beta2/sim_beta1 >= 1.15)\n#> [1] 0.98152\n```\n:::\n\n\nY podríamos estar bastante seguros de que p2 es al menos un 15% mayor que p1. \n\nPero ¿qué pasa si las proporciones son pequeñas, digamos de un 4 por mil?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(-1)\np1 <- 0.004\np2 <- p1 * 1.16\nn <- 1E5\nsim <- 1E6\n\nsim_beta1 <- rbeta(sim, p1 * n, n - p1 * n)\nsim_beta2 <- rbeta(sim, p2*n, n - p2 * n)\n\nmedian(sim_beta1)\n#> [1] 0.003997118\nmedian(sim_beta2)\n#> [1] 0.004636583\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(density(sim_beta1), main = \"prop\", col = \"darkblue\", lty=2, xlim = c(0.003, 0.006)  )\n\nlines(density(sim_beta2), col = \"darkred\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=80%}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(sim_beta2/sim_beta1 >= 1.15)\n#> [1] 0.550476\n```\n:::\n\n\nPues ya no podemos estar tan seguros de que el incremento haya sido de alrededor un 15%.\n\nEn próximas entradas veremos como calcular de forma clásica el tamaño muestral necesario para detectar ese efecto. \n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}