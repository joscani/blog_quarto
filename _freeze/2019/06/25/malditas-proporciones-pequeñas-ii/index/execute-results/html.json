{
  "hash": "945ef82dbbbe4509739599df55f3869f",
  "result": {
    "markdown": "---\ntitle: Malditas proporciones pequeñas II\ndate: '2019-06-25'\ncategories:\n  - 2019\n  - estadística\n  - R\ndescription: ''\nexecute: \n  message: false\n  warning: false\n  echo: true\nformat: \n  html: \n    fig-height: 5\n    fig-dpi: 300\n    fig-width: 8.88\n    fig-align: center\nknitr:\n  opts_chunk:\n    out.width: 80%\n    fig.showtext: TRUE\n    collapse: true\n    comment: \"#>\"\n---\n\n\n¿Cuál sería el tamaño muestral mínimo para estimar un incremento del 15% en una proporción de digamos 0.004? \n\nEn realidad me gustaría hacer como cuenta mi amigo Carlos en este [**post**](https://www.datanalytics.com/2019/06/18/bayes-no-habia-previsto-esto/), pero no puedo ir examinando unidades y actualizar los intervalos de credibilidad hasta que la anchura me convenza, porque ni siquiera conozco al tío de la furgoneta que ha de ir \"examinando\" cada unidad experimental, amén de que para conseguir 4 tiene que examinar cerca de 1000. Así que veamos como se ha hecho toda la vida.\n\nNos interesa es minimizar los errore tipo I y tipo II. Recordemos lo que eran.\n\n- Error tipo I : Error de falso positivo, decir que  hay diferencias\ncuando en realidad no las hay (H0 es cierta pero digo que no)\n- Error tipo II: Error falso negativo, error que cometo al decir que no hay diferencias cuando en realidad si las hay. (H0 es falsa pero decimos que es verdadera)\n8\n![errores](error_tipo1_tipo2_pregnant.jpg)\n\n\nSi utilizamos el paquete de R [`pwr`](https://cran.r-project.org/web/packages/pwr/vignettes/pwr-vignette.html) podemos calcularlo para un error tipo I, (el alpha de siempre) de 0.05 y una potencia (1 - error tipo II) de 0.9\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- 0.004\np2 <- p1 * 1.15\nlibrary(pwr)\n\npotencia_0.9 <- pwr.p.test(ES.h(p1=p1, p2= p2),\n                           sig.level= 0.05, power = 0.9) \nplot(potencia_0.9)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=80%}\n:::\n:::\n\n\nY nos sale que el tamaño de muestra mínimo está en torno a 125 mil . \n\nHay otras librerías para calcular dicho tamaño muestral, por ejemplo \n[`SampleSizeProportions`](https://cran.r-project.org/web/packages/SampleSizeProportions/index.html) que según pone en la documentación lo hace teniendo en cuenta el intervalo de credibilidad deseado. \nTengo que mirar mejor esta librería. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(SampleSizeProportions)\n\nlen <-  (p1 * 1.15 - p1/1.15)\nc1 <- 40\nc2 <- 46\nd1 <- 9960\nd2 <- 9954\n\npropdiff.modwoc(len = len, c1 = c1, d1 = d1, c2 = c2, d2 = d2)\n#> [1] 120910 120910\n```\n:::\n\n\nY sale unos 120 mil para cada grupo.\n\nO también podemos ver cosas como está que comentan los amigos de \nWinVector, [**aquí**](http://www.win-vector.com/blog/2019/06/estimating-rates-using-probability-theory-chalk-talk/) o [**aquí**](http://www.win-vector.com/blog/2013/12/sample-size-and-power-for-rare-events/)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nestimateT <- function(lowProb,difference,errorProb) {\n  -log(errorProb/2)*lowProb/(difference^2)\n}\n\n# detectar diferencias de 15%\nlowProb <- 0.004\nincremento <- 0.15\nestimateT(lowProb, lowProb*incremento,  0.0006 )\n#> [1] 90130.31\n```\n:::\n\n\nY nos sale un tamaño aproximado de 90 mil.  Sea como fuere el tener que determinar tamaños de muestra para poder medir variaciones de un 15% en proporciones pequeñas implica tener muestras de tamaño 100000, así que como dice el título, ¡malditas proporciones pequeñas!\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}