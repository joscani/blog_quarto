{
  "hash": "dd55940bbb8fb4514b8c30967d439f2d",
  "result": {
    "markdown": "---\ntitle: Agua con gas\ndate: '2019-06-07'\ndate-modified: last-modified\ncategories:\n  - h2o\n  - 2019\n  - bigdata\nexecute: \n  message: false\n  warning: false\n  echo: true\nformat: \n  html: \n    fig-height: 5\n    fig-dpi: 300\n    fig-width: 8\n    fig-align: center\nknitr:\n  opts_chunk:\n    out.width: 80%\n    fig.showtext: TRUE\n    collapse: true\n    comment: \"#>\"\n---\n\n\n\nO mejor dicho **[Sparkling Water](https://www.h2o.ai/download/#sparkling-water)** , que es una librería de la buena gente de **[h2o](https://www.h2o.ai/)** que permite aunar el mundo spark con el mundo de h2o. \n\nEn un **[post anterior](https://muestrear-no-es-pecado.netlify.com/2019/03/12/productivizando-modelos-binarios-con-h20/)** ya comentaba cómo poner modelos de h2o en producción en un cluster de spark, pero tengo que rectificar el punto en el que decía que con sparkling water había un cuello de botella al pasar de sparkdataframe a h2oframe, ese cuello ya no es tal, puesto que la **conversión se hace en distribuido**.\n\n## Antecedentes\n\nEn mi corta experiencia en el mundo del big data (2016- actualidad), en todos los sitios por los que paso se me presenta la disyuntiva de cómo pasar modelos a producción.\nYo vengo del mundo de R y otra mucha gente del mundo de python y las soluciones que se nos ocurren son cosas basadas en docker, hacer udf's dentro de spark o cosas así. Otra gente siempre me dice que lo que hay que usar es **[MLlib](https://spark.apache.org/docs/latest/ml-guide.html)** ya sea usando pyspark, sparkr, sparklyr o directamente la API con Scala (no conozco a nadie que use la API de Java), pero seamos honestos, los **modelos implementados en MLlib son una basura**, son lentos, consumen muchos recursos y dan peores resultados que los implementados con R o python por ejemplo. \n\nComo dice el título de este blog \"muestrear no es pecado\" y a la hora de entrenar un modelo prefiero hacer 1000 muestreos aleatorios con reemplazamiento y ver la estabilidad de las predicciones e incluso sacar intervalos de confianza que  cualquier otra cosa.  Pero a todos nos piden implementar nuestros modelos (entrenamiento y predicción) en un **entorno productivo**. \n\n\n## Una posible solución (buena, bonita y barata)\n\nTal y como se cuenta en la comparativa que hace **[Szilard](https://github.com/szilard/benchm-ml)** H2O es más eficiente que R, Python y Spark y con resultados iguales o mejores. \nY un ingeniero me diría, -sí vale, muy bonito, pero yo lo que uso es spark y es lo que tenemos en el entorno de producción y no nos dejan instalar ni R, ni python, ni montar un cluster de h2o en los workers- . Pues aquí es dónde entra `sparkling-water`. \n\nCon Sparkling Water tenemos lo mejor de los dos mundos, **Spark para tratar los datos y h2o para entrenar modelos en distribuido y para predicción**, y lo mejor de todo, podemos utilizar sparkling-water como si fuera una librería más de SPARK e incluirlo dentro de nuestras Apps sin ningún problema, con lo que el paso a producción es tan simple como con cualquier otro proceso de spark. \n\nOtra ventaja es qué h2o y sparkling-water están ampliamente documentados, y por ejemplo **[aquí](http://docs.h2o.ai/sparkling-water/2.3/latest-stable/doc/deployment/deployment.html)** viene información de cómo utilizar en un **EMR de Amazon**, en **Azure** o en **Google Cloud**. Os recomiendo encarecidamente que leáis la docu, es una joya, así como los códigos de ejemplo que tienen en su **[github](https://github.com/h2oai/sparkling-water/tree/master/examples)**\n\nY bueno, después de tanto rollo y que parezco el comercial de la empresa voy a poner un ejemplo de cómo usar sparkling-water en spark con scala. En otro post lo comentaré con R.\n\n\n## Ejemplo con spark-scala\n\nVamos a probar funcionalidad con spark-shell, para construir una app en condiciones una opción sería crear el jar ya sea mediante sbt o con gradle, en un **[post anterior](https://muestrear-no-es-pecado.netlify.com/2019/03/12/productivizando-modelos-binarios-con-h20/)** conté más o menos como era.\n\nLo primero es lanzar el spark-shell añadiendo el **jar correspondiente de sparkling water**, spark ya se encarga de distribuirlo entre los workers.\n\nLa prueba la hago sobre mi portátil aunque todo esto ya está probado sobre un cluster de spark tocho y funciona perfectamente.\nHabría que cambiar el modelo de ejecución a `--master yarn` y elegir más ejecutores y memoria.\n\nLa versión de sparkling-water correspondiente a cada versión de spark se puede consultar **[Aquí](https://github.com/h2oai/sparkling-water/tree/master/r)** Yo voy a utilizar spark 2.4.0 y sparkling-water 2.4.10\n\n**Arrancamos un spark shell en modo local**\n\n```bash\n/home/jose/spark/spark-2.4.0-bin-hadoop2.7/bin/spark-shell \\\n--jars /home/jose/Descargas/sparkling-water-2.4.10/assembly/build/libs/sparkling-water-assembly_2.11-2.4.10-all.jar \\\n--conf \"spark.dynamicAllocation.enabled=false\" \\\n--conf \"spark.scheduler.minRegisteredResourcesRatio=1\"  --executor-memory 7G --executor-cores 2 --num-executors 1 \\\n--name sparkling_water_scala \\\n/\n```\n\n\nPodemos ver el sparkui en `http://127.0.0.1:4040/jobs/`\n\nTodo lo necesario para ejecutar h2o y su enlace con spark está en el jar \n`sparkling-water-assembly_2.11-2.4.10-all.jar` y al añadirlo al lanzar el spark-shell ya podemos utilizar h2o dentro de spark como una librería más.\n\nImportamos librerías (no todas son necesarias)\n\n```scala\nimport org.apache.spark.SparkFiles\nimport org.apache.spark.h2o._\nimport org.apache.spark.examples.h2o._\nimport org.apache.spark.ml.h2o.models._\nimport org.apache.spark.sql.functions._\n\nimport org.apache.spark.sql.{DataFrame, SQLContext}\nimport water.Key\nimport java.io.File\nimport java.net.URI\n\nimport _root_.hex.tree.gbm.GBM\nimport _root_.hex.tree.gbm.GBMModel\nimport _root_.hex.tree.gbm.GBMModel.GBMParameters\nimport _root_.hex.ModelMetricsSupervised\nimport _root_.hex.Model\nimport _root_.hex.ScoreKeeper\n\n//import _root_.hex._\nimport _root_.hex.ModelMetricsBinomial\nimport water.support.{H2OFrameSupport, SparkContextSupport, ModelMetricsSupport}\nimport water.support.SparkContextSupport.addFiles\nimport water.support.H2OFrameSupport._\nimport water.support.ModelSerializationSupport\nimport org.apache.spark.sql.{SaveMode}\n\n\n```\n\n\nLevantamos un `h2ocontext` sobre el `sparkcontext`, lo que hace es levantar un cluster de h2o dentro de spark, sin necesidad de tener que instalar nada en los workers, no R, no python 3. \n\n![backendh2o](internal_backend.png)\n\n```scala\n\nimplicit val sqlContext = spark.sqlContext\nval hc = H2OContext.getOrCreate(sc)\n\nimport hc._\nimport hc.implicits._\nimport sqlContext.implicits._\n\n```\n\nY se nos levanta el flow de h2o en \n\n```scala\nhc.flowURL\nres0: String = http://192.168.1.37:54321\n```\n\nO lo abrimos de esta forma\n\n```scala\nopenFlow\n```\n\nimagen![flow](h2o_flow.png)\n\n\n\n Leemos datos con spark\n \n```scala\n\nval dataPath = \"mtcars.csv\"\n\nval df= spark.read.option(\"header\", \"true\").\noption(\"inferSchema\", \"true\").\ncsv(dataPath)\ndf.show(3,false)\n```\n\n```scala\n+----+---+----+---+----+-----+-----+---+---+----+----+-------------+\n|mpg |cyl|disp|hp |drat|wt   |qsec |vs |am |gear|carb|id           |\n+----+---+----+---+----+-----+-----+---+---+----+----+-------------+\n|21  |6  |160 |110|3.9 |2.62 |16.46|0  |1  |4   |4   |Mazda RX4    |\n|21  |6  |160 |110|3.9 |2.875|17.02|0  |1  |4   |4   |Mazda RX4 Wag|\n|22.8|4  |108 |93 |3.85|2.32 |18.61|1  |1  |4   |1   |Datsun 710   |\n+----+---+----+---+----+-----+-----+---+---+----+----+-------------+\nonly showing top 3 rows\n```\n\nCreamos variable binaria que sea tener 6 cilindros vs 4 u 8\n\n```scala\n\nval df2 = df.withColumn(\"cyl_cat\", when($\"cyl\" === 6 , \"1\").otherwise(\"0\")).drop($\"cyl\")\n\n```\n\n\nConvertimos el sparkdataframe a h2oframe. Esto antes era un cuello de botella pero ahora el paso de sparkdataframe a h2oframe se hace en distribuido y es bastante rápido, incluso con datos de 40 millones de filas y más de 100 columnas\n\n```scala\n\n// convertir a h2oframe\nval trainFrame:H2OFrame = df2\ntrainFrame.names\ntrainFrame.means\n\n```\n\nConvertimos `cyl_cat`, `gear`, `carb` a Categorical, esto se puede hacer en spark previamente convirtiendo a string y luego pasar todos los strings a categorical en h2o con \n`withLockAndUpdate(trainFrame){ allStringVecToCategorical(_) }`\n\n```scala\n\n\nH2OFrameSupport.withLockAndUpdate(trainFrame) { fr =>\n  fr.replace(fr.find(\"gear\"), fr.vec(\"gear\").toCategoricalVec).remove()\n}\n\nH2OFrameSupport.withLockAndUpdate(trainFrame) { fr =>\n  fr.replace(fr.find(\"cyl_cat\"), fr.vec(\"cyl_cat\").toCategoricalVec).remove()\n}\n\nH2OFrameSupport.withLockAndUpdate(trainFrame) { fr =>\n  fr.replace(fr.find(\"carb\"), fr.vec(\"carb\").toCategoricalVec).remove()\n}\n\n\n```\n```scala\nres8: org.apache.spark.h2o.H2OFrame =\nFrame key: frame_rdd_44_864202a286d438fb206334d98079482a\n   cols: 12\n   rows: 32\n chunks: 1\n   size: 4896\n\n```\n\n\nDividimos en traint, test y hold. H2O hace esta tarea bastante mejor que spark\n\n```scala\n\nval keys = Seq[String](\"train.hex\", \"test.hex\", \"hold.hex\")\nval ratios = Seq[Double](0.6, 0.3, 0.1)\nval frs = splitFrame(trainFrame, keys , ratios)\n\nval (train, test, hold) = (frs(0), frs(1), frs(2))\n\n``` \n\nAjustamos un modelo gbm para predecir `cyl_cat`, cambiamos la métrica de early stopping a AUC\n\n```scala \nval ignore_columns = Array[String](\"id\")\nval stopping_metric = ScoreKeeper.StoppingMetric.AUC\n\nval gbmParams = new GBMParameters()\ngbmParams._train = train\ngbmParams._valid = test\n\ngbmParams._response_column = \"cyl_cat\"\ngbmParams._ignored_columns = ignore_columns\ngbmParams._ntrees = 10\ngbmParams._max_depth = 2\ngbmParams._seed = 155\ngbmParams._min_rows = 4\ngbmParams._learn_rate_annealing = 0.9\ngbmParams._col_sample_rate = 0.9\ngbmParams._sample_rate = 0.98\ngbmParams._balance_classes = false\ngbmParams._stopping_metric = stopping_metric \ngbmParams._stopping_rounds = 2\ngbmParams._score_tree_interval = 3\n```\n\n\nEntrenamos, (en la interfaz se puede ver como va avanzando el entrenamiento y las métricas en train y validación)\n\n```scala\nval gbmModel = new GBM(gbmParams).trainModel.get\n\nval holdMetrics =  ModelMetricsSupport.modelMetrics[ModelMetricsBinomial](gbmModel, hold)\n\nprintln(holdMetrics.auc)\n```\n\nEn la interfaz podemos ver todas las métricas, el gainlift, etc.\n\n\n\n\n```scala\nprintln(holdMetrics.gainsLift)\n```\n\n\n\n## Serializar/guardar el modelo\n\n¿Cómo guardamos el modelo? Hay dos formas\n\n* Serializando con `ModelSerializationSupport.exportH2OModel` lo que implica que cuando queramos cargarlo y predecir tenemos que lanzar de nuevo un `spark-shell` o `spark-submit` con el jar de `sparkling-water`\n* Guardarlo como mojo (model object java optimization) tal y como conté en post anterior\n\nAmbas formas de salvarlo se pueden hacer desde la interfaz  y desde las diferentes apis. Voy a contar como sería con la primera\n\nCreamos un uri de dónde vamos a guardarlo, puede ser una ruta de hdfs, el filesystem o incluso un bucket de s3.\n\n```scala\nval destinationURI = URI.create(\"file:///home/jose/mi_modelo\")\n//val uri_mojo = URI.create(\"file:///opt/datos2/jcanadar/modelo_sparkling_mojo.zip\")\nModelSerializationSupport.exportH2OModel(gbmModel, destinationURI)\n\n```\n\nCargar modelo guardado y hacer predicciones\n\n```scala\nval loadedModel: GBMModel = ModelSerializationSupport.loadH2OModel(destinationURI)\n\n```\n\nAl cargarlo ya me da información de las métricas que se obtuvieron con ese modelo\n\n```bash\nval loadedModel: GBMModel = ModelSerializationSupport.loadH2OModel(destinationURI)\nloadedModel: hex.tree.gbm.GBMModel =\nModel Metrics Type: Binomial\n Description: N/A\n model id: GBM_model_1559923164707_105\n frame id: train.hex\n MSE: 0.07837714\n RMSE: 0.27995917\n AUC: 1.0\n pr_auc: 0.0\n logloss: 0.30478087\n mean_per_class_error: 0.0\n default threshold: 0.6001753807067871\n CM: Confusion Matrix (Row labels: Actual class; Column labels: Predicted class):\n         0  1   Error    Rate\n     0  11  0  0,0000  0 / 11\n     1   0  5  0,0000   0 / 5\nTotals  11  5  0,0000  0 / 16\nGains/Lift Table (Avg response rate: 31,25 %, avg score:31,52 %):\n  Group  Cumulative Data Fraction  Lower Threshold      Lift  Cumulative Lift  Response Rate     Score  Cumulative Response Rate  Cumulative Score  Capture Rate  Cumulative Capture Rate         Gain  Cumulative Gain\n      1                ...\n\n```\n\nPara predecir sería tan sencillo como pasar de sparkdataframe a h2oframe como ya hemos visto antes y aplicar un método. \n\n```scala\n// ya tengo un conjunto de datos en formato h2oframe, \n\nval predicciones = loadedModel.score(hold)\n\n```\n\nConvierto a sparkdataframe\n\n```scala\nval predicciones_spark = hc.asDataFrame(predicciones)\npredicciones_spark.show(3, false)\n```\n\n```bash\n+-------+------------------+-------------------+\n|predict|p0                |p1                 |\n+-------+------------------+-------------------+\n|0      |0.6386240026776301|0.3613759973223699 |\n|1      |0.3998245858574603|0.6001754141425397 |\n|0      |0.849842626576839 |0.15015737342316104|\n+-------+------------------+-------------------+\n```\nSalvar a tabla hive \n\n```scala\npredicciones_spark.write.mode(SaveMode.Overwrite).saveAsTable(\"esquema.nombretabla\")\n\n```\n\nOtra cosa interesante es que h2o incorpora explicatividad mediante shap values para los algoritmos de árboles.\n\n```scala\n// hay que crear una clave aleatoria con Key.make para que funcione\nval explain_frame = loadedModel.scoreContributions(hold, Key.make())\nval explain_spark = hc.asDataFrame(explain_frame)\nexplain_spark.show(3,false)\n```\n\nLa suma de todos los términos de la explicatividad da el logit de la probabilidad de tener cyl == 4.\n```scala\n+-------------------+-------------------+---+----+---+----+---+---+----+-------------------+-------------------+\n|mpg                |disp               |hp |drat|wt |qsec|vs |am |gear|carb               |BiasTerm           |\n+-------------------+-------------------+---+----+---+----+---+---+----+-------------------+-------------------+\n|0.06274261325597763|0.7365164756774902 |0  |0   |0  |0   |0  |0  |0   |-0.4328688085079193|-0.9357871413230896|\n|0.17428503930568695|0.8345963358879089 |0  |0   |0  |0   |0  |0  |0   |0.33310189843177795|-0.9357871413230896|\n|-0.2034180760383606|-0.7214104533195496|0  |0   |0  |0   |0  |0  |0   |0.12724840641021729|-0.9357871413230896|\n+-------------------+-------------------+---+----+---+----+---+---+----+-------------------+-------------------+\nonly showing top 3 rows\n\n```\n\nLo único que faltaría para tener este en un entorno de producción sería meterlo en un jar ya sea mediante sbt o con gradle. En un proyecto en la empresa lo hemos probado, y gracias a mi compañero de trabajo y sin embargo amigo [Sergio Calderón](https://www.linkedin.com/in/sergiocalde94/) y a mis queridos ingenazis lo hemos formalizado en un proyecto gradle.\n\nHuelga decir que con esta implementación hemos mejorado espectacularmente el tiempo de entrenamiento y predicción de nuestros modelos obteniendo AUC's similares a los que se obtienen con xgboost y la ventaja de que pasar a producción es muchísimo más sencillo que con otras alternativas\n\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}