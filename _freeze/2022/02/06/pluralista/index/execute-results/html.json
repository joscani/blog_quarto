{
  "hash": "fef92436f40ea4216d0b1e35a9e25105",
  "result": {
    "markdown": "---\ntitle: Pluralista\nauthor: jlcr\ndate: '2022-02-06'\nslug: pluralista\ncategories:\n  - estadística\n  - R\ntags:\n  - análisis bayesiano\n  - causal inference\n  - R\ndescription: ''\ndraft: no\ntopics: []\n\nexecute: \n  message: false\n  warning: false\n  echo: true\nformat: \n  html: \n    fig-height: 5\n    fig-dpi: 300\n    fig-width: 8.88\n    fig-align: center\nknitr:\n  opts_chunk:\n    out.width: 80%\n    fig.showtext: TRUE\n    collapse: true\n    comment: \"#>\"\n---\n\n\n\nAndo viendo los vídeos de Richard McElreath , [Statistical Rethinking 2022](https://github.com/rmcelreath/stat_rethinking_2022) y ciertamente me están gustando mucho. En la segunda edición de su libro hace hincapié en temas de inferencia causal. Cuenta bastante bien todo el tema de los \"confounders\", \"forks\", \"colliders\" y demás. Además lo hace simulando datos, por lo que entiende todo de forma muy sencilla. Un par de conceptos que me han llamado la atención son por ejemplo cuando dice que condicionar por una variable no significa lo mismo en un modelo de regresión al uso que en uno bayesiano, en el segundo caso significa incluir esa variable en la distribución conjunta.  Esto permite por ejemplo que bajo el marco de un modelo bayesiano se pueda condicionar incluso por un \"collider\" cosa que los entendidos de la inferencia causal prohíben expresamente pues eso abre un camino no causal en el DAG definido.\n\n\nSegún la [RAE](https://dle.rae.es/pluralismo) , pluralismo significa \n\n> pluralismo\n1. m. Sistema por el cual se acepta o reconoce la pluralidad de doctrinas o posiciones.\n\ny en los videos se toma dicha postura, por ejemplo, se especifica el modelo teórico utilizando los diagramas causales y el Back door criterio para ver sobre qué variables hay que condicionar o no , para ver el efecto total de X sobre Y o para estimar el efecto directo. \n\n\nHay un ejemplo muy bueno en este [post de Richard](https://elevanth.org/blog/2021/06/29/regression-fire-and-dangerous-things-3-3/).\n\n**Nota**: Este post es simplemente para entender un poco el post de Richard, el mérito es totalmente de él. \n\nBásicamente es una situación dónde se quiere estimar el efecto que tiene sobre el número de hijos que tiene una mujer, el número de hijos que tuvo su madre. En el diagrama causal también se indica la influencia que tiene el orden de nacimiento de de la madre y de la hija. \n\n\nDiagrama causal:\n\n* M: Número de hijos de la madre\n* D: Número de hijos de la hija\n* B1: Orden de nacimiento de la madre\n* B2: Orden de nacimiento de la hija\n* U: Variable no medida en los datos, que pudiera ser cosas como influencia del entorno social y económico dónde viven madre e hija, que influye en las decisión del número de hijos de ambas. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(dagitty)\nlibrary(ggdag)\nlibrary(patchwork)\n\ng <- dagitty(\"dag{ \n  M -> D ;\n  B2 -> D;\n  B1 -> M;\n  U -> M;\n  U -> D\n }\")\n\n\ncoords <-  \n  list(\n  x = c(B1 = 1, M = 2,  U = 3.5, D = 5, B2 = 6),\n  y = c(B1 = 0, M = 0, U = 1, D = 0, B2 = 0)\n)\n\ncoordinates(g) <- coords\n\nggdag(g) + \n  theme_void()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=80%}\n:::\n:::\n\n\nSi queremos estimar el efecto global o el directo de M sobre D, habría que condicionar por U (siguiendo el backdoor criterio), y al ser no observable,  no se puede estimar. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nadjustmentSets(g, exposure = \"M\", outcome = \"D\", effect = \"total\"  )\n#> { U }\nadjustmentSets(g, exposure = \"M\", outcome = \"D\", effect = \"direct\"  )\n#> { U }\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n\nggdag_adjustment_set(g, exposure = \"M\", outcome = \"D\", effect = \"direct\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=80%}\n:::\n:::\n\n\n\n¿Cómo podemos \"estimar\" el efecto de M sobre D dado que no podemos condicionar (en el sentido clásico) sobre U? .\n\n\n\n\nRichard propone lo que el llama \"full luxury bayesian\" que consiste en estimar a la vez todo el DAG y luego generar simulaciones usando la distribución conjunta obtenida para medir el efecto de la \"intervención\" y poder obtener el efecto causal. \n\nNótese que cuando en el DAG las relaciones se pueden expresar como modelos lineales, se puede estimar todo el DAG usando técnicas como los modelos de ecuaciones estructurales o el path analysis.\n\n## Simulación\n\nSimulamos unos datos de forma qué vamos a conocer la \"verdad\" de la relaciones entre variables, que para eso simulamos. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\nset.seed(1908)\nN <- 1000 # número de pares, 1000 madres y 1000 hijas\n\n\nU <- rnorm(N,0,1) # Simulamos el confounder\n\n# orden de nacimiento y \nB1 <- rbinom(N,size=1,prob=0.5)  # 50% de madres nacieeron en primer lugar\nM <- rnorm( N , 2 * B1 + U )\n\nB2 <- rbinom(N,size=1,prob=0.5) # 50% son las primogénitas\nD <- rnorm( N , 2  *B2 + U + 0 * M )\n\n```\n:::\n\n\n\nEn esta simulación se ha forzado que el efecto del número de hijos de la madre sobre el núemro de hijos de la hija sea nulo. Por tanto sabemos que el efecto de M sobre D es 0..\n\nSi hacemos un modelo sin condicionar, tenemos sesgo\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(D ~ M)\n#> \n#> Call:\n#> lm(formula = D ~ M)\n#> \n#> Coefficients:\n#> (Intercept)            M  \n#>      0.7108       0.2930\n```\n:::\n\n\nCondicionando por B1 también, de hecho tenemos la situación de amplificación del sesgo\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(D ~ M + B1)\n#> \n#> Call:\n#> lm(formula = D ~ M + B1)\n#> \n#> Coefficients:\n#> (Intercept)            M           B1  \n#>      1.0356       0.4606      -1.0441\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(D ~ M + B1 +B2 )\n#> \n#> Call:\n#> lm(formula = D ~ M + B1 + B2)\n#> \n#> Coefficients:\n#> (Intercept)            M           B1           B2  \n#>    -0.01621      0.46913     -0.91307      2.01487\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(D ~ M + B2)\n#> \n#> Call:\n#> lm(formula = D ~ M + B2)\n#> \n#> Coefficients:\n#> (Intercept)            M           B2  \n#>     -0.3204       0.3231       2.0550\n```\n:::\n\n\n\nEn esta situación, no podemos estimar el efecto de M sobre D utilizando un solo modelo.\n\nUna forma de estimar el efecto de M sobre D es tirar de path analysis, que en este caso se puede al ser las relaciones lineales. \n\n\nSea: \n\n* b: Efecto de B1 sobre M\n* m: Efecto de M sobre D\n\n\nSe tiene que \n\n$$Cov(B1, D ) = b\\cdot m \\cdot Var(B1)$$\nY como \n\n$$b = \\dfrac{Cov(B1,M)}{Var(B1)} $$\n\n\nPodemos estimar $m$ como \n\n$$m = \\dfrac{Cov(B1,D)}{b \\cdot Var(B1)} = \\dfrac{Cov(B1,D)}{Cov(B1,M)} $$\nY \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(m_hat = cov(B1,D) / cov(B1,M))\n#> [1] -0.0563039\n```\n:::\n\n\ny esta estimación está menos sesgada, antes era del orden de 0.1 o 0.2 y ahora la estimación es del orden 0.01. Pero con esta estimación no tenemos información de su distribución sino sólo de esta estimación puntual. Y si las relaciones no fueran lineales no podría usarse, en cambio la siguiente aproximación si funciona\n\n\n## Full luxury bayes\n\nUtilizamos la librería de Richard `rethinking` y también `cmdstanr` para expresar el modelo causal completo y ajustarlo con Stan.\n\nAhora estimamos el DAG completo,  aquí es dónde es diferente de la aproximación causal de Pearl, de esta forma podemos \"condicionar\" incluso por los colliders, porque condicionar en este marco significa meter esa información dentro de la distribución conjunta. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(cmdstanr)\nlibrary(rethinking)\nset_cmdstan_path(\"~/Descargas/cmdstan/\")\n\n# No metemos U al ser no observable\ndat <- list(\n  N = N,\n  M = M,\n  D = D,\n  B1 = B1,\n  B2 = B2\n)\nset.seed(1908)\n\nflbi <- ulam(\n  alist(\n    # mom model\n    M ~ normal( mu , sigma ),\n    mu <- a1 + b*B1 + k*U[i],\n    # daughter model\n    D ~ normal( nu , tau ),\n    nu <- a2 + b*B2 + m*M + k*U[i],\n    # B1 and B2\n    B1 ~ bernoulli(p),\n    B2 ~ bernoulli(p),\n    # unmeasured confound\n    vector[N]:U ~ normal(0,1),\n    # priors\n    c(a1,a2,b,m) ~ normal( 0 , 0.5 ),\n    c(k,sigma,tau) ~ exponential( 1 ),\n    p ~ beta(2,2)\n  ), data=dat , chains=4 , cores=4 , warmup = 500, iter=2500 , cmdstan=TRUE )\n#> Running MCMC with 4 parallel chains, with 1 thread(s) per chain...\n#> \n#> Chain 1 Iteration:    1 / 2500 [  0%]  (Warmup) \n#> Chain 2 Iteration:    1 / 2500 [  0%]  (Warmup) \n#> Chain 3 Iteration:    1 / 2500 [  0%]  (Warmup) \n#> Chain 4 Iteration:    1 / 2500 [  0%]  (Warmup) \n#> Chain 4 Iteration:  100 / 2500 [  4%]  (Warmup) \n#> Chain 3 Iteration:  100 / 2500 [  4%]  (Warmup) \n#> Chain 1 Iteration:  100 / 2500 [  4%]  (Warmup) \n#> Chain 4 Iteration:  200 / 2500 [  8%]  (Warmup) \n#> Chain 2 Iteration:  100 / 2500 [  4%]  (Warmup) \n#> Chain 3 Iteration:  200 / 2500 [  8%]  (Warmup) \n#> Chain 1 Iteration:  200 / 2500 [  8%]  (Warmup) \n#> Chain 4 Iteration:  300 / 2500 [ 12%]  (Warmup) \n#> Chain 2 Iteration:  200 / 2500 [  8%]  (Warmup) \n#> Chain 4 Iteration:  400 / 2500 [ 16%]  (Warmup) \n#> Chain 1 Iteration:  300 / 2500 [ 12%]  (Warmup) \n#> Chain 3 Iteration:  300 / 2500 [ 12%]  (Warmup) \n#> Chain 1 Iteration:  400 / 2500 [ 16%]  (Warmup) \n#> Chain 2 Iteration:  300 / 2500 [ 12%]  (Warmup) \n#> Chain 3 Iteration:  400 / 2500 [ 16%]  (Warmup) \n#> Chain 4 Iteration:  500 / 2500 [ 20%]  (Warmup) \n#> Chain 4 Iteration:  501 / 2500 [ 20%]  (Sampling) \n#> Chain 2 Iteration:  400 / 2500 [ 16%]  (Warmup) \n#> Chain 1 Iteration:  500 / 2500 [ 20%]  (Warmup) \n#> Chain 1 Iteration:  501 / 2500 [ 20%]  (Sampling) \n#> Chain 3 Iteration:  500 / 2500 [ 20%]  (Warmup) \n#> Chain 3 Iteration:  501 / 2500 [ 20%]  (Sampling) \n#> Chain 4 Iteration:  600 / 2500 [ 24%]  (Sampling) \n#> Chain 2 Iteration:  500 / 2500 [ 20%]  (Warmup) \n#> Chain 2 Iteration:  501 / 2500 [ 20%]  (Sampling) \n#> Chain 3 Iteration:  600 / 2500 [ 24%]  (Sampling) \n#> Chain 4 Iteration:  700 / 2500 [ 28%]  (Sampling) \n#> Chain 1 Iteration:  600 / 2500 [ 24%]  (Sampling) \n#> Chain 2 Iteration:  600 / 2500 [ 24%]  (Sampling) \n#> Chain 4 Iteration:  800 / 2500 [ 32%]  (Sampling) \n#> Chain 1 Iteration:  700 / 2500 [ 28%]  (Sampling) \n#> Chain 3 Iteration:  700 / 2500 [ 28%]  (Sampling) \n#> Chain 2 Iteration:  700 / 2500 [ 28%]  (Sampling) \n#> Chain 4 Iteration:  900 / 2500 [ 36%]  (Sampling) \n#> Chain 1 Iteration:  800 / 2500 [ 32%]  (Sampling) \n#> Chain 3 Iteration:  800 / 2500 [ 32%]  (Sampling) \n#> Chain 2 Iteration:  800 / 2500 [ 32%]  (Sampling) \n#> Chain 4 Iteration: 1000 / 2500 [ 40%]  (Sampling) \n#> Chain 1 Iteration:  900 / 2500 [ 36%]  (Sampling) \n#> Chain 3 Iteration:  900 / 2500 [ 36%]  (Sampling) \n#> Chain 2 Iteration:  900 / 2500 [ 36%]  (Sampling) \n#> Chain 4 Iteration: 1100 / 2500 [ 44%]  (Sampling) \n#> Chain 1 Iteration: 1000 / 2500 [ 40%]  (Sampling) \n#> Chain 3 Iteration: 1000 / 2500 [ 40%]  (Sampling) \n#> Chain 2 Iteration: 1000 / 2500 [ 40%]  (Sampling) \n#> Chain 4 Iteration: 1200 / 2500 [ 48%]  (Sampling) \n#> Chain 1 Iteration: 1100 / 2500 [ 44%]  (Sampling) \n#> Chain 3 Iteration: 1100 / 2500 [ 44%]  (Sampling) \n#> Chain 2 Iteration: 1100 / 2500 [ 44%]  (Sampling) \n#> Chain 4 Iteration: 1300 / 2500 [ 52%]  (Sampling) \n#> Chain 1 Iteration: 1200 / 2500 [ 48%]  (Sampling) \n#> Chain 3 Iteration: 1200 / 2500 [ 48%]  (Sampling) \n#> Chain 2 Iteration: 1200 / 2500 [ 48%]  (Sampling) \n#> Chain 4 Iteration: 1400 / 2500 [ 56%]  (Sampling) \n#> Chain 1 Iteration: 1300 / 2500 [ 52%]  (Sampling) \n#> Chain 3 Iteration: 1300 / 2500 [ 52%]  (Sampling) \n#> Chain 2 Iteration: 1300 / 2500 [ 52%]  (Sampling) \n#> Chain 4 Iteration: 1500 / 2500 [ 60%]  (Sampling) \n#> Chain 1 Iteration: 1400 / 2500 [ 56%]  (Sampling) \n#> Chain 3 Iteration: 1400 / 2500 [ 56%]  (Sampling) \n#> Chain 4 Iteration: 1600 / 2500 [ 64%]  (Sampling) \n#> Chain 1 Iteration: 1500 / 2500 [ 60%]  (Sampling) \n#> Chain 2 Iteration: 1400 / 2500 [ 56%]  (Sampling) \n#> Chain 3 Iteration: 1500 / 2500 [ 60%]  (Sampling) \n#> Chain 4 Iteration: 1700 / 2500 [ 68%]  (Sampling) \n#> Chain 2 Iteration: 1500 / 2500 [ 60%]  (Sampling) \n#> Chain 3 Iteration: 1600 / 2500 [ 64%]  (Sampling) \n#> Chain 1 Iteration: 1600 / 2500 [ 64%]  (Sampling) \n#> Chain 2 Iteration: 1600 / 2500 [ 64%]  (Sampling) \n#> Chain 4 Iteration: 1800 / 2500 [ 72%]  (Sampling) \n#> Chain 1 Iteration: 1700 / 2500 [ 68%]  (Sampling) \n#> Chain 3 Iteration: 1700 / 2500 [ 68%]  (Sampling) \n#> Chain 2 Iteration: 1700 / 2500 [ 68%]  (Sampling) \n#> Chain 4 Iteration: 1900 / 2500 [ 76%]  (Sampling) \n#> Chain 1 Iteration: 1800 / 2500 [ 72%]  (Sampling) \n#> Chain 3 Iteration: 1800 / 2500 [ 72%]  (Sampling) \n#> Chain 4 Iteration: 2000 / 2500 [ 80%]  (Sampling) \n#> Chain 2 Iteration: 1800 / 2500 [ 72%]  (Sampling) \n#> Chain 3 Iteration: 1900 / 2500 [ 76%]  (Sampling) \n#> Chain 1 Iteration: 1900 / 2500 [ 76%]  (Sampling) \n#> Chain 4 Iteration: 2100 / 2500 [ 84%]  (Sampling) \n#> Chain 2 Iteration: 1900 / 2500 [ 76%]  (Sampling) \n#> Chain 3 Iteration: 2000 / 2500 [ 80%]  (Sampling) \n#> Chain 1 Iteration: 2000 / 2500 [ 80%]  (Sampling) \n#> Chain 4 Iteration: 2200 / 2500 [ 88%]  (Sampling) \n#> Chain 2 Iteration: 2000 / 2500 [ 80%]  (Sampling) \n#> Chain 1 Iteration: 2100 / 2500 [ 84%]  (Sampling) \n#> Chain 3 Iteration: 2100 / 2500 [ 84%]  (Sampling) \n#> Chain 4 Iteration: 2300 / 2500 [ 92%]  (Sampling) \n#> Chain 2 Iteration: 2100 / 2500 [ 84%]  (Sampling) \n#> Chain 3 Iteration: 2200 / 2500 [ 88%]  (Sampling) \n#> Chain 1 Iteration: 2200 / 2500 [ 88%]  (Sampling) \n#> Chain 4 Iteration: 2400 / 2500 [ 96%]  (Sampling) \n#> Chain 2 Iteration: 2200 / 2500 [ 88%]  (Sampling) \n#> Chain 3 Iteration: 2300 / 2500 [ 92%]  (Sampling) \n#> Chain 1 Iteration: 2300 / 2500 [ 92%]  (Sampling) \n#> Chain 4 Iteration: 2500 / 2500 [100%]  (Sampling) \n#> Chain 2 Iteration: 2300 / 2500 [ 92%]  (Sampling) \n#> Chain 4 finished in 18.7 seconds.\n#> Chain 3 Iteration: 2400 / 2500 [ 96%]  (Sampling) \n#> Chain 1 Iteration: 2400 / 2500 [ 96%]  (Sampling) \n#> Chain 2 Iteration: 2400 / 2500 [ 96%]  (Sampling) \n#> Chain 3 Iteration: 2500 / 2500 [100%]  (Sampling) \n#> Chain 3 finished in 19.3 seconds.\n#> Chain 1 Iteration: 2500 / 2500 [100%]  (Sampling) \n#> Chain 1 finished in 19.4 seconds.\n#> Chain 2 Iteration: 2500 / 2500 [100%]  (Sampling) \n#> Chain 2 finished in 19.8 seconds.\n#> \n#> All 4 chains finished successfully.\n#> Mean chain execution time: 19.3 seconds.\n#> Total execution time: 19.9 seconds.\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npost <- extract.samples(flbi)\nprecis(flbi)\n#>             mean         sd        5.5%      94.5%      n_eff     Rhat4\n#> m     0.01029393 0.04047150 -0.05430275 0.07409054   890.4789 1.0018319\n#> b     1.98864256 0.05811342  1.89487725 2.08168275  3042.1496 1.0007825\n#> a2    0.02836364 0.07310509 -0.08729441 0.14659932  1335.7564 1.0027553\n#> a1    0.06834714 0.05394291 -0.01785119 0.15621615  3747.6036 1.0007151\n#> tau   0.98041340 0.03617180  0.92352906 1.03914055  2745.6394 1.0007016\n#> sigma 1.07286195 0.05249312  0.98902178 1.15557275   909.1510 1.0015771\n#> k     0.98545837 0.05638324  0.89516212 1.07461055   828.2759 1.0013545\n#> p     0.48012384 0.01111044  0.46233213 0.49808700 16117.4910 0.9996995\n```\n:::\n\n\nVemos que no aparece la estimación de U, pero en la posterior se ha estimado un valor de U para cada uno de las observaciones. 1000 observaciones y \n\n\n::: {.cell}\n\n```{.r .cell-code}\n\ndim(post$U)\n#> [1] 8000 1000\npost$U[1:4, 1:5]\n#>          [,1]       [,2]       [,3]      [,4]        [,5]\n#> [1,] 0.382053 -0.4087260 -1.5231200  0.486262  0.00381229\n#> [2,] 0.733459  0.2971870  0.0441252 -1.424160 -0.98469300\n#> [3,] 0.254011 -0.0201819 -0.7499000 -1.444340 -0.51772400\n#> [4,] 0.468004  0.1923180 -1.8694400 -1.314570 -0.43902700\n```\n:::\n\n\n\n## Efecto de M sobre D. \n\nEste era el efecto que queríamos obtener y el cuál no podíamos estimar al no poder condicionar sobre U. Aquí es tan sencillo como ver su distribución a posteriori. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n\nquantile(post$m)\n#>          0%         25%         50%         75%        100% \n#> -0.14804300 -0.01706778  0.01080760  0.03813360  0.15027000\n\nggplot() +\n  geom_density(aes(post$m)) + \n  labs(title = \"Efecto directo de M sobre D\", \n       x = \"m\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=80%}\n:::\n:::\n\n\n\n\n### Efecto de B1 sobre D\n\n\nComo ya sabíamos, al haber simulado los datos de forma que las relaciones entre las variables sean lineales, el efecto de B1 sobre D  no es más que el efecto de B1 sobre M multiplicado por el efecto de M sobre D. \n\nUtilizando la distribución a posteriori. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Efecto de B1 sobre D \nquantile( with(post,b*m) )\n#>          0%         25%         50%         75%        100% \n#> -0.27728158 -0.03379382  0.02148739  0.07658919  0.30614657\n\nggplot() +\n  geom_density(aes(post$b * post$m))+\n  labs(title = \"Efecto de B1 sobre D\", \n       x = \"b1 x m\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-14-1.png){width=80%}\n:::\n:::\n\n\n### Efecto de B1 sobre D, simulando\n\nTal y como dice en su curso, el efecto causal puede ser visto como hacer una intervención supuesto cierto el modelo causal. \n\nSimplemente utilizamos las posterioris obtenidas y vamos simulando , en primer lugar B1 = 0 y  simulamos qué M se obtendría, y lo hacemos también para B1 = 1 y restamos para obtener el efecto causal, que coindice con `b * m `\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# \n\n# B1 = 0\n# B1 -> M\nM_B1_0 <- with( post , a1 + b*0 + k*0 )\n# M -> D\nD_B1_0 <- with( post , a2 + b*0 + m*M_B1_0 + k*0 )\n\n# now same but with B1 = 1\nM_B1_1 <- with( post , a1 + b*1 + k*0 )\nD_B1_1 <- with( post , a2 + b*0 + m*M_B1_1 + k*0 )\n\n# difference to get causal effect\nd_D_B1 <- D_B1_1 - D_B1_0\nquantile(d_D_B1)\n#>          0%         25%         50%         75%        100% \n#> -0.27728158 -0.03379382  0.02148739  0.07658919  0.30614657\n```\n:::\n\n\nPues como dice el título , ser pluralista no está tan mal, puedes usar el DAG y el backdoor criterio para entender qué variables ha de tener en cuenta para estimar tu efecto causal, y a partir de ahí podrías usar el \"full luxury bayesian\" en situaciones más complicadas. \n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}