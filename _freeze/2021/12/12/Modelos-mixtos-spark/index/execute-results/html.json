{
  "hash": "b9455670813878ad2d5958471c1d5cf9",
  "result": {
    "markdown": "---\ntitle: Modelos mixtos en spark. Intento 1\nauthor: jlcr\ndate: '2021-12-12'\nslug: modelos-mixtos-en-spark-intento-1\ncategories:\n  - estadística\n  - spark\n  - modelos mixtos\n  - 2021\nexecute: \n  message: false\n  warning: false\n  echo: true\nformat: \n  html: \n    fig-height: 5\n    fig-dpi: 300\n    fig-width: 8.88\n    fig-align: center\nknitr:\n  opts_chunk:\n    out.width: 80%\n    fig.showtext: TRUE\n    collapse: true\n    comment: \"#>\"\n---\n\n\nA los que nos dedicamos a esto siempre echamos de menos un `lme4` en `python` o en `Spark`.  En `Julia` afortunadamente tenemos [`MixedModels.jl`](https://juliastats.org/MixedModels.jl/stable/). \n\nTotal que buscando alguna posible solución para poder usar esto en spark me encuentro con dos posibles soluciones. \n\n* [`photon-ml`](https://github.com/linkedin/photon-ml)\n* [`MomentMixedModels`](https://github.com/stitchfix/MomentMixedModels)\n\nAmbos repos llevan un tiempo sin actualizarse así que no sé yo.\n\n`photon-ml` es de linkedin y tiene buena pinta, al menos el tutorial, que tienes que bajarte un docker y tal, funciona. Aunque la sintaxis es rara. Aún tengo que probarlo más y probar a crear el jar del proyecto ya que no está en maven central y tal (y no me funcionó)\n\n> Ejemplo de sintaxis de photon-ml \n\n```scala \n// Define another feature shard for our random effect coordinate, and create a new mapping\n// with both our 'global' and 'perUser' shards.\nval perUserFeatureShardId = \"perUser\"\nval perUserFeatureShard = Set(\"genreFeatures\", \"movieLatentFactorFeatures\")\nval mixedFeatureShardBags = Map(\n    globalFeatureShardId -> globalFeatureShard,\n    perUserFeatureShardId -> perUserFeatureShard)\n\n// Since we have a new shard, re-read the training and validation data into a new DataFrame\n// (and a new index map for the new feature shard).\nval (mixedInputData, mixedFeatureShardInputIndexMaps) = dataReader.readMerged(\n    Seq(\"/data/movielens/trainData.avro\"),\n    mixedFeatureShardBags,\n    numPartitions)\nval mixedValidateData = dataReader.readMerged(\n    Seq(\"/data/movielens/validateData.avro\"),\n    mixedFeatureShardInputIndexMaps,\n    mixedFeatureShardBags,\n    numPartitions)\n\n``` \n\nDonde mixedInputData es un dataframe de spark con esta pinta.\n\n```scala\nmixedInputData.show()\n\n+----+--------+------+-------+------+------+--------------------+--------------------+\n| uid|response|userId|movieId|weight|offset|              global|             perUser|\n+----+--------+------+-------+------+------+--------------------+--------------------+\n|null|     4.0|     1|   1215|  null|  null|(51,[0,1,2,3,4,5,...|(51,[0,1,2,3,4,5,...|\n|null|     3.5|     1|   1350|  null|  null|(51,[0,1,2,3,4,5,...|(51,[0,1,2,3,4,5,...|\n|null|     4.0|     1|   2193|  null|  null|(51,[0,1,2,3,4,5,...|(51,[0,1,2,3,4,5,...|\n|null|     3.5|     1|   3476|  null|  null|(51,[0,1,2,3,4,5,...|(51,[0,1,2,3,4,5,...|\n|null|     5.0|     1|   4993|  null|  null|(51,[0,1,2,3,4,5,...|(51,[0,1,2,3,4,5,...|\n|null|     4.0|     3|   1544|  null|  null|(51,[0,1,2,3,4,5,...|(51,[0,1,2,3,4,5,...|\n|null|     4.0|     7|    440|  null|  null|(51,[0,1,2,3,4,5,...|(51,[0,1,2,3,4,5,...|\n|null|     3.0|     7|    914|  null|  null|(51,[0,1,2,3,4,5,...|(51,[0,1,2,3,4,5,...|\n|null|     3.0|     7|   1894|  null|  null|(51,[0,1,2,3,4,5,...|(51,[0,1,2,3,4,5,...|\n|null|     3.0|     7|   2112|  null|  null|(51,[0,1,2,3,4,5,...|(51,[0,1,2,3,4,5,...|\n|null|     4.0|     7|   3524|  null|  null|(51,[0,1,2,3,4,5,...|(51,[0,1,2,3,4,5,...|\n|null|     4.0|     7|   3911|  null|  null|(51,[0,1,2,3,4,5,...|(51,[0,1,2,3,4,5,...|\n|null|     5.0|    11|    256|  null|  null|(51,[0,1,2,3,4,5,...|(51,[0,1,2,3,4,5,...|\n|null|     5.0|    11|   1200|  null|  null|(51,[0,1,2,3,4,5,...|(51,[0,1,2,3,4,5,...|\n|null|     4.5|    11|  48394|  null|  null|(51,[0,1,2,3,4,5,...|(51,[0,1,2,3,4,5,...|\n|null|     1.0|    11|  56003|  null|  null|(51,[0,1,2,3,4,5,...|(51,[0,1,2,3,4,5,...|\n|null|     0.5|    11|  64508|  null|  null|(51,[0,1,2,3,4,5,...|(51,[0,1,2,3,4,5,...|\n|null|     5.0|    14|    471|  null|  null|(51,[0,1,2,3,4,5,...|(51,[0,1,2,3,4,5,...|\n|null|     3.0|    14|   2018|  null|  null|(51,[0,1,2,3,4,5,...|(51,[0,1,2,3,4,5,...|\n|null|     3.5|    14|   6936|  null|  null|(51,[0,1,2,3,4,5,...|(51,[0,1,2,3,4,5,...|\n\n\n```\n\nDonde las columna global y perUser son iguales, pero una se usa para estimar la parte de los efectos fijos y la otra para los aleatorios. \n\nY luego sigue con \n\n```scala\n// A 'RandomEffectDataConfiguration' requires an identifier field to use for grouping data from the\n// same entity, in addition to the fields that a 'FixedEffectDataConfiguration' requires. It also has\n// some additional optional parameters not covered in this tutorial.\nval perUserRandomEffectId = \"userId\"\nval perUserDataConfig = RandomEffectDataConfiguration(\n    perUserRandomEffectId,\n    perUserFeatureShardId,\n    numPartitions,\n    projectorType = IndexMapProjection)\n\n// A 'RandomEffectOptimizationConfiguration' is defined much like a\n// 'FixedEffectOptimizationConfiguration'. The options below are varied from those above primarily\n// for variety and demonstration.\nval perUserOptimizerConfig = OptimizerConfig(\n    optimizerType = TRON,\n    tolerance = 1e-3,\n    maximumIterations = 4)\nval perUserRegularizationContext = L2RegularizationContext\nval perUserRegularizationWeight = 1\nval perUserOptimizationConfig = RandomEffectOptimizationConfiguration(\n    perUserOptimizerConfig,\n    perUserRegularizationContext,\n    perUserRegularizationWeight)\n\n// Assign a coordinate ID to the random effect configurations we defined above. This time, we have\n// multiple coordinates and need to determine the update sequence. In general, it's recommended to\n// order coordinates from least to most granular, i.e. those that correlate most with the response to\n// those that correlate least.\nval perUserCoordinateId = \"perUser\"\nval mixedCoordinateDataConfigs = Map(\n    globalCoordinateId -> globalDataConfig,\n    perUserCoordinateId -> perUserDataConfig)\nval mixedCoordinateOptConfigs = Map(\n    globalCoordinateId -> globalOptimizationConfig,\n    perUserCoordinateId -> perUserOptimizationConfig)\nval mixedUpdateSequence = Seq(globalCoordinateId, perUserCoordinateId)\n\n// Reset our estimator. The training task hasn't changed, but the data configurations and update\n// sequence have. Furthermore, since there are now multiple coordinates, we should try multiple\n// passes of coordinate descent.\nestimator.setCoordinateDataConfigurations(mixedCoordinateDataConfigs)\nestimator.setCoordinateUpdateSequence(mixedUpdateSequence)\nestimator.setCoordinateDescentIterations(2)\n\n// Train a new model.\nval (mixedModel, _, mixedModelConfig) = estimator.fit(\n    mixedInputData,\n    Some(mixedValidateData),\n    Seq(mixedCoordinateOptConfigs)).head\n\n// Save the trained model.\nModelProcessingUtils.saveGameModelToHDFS(\n    sc,\n    new Path(\"output/mixed\"),\n    mixedModel,\n    trainingTask,\n    mixedModelConfig,\n    None,\n    mixedFeatureShardInputIndexMaps)\n    \n``` \n\nY guarda los coeficientes en `avro`\n\n```bash\n\"avro cat -n 1 ./output/mixed/random-effect/perUser/coefficients/part-00000.avro\" #| \"jq .\" !\n{\n  \"variances\": null,\n  \"means\": [\n    {\n      \"term\": \"Drama\",\n      \"name\": \"Genre\",\n      \"value\": -0.35129547272878503\n    },\n    {\n      \"term\": \"Musical\",\n      \"name\": \"Genre\",\n      \"value\": -0.2967514108349342\n    },\n    {\n      \"term\": \"\",\n      \"name\": \"7\",\n      \"value\": -0.13789947075029355\n    },\n    {\n      \"term\": \"\",\n      \"name\": \"14\",\n      \"value\": -0.13577029316450503\n    },\n    {\n      \"term\": \"\",\n      \"name\": \"8\",\n      \"value\": -0.12850130065314527\n    },\n    {\n      \"term\": \"\",\n      \"name\": \"26\",\n      \"value\": -0.11646520581859549\n    },\n    {\n      \"term\": \"\",\n      \"name\": \"15\",\n      \"value\": -0.09620039918539182\n    },\n    {\n      \"term\": \"\",\n      \"name\": \"6\",\n      \"value\": 0.08934738779979344\n    },\n    {\n      \"term\": \"Comedy\",\n      \"name\": \"Genre\",\n      \"value\": 0.08833383209245319\n    },\n    {\n      \"term\": \"\",\n      \"name\": \"2\",\n      \"value\": -0.08756438537931642\n    },\n\nmore coefficients\n    \"modelClass\": \"com.linkedin.photon.ml.supervised.regression.LinearRegressionModel\",\n  \"lossFunction\": \"\",\n  \"modelId\": \"7\"\n}\n```\n\nLo dicho, no tiene mala pinta y ajusta rápido, me falta probar a crear el jar del proyecto\n\n\nPor otro lado [`MomentMixedModels`](https://github.com/stitchfix/MomentMixedModels/) también parecía prometedora pero al intentar crear el jar con sbt (tampoco está en maven central) peta con `(*:update) sbt.ResolveException: unresolved dependency: com.stitchfix.algorithms.spark#sfs3_2.11;0.7.0-spark2.2.0: not found` y viendo el `build.sbt`  hace referencia a `http://artifactory.vertigo.stitchfix.com/artifactory/releases` que parece que ya no existe, así que mi gozo en un pozo.  La sintaxis parecía sencilla. \n\n```scala\nval linearModelFitter = {\n    new MixedEffectsRegression()\n      .setResponseCol(\"Reaction\")\n      .setFixedEffectCols(Seq(\"Days\"))\n      .setRandomEffectCols(Seq(\"Days\"))\n      .setFamilyParam(\"gaussian\")\n      .setGroupCol(\"Subject\")\n  }\n\n  val linearModel = linearModelFitter.fit(sleepstudyData)\n  println(linearModel.β)\n\n``` \n\nPues nada, a ver si algún ingenazi con alma de analista se digna a hacer una implementación de `lme4` en `Spark` , porque, reconozcámoslo `Spark-ml` es una ñapa. Lo único que medio funciona bien es usar los algoritmos de h2o sobre spark con [`sparkling-water`](https://github.com/h2oai/sparkling-water)  y me falta probar un poco más su implementación de [modelos jerárquicos](https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/glm.html#hierarchical-glm)\n\nHasta otra. \n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}