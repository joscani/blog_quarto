{
  "hash": "19c311f5e02f0e3f00483345d9dd2ef4",
  "result": {
    "markdown": "---\ntitle: Cachitos. Segunda parte\ndate: '2021-01-13'\ncategories:\n  - estadística\n  - polémica\n  - 2021\ndescription: ''\nexecute: \n  message: false\n  warning: false\n  echo: true\nformat: \n  html: \n    fig-height: 5\n    fig-dpi: 300\n    fig-width: 8.88\n    fig-align: center\n    code-fold: show\n    code-summary: \"Mostrar / ocultar código\"\nknitr:\n  opts_chunk:\n    out.width: 80%\n    fig.showtext: TRUE\n    collapse: true\n    comment: \"#>\"\n---\n\n\nEn el [post anterior](https://muestrear-no-es-pecado.netlify.app/2021/01/11/cachitos-primera-parte/) vimos como extraer  1 de cada n fotogramas de un video, recortar una zona en concreto y pasarle un software de reconocimiento óptico de caracteres para tener el texto.  En esta parte vamos a ver como leer esos ficheros de texto y también una de las formas de quitar subtítulos duplicados. Para eso vamos a utilizar R. \nVamos al lío. \n\nEjecuto el script `extract_subtitles.sh` del post anterior de la siguiente forma.\n\n```bash\n./extract_subtitles.sh 2020\n./extract_subtitles.sh 2019\n```\n\nSe baja el video desde alacarta, recorta los subtítulos y obtiene el texto. La estructura de directorios que me crea en dónde le haya dicho que es el `root_directory` es\n\n```bash\n\n╰─ $ ▶ tree -d\n.\n├── 2019_txt\n├── 2020_txt\n└── video\n    ├── 2019_jpg\n    └── 2020_jpg\n\n```\n\nDónde en video tenemos los dos videos en mp4, y los directorios con los fotogramas originales junto con los subtítulos, y en los directorios anno_txt cada uno de los ficheros de texto correspondientes a los fotogramas. \n\n```bash\n╰─ $ ▶ ll 2020_txt | head -n 20\ntotal 5456\ndrwxrwxr-x 2 jose jose 77824 ene 11 20:51 ./\ndrwxrwxr-x 8 jose jose  4096 ene 13 19:41 ../\n-rw-rw-r-- 1 jose jose     1 ene  4 13:07 00000001.jpg.subtitulo.tif.txt\n-rw-rw-r-- 1 jose jose     1 ene  4 13:06 00000002.jpg.subtitulo.tif.txt\n-rw-rw-r-- 1 jose jose     1 ene  4 13:07 00000003.jpg.subtitulo.tif.txt\n-rw-rw-r-- 1 jose jose     1 ene  4 13:08 00000004.jpg.subtitulo.tif.txt\n-rw-rw-r-- 1 jose jose     3 ene  4 13:07 00000005.jpg.subtitulo.tif.txt\n-rw-rw-r-- 1 jose jose     3 ene  4 13:07 00000006.jpg.subtitulo.tif.txt\n-rw-rw-r-- 1 jose jose     3 ene  4 13:07 00000007.jpg.subtitulo.tif.txt\n-rw-rw-r-- 1 jose jose     3 ene  4 13:06 00000008.jpg.subtitulo.tif.txt\n-rw-rw-r-- 1 jose jose     1 ene  4 13:07 00000009.jpg.subtitulo.tif.txt\n-rw-rw-r-- 1 jose jose     3 ene  4 13:08 00000010.jpg.subtitulo.tif.txt\n-rw-rw-r-- 1 jose jose     1 ene  4 13:08 00000011.jpg.subtitulo.tif.txt\n-rw-rw-r-- 1 jose jose     6 ene  4 13:07 00000012.jpg.subtitulo.tif.txt\n-rw-rw-r-- 1 jose jose    24 ene  4 13:06 00000013.jpg.subtitulo.tif.txt\n-rw-rw-r-- 1 jose jose    94 ene  4 13:07 00000014.jpg.subtitulo.tif.txt\n-rw-rw-r-- 1 jose jose    65 ene  4 13:07 00000015.jpg.subtitulo.tif.txt\n-rw-rw-r-- 1 jose jose    93 ene  4 13:06 00000016.jpg.subtitulo.tif.txt\n-rw-rw-r-- 1 jose jose     1 ene  4 13:06 00000017.jpg.subtitulo.tif.txt\n\n\n╰─ $ ▶ ll 2020_txt | wc -l\n1347\n\n\n```\nY vemos que hay 1347 ficheros txt, y algunos muy pequeños (los que no tienen texto)\n\nVeamos el `00000016.jpg.subtitulo.tif.txt`\n\n```bash\n╰─ $ ▶ cat 2020_txt/00000016.jpg.subtitulo.tif.txt\nViendo la actitud del público, más que una actuación\nesto es una sesión de coaching.\n```\n\nPues vamos a leerlos todos usando R. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nroot_directory = \"/media/hd1/canadasreche@gmail.com/public/proyecto_cachitos/\"\nanno <- \"2020\"\n\n# Construims un data frame con los nombrs de los ficheros \n\nnombre_ficheros <- list.files(path = str_glue(\"{root_directory}{anno}_txt/\")) %>% \n    enframe() %>% \n    rename(n_fichero = value)\n\nnombre_ficheros\n#> # A tibble: 1,344 × 2\n#>     name n_fichero                     \n#>    <int> <chr>                         \n#>  1     1 00000001.jpg.subtitulo.tif.txt\n#>  2     2 00000002.jpg.subtitulo.tif.txt\n#>  3     3 00000003.jpg.subtitulo.tif.txt\n#>  4     4 00000004.jpg.subtitulo.tif.txt\n#>  5     5 00000005.jpg.subtitulo.tif.txt\n#>  6     6 00000006.jpg.subtitulo.tif.txt\n#>  7     7 00000007.jpg.subtitulo.tif.txt\n#>  8     8 00000008.jpg.subtitulo.tif.txt\n#>  9     9 00000009.jpg.subtitulo.tif.txt\n#> 10    10 00000010.jpg.subtitulo.tif.txt\n#> # … with 1,334 more rows\n```\n:::\n\n\nAhora los podemos leer en orden\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsubtitulos <-  list.files(path = str_glue(\"{root_directory}{anno}_txt/\"), \n                        pattern = \"*.txt\", full.names = TRUE) %>% \n    map(~read_file(.)) %>% \n    enframe() %>%  \n  # hacemos el join con el dataframe anterior para tener el nombre del fichero original\n    left_join(nombre_ficheros)\n\nglimpse(subtitulos)\n#> Rows: 1,344\n#> Columns: 3\n#> $ name      <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n#> $ value     <list> \"\\f\", \"\\f\", \"\\f\", \"\\f\", \" \\n\\f\", \" \\n\\f\", \" \\n\\f\", \" \\n\\f\",…\n#> $ n_fichero <chr> \"00000001.jpg.subtitulo.tif.txt\", \"00000002.jpg.subtitulo.ti…\nsubtitulos\n#> # A tibble: 1,344 × 3\n#>     name value     n_fichero                     \n#>    <int> <list>    <chr>                         \n#>  1     1 <chr [1]> 00000001.jpg.subtitulo.tif.txt\n#>  2     2 <chr [1]> 00000002.jpg.subtitulo.tif.txt\n#>  3     3 <chr [1]> 00000003.jpg.subtitulo.tif.txt\n#>  4     4 <chr [1]> 00000004.jpg.subtitulo.tif.txt\n#>  5     5 <chr [1]> 00000005.jpg.subtitulo.tif.txt\n#>  6     6 <chr [1]> 00000006.jpg.subtitulo.tif.txt\n#>  7     7 <chr [1]> 00000007.jpg.subtitulo.tif.txt\n#>  8     8 <chr [1]> 00000008.jpg.subtitulo.tif.txt\n#>  9     9 <chr [1]> 00000009.jpg.subtitulo.tif.txt\n#> 10    10 <chr [1]> 00000010.jpg.subtitulo.tif.txt\n#> # … with 1,334 more rows\n```\n:::\n\nen n_fichero tenemos el nombre y en value el texto\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\nsubtitulos %>% \n  pull(value) %>%\n  ## usamos `[[` que es el operador para acceder a la lista el que normalemente se usa [[nombre_elemento]]\n  `[[`(16)\n#> [1] \"Viendo la actitud del público, más que una actuación\\nesto es una sesión de coaching.\\n\\n \\n\\f\"\n\n# equivalentemente\n\n# subtitulos %>% \n#     pull(value) %>% \n#     pluck(16)\n\n```\n:::\n\n\nComo sabemos que hay muchos ficheros sin texto podemos contar letras. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsubtitulos <- subtitulos %>% \n    mutate(n_caracteres = nchar(value)) \n\nsubtitulos %>% \n    group_by(n_caracteres) %>% \n    count()\n#> # A tibble: 127 × 2\n#> # Groups:   n_caracteres [127]\n#>    n_caracteres     n\n#>           <int> <int>\n#>  1            1   480\n#>  2            3   125\n#>  3            4    17\n#>  4            5     7\n#>  5            6    13\n#>  6            7     2\n#>  7            8     7\n#>  8            9     6\n#>  9           10     4\n#> 10           11     5\n#> # … with 117 more rows\n\nsubtitulos %>% \n    group_by(n_caracteres) %>% \n    count() %>% \n  ggplot(aes(x = n_caracteres, y = n)) +\n  geom_col()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=80%}\n:::\n:::\n\n\nY vemos que hay muchos subtitulos con pocos caracteres. Si vemos por ejemplo los que tienen 8 caracteres\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsubtitulos %>% \n    filter(n_caracteres ==8) %>% \n    pull(value)\n#> [[1]]\n#> [1] \"LEN As\\n\\f\"\n#> \n#> [[2]]\n#> [1] \"pro\\n\\nÑ\\n\\f\"\n#> \n#> [[3]]\n#> [1] \"ñ Xd a\\n\\f\"\n#> \n#> [[4]]\n#> [1] \"/ EI\\nE\\n\\f\"\n#> \n#> [[5]]\n#> [1] \"TOY ES\\n\\f\"\n#> \n#> [[6]]\n#> [1] \"110\\n\\ny\\n\\f\"\n#> \n#> [[7]]\n#> [1] \"steria\\n\\f\"\n```\n:::\n\n\nQue se corresponden con haber pillado parte no del subtítulo sino del nombre de la actuación\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsubtitulos %>% \n    filter(n_caracteres ==8)\n#> # A tibble: 7 × 4\n#>    name value     n_fichero                      n_caracteres\n#>   <int> <list>    <chr>                                 <int>\n#> 1   207 <chr [1]> 00000207.jpg.subtitulo.tif.txt            8\n#> 2   252 <chr [1]> 00000252.jpg.subtitulo.tif.txt            8\n#> 3   321 <chr [1]> 00000321.jpg.subtitulo.tif.txt            8\n#> 4   339 <chr [1]> 00000339.jpg.subtitulo.tif.txt            8\n#> 5   442 <chr [1]> 00000442.jpg.subtitulo.tif.txt            8\n#> 6   494 <chr [1]> 00000494.jpg.subtitulo.tif.txt            8\n#> 7   722 <chr [1]> 00000722.jpg.subtitulo.tif.txt            8\n```\n:::\n\n\nUsando la librería `magick` en R que permite usar `imagemagick` en R, ver **[post](https://analisisydecision.es/tratamiento-y-procesado-de-imagenes-con-r-y-magick/)** de Raúl Vaquerizo y su homenaje a Sean Connery, podemos ver el fotgrama correspondiente\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(magick)\n(directorio_imagenes <- str_glue(\"{root_directory}video/{anno}_jpg/\"))\n#> /media/hd1/canadasreche@gmail.com/public/proyecto_cachitos/video/2020_jpg/\n\nimage_read(str_glue(\"{directorio_imagenes}00000207.jpg\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=80%}\n:::\n:::\n\n\nTambién podemos ver hasta cuando pasa eso, por ejemplo si vemos subtítulos con 18 caracteres\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsubtitulos %>% \n    filter(n_caracteres ==18) %>% \n    pull(value)\n#> [[1]]\n#> [1] \" \\n\\nA BAEZA\\n\\n ———\\n\\f\"\n#> \n#> [[2]]\n#> [1] \"Descanse en Pau.\\n\\f\"\n#> \n#> [[3]]\n#> [1] \"VEL y BIMBA BOSÉ\\n\\f\"\n#> \n#> [[4]]\n#> [1] \"IIS >>\\n\\npd.\\ndd >\\n\\f\"\n```\n:::\n\n\nVemos que también pasa, pero ya vamos pillando rótulos de verdad como el \"Descanse en Pau\" que pusieron ante una actuación de Pau Donés. \n\nComo vemos hay que hacer limpieza, pero por el momento vamos a quedarnos con  los subtítulos con número de caracteres mayor de 17. Esta decisión hace que perdamos algunos subtítulos de verdad, como por ejemplo el conocido \"Loco Vox\". \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsubtitulos <- subtitulos %>% \n    filter(n_caracteres > 17) \n\nglimpse(subtitulos)\n#> Rows: 664\n#> Columns: 4\n#> $ name         <int> 13, 14, 15, 16, 19, 20, 21, 22, 25, 26, 27, 31, 32, 33, 3…\n#> $ value        <list> \" \\n\\nA BAEZA\\n\\n ———\\n\\f\", \"Después del añito que hemos…\n#> $ n_fichero    <chr> \"00000013.jpg.subtitulo.tif.txt\", \"00000014.jpg.subtitulo…\n#> $ n_caracteres <int> 18, 92, 62, 89, 50, 112, 114, 114, 31, 91, 78, 117, 98, 9…\n```\n:::\n\n\nPues ya hemos pasado de más de 1000 rótulos a 664. Pero sabemos, por el post anterior que hay algunos duplicados. \n\nCon el fin de detectar cuáles están duplicados y aprovechando que están en orden de aparición, podemos hacer utilizar distancias de texto para calcular la distancia de cada subtítulo con el anterior, y si la distancia es pequeña es que es el mismo rótulo. \n\nPrimero hacemos una minilimpieza. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nstring_mini_clean <-  function(string){\n    string <- gsub(\"?\\n|\\n\", \" \", string)\n    string <- gsub(\"\\r|?\\f|=\", \" \", string)\n    string <- gsub('“|”|—|>',\" \", string)\n    \n    string <- gsub(\"[[:punct:][:blank:]]+\", \" \", string)\n    string <- tolower(string)\n    string <- gsub(\"  \", \" \", string)\n    string <-  \n    \n    return(string)\n}\n\n# Haciendo uso de programacion funciona con purrr es muy fácil pasar esta función a cada elemento. y decirle que # el reultado es string con map_chr\n\nsubtitulos_proces <- subtitulos %>% \n    mutate(texto = map_chr(value, string_mini_clean)) %>% \n    select(-value)\n\nsubtitulos_proces %>% \n  select(texto)\n#> # A tibble: 664 × 1\n#>    texto                                                                        \n#>    <chr>                                                                        \n#>  1 \" a baeza \"                                                                  \n#>  2 \"después del añito que hemos pasado quien mm aman 110 se consuela es porque …\n#>  3 \"viendo la actitud del público más que una actuación esto es \"               \n#>  4 \"viendo la actitud del público más que una actuación esto es una sesión de c…\n#>  5 \" intura y su conjunto conga del jaruco 2 \"                                  \n#>  6 \"la última vez que hiciste algo parecido fue en el súper y llevabas 25 rollo…\n#>  7 \" a que produce nostalgia ver a un grupo de españoles p poniéndose de acuerd…\n#>  8 \" a que produce nostalgia ver a un grupo de españoles poniéndose de acuerdo …\n#>  9 \"jno lomas xte conmigo pi \"                                                  \n#> 10 \"í 7 igual lo que nos ha caído es una maldición india rel y este es el orige…\n#> # … with 654 more rows\n```\n:::\n\n\nY ya vemos a simple vista que hay algun duplicado. Calculemos ahora la distancia de strings, utilizando la función `stringdist` de la librería del mismo nombre.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\nsubtitulos_proces %>% \n    mutate(texto_anterior = lag(texto)) %>% \n    # calculamos distancias con método lcs (que no me he leído que hace exactamente)\n    mutate(distancia = stringdist::stringdist(texto, texto_anterior, method = \"lcs\")) %>% \n  # veamos algunos elementos\n    filter(distancia < 10) %>% \n    arrange(desc(distancia) ) %>% \n    select(texto, texto_anterior, distancia) %>% \n    head()\n#> # A tibble: 6 × 3\n#>   texto                                                          texto…¹ dista…²\n#>   <chr>                                                          <chr>     <dbl>\n#> 1 \"mn por si no te lo ha dicho aún tu cuñado 98 6 se considerab… \"a si …       9\n#> 2 \"por alguna razón a beyoncé le sale bastante mejor el truco d… \" zz p…       6\n#> 3 \"asi es como se visten los daft punk lr ey para teletrabajar \" \"asi e…       6\n#> 4 \"la pandemia interrumpió su gira de 40 aniversario pasas carl… \"la pa…       6\n#> 5 \"2 xl en viajes al pasado los 80 con nostalgia de los 50 yy c… \"2 xl …       6\n#> 6 \"lp parece que a nek le ha pillado despistado 3 el cachito an… \"parec…       6\n#> # … with abbreviated variable names ¹​texto_anterior, ²​distancia\n```\n:::\n\n\nY parece que funciona. \nAsí que decido quitar las filas dónde la distancia  sea menos que 19  y así eliminar muchos de los duplicados. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsubtitulos_proces <- subtitulos_proces %>% \n    mutate(texto_anterior = lag(texto)) %>% \n    mutate(distancia = stringdist::stringdist(texto, texto_anterior, method = \"lcs\")) %>% \n    filter(distancia > 19) %>% \n    select(-texto_anterior)\n\nsubtitulos_proces %>% \n  head()\n#> # A tibble: 6 × 5\n#>    name n_fichero                      n_caracteres texto                dista…¹\n#>   <int> <chr>                                 <int> <chr>                  <dbl>\n#> 1    14 00000014.jpg.subtitulo.tif.txt           92 \"después del añito …      84\n#> 2    15 00000015.jpg.subtitulo.tif.txt           62 \"viendo la actitud …      89\n#> 3    16 00000016.jpg.subtitulo.tif.txt           89 \"viendo la actitud …      23\n#> 4    19 00000019.jpg.subtitulo.tif.txt           50 \" intura y su conju…      76\n#> 5    20 00000020.jpg.subtitulo.tif.txt          112 \"la última vez que …     103\n#> 6    21 00000021.jpg.subtitulo.tif.txt          114 \" a que produce nos…     128\n#> # … with abbreviated variable name ¹​distancia\n```\n:::\n\n\nY ahora escribimos este dataframe en un csv y será la materia prima para ver qué podemos hacer con esto (para eso requeriré ayuda de algún amigo más ducho en tales artes)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_csv(subtitulos_proces,\n          file = str_glue(\"{root_directory}{anno}_txt_unido.csv\"))\n```\n:::\n\n\n\nY os dejo este csv en este [enlace](https://drive.google.com/file/d/1lWbl1M39NfgGsLfEjZeg8XsyfuqsTrFS/view?usp=sharing) \n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}