{
  "hash": "a3f8d70279622ff1a7fca60cff9ae533",
  "result": {
    "markdown": "---\ntitle: ' Cachitos. Primera parte'\ndate: '2021-01-11'\ncategories:\n  - estadística\n  - linux\n  - polémica\n  - ocr\n  - 2021\ndescription: ''\nexecute: \n  message: false\n  warning: false\n  echo: true\nformat: \n  html: \n    fig-height: 5\n    fig-dpi: 300\n    fig-width: 8.88\n    fig-align: center\n    code-fold: show\n    code-summary: \"Mostrar / ocultar código\"\nknitr:\n  opts_chunk:\n    out.width: 80%\n    fig.showtext: TRUE\n    collapse: true\n    comment: \"#>\"\n---\n\n\nEn las ya pasadas navidades se generó algo de polémica con el especial de cachitos nochevieja. Qué si los rótulos se metían mucho con la oposición, el rey y ciudadanos y muy poco con el gobierno. Así que me entró la curiosidad y pensé, ¿por qué no analizar los rótulos del cachitos nochevieja de 2020 y de paso del 2019? Pues me pusé manos a la obra. \nLo primero de todo, dar las gracias a [Raúl Vaquerizo](https://analisisydecision.es/) y a [Carlos Gil Bellosta](https://www.datanalytics.com/) por darme consejos y pasarme el enlace al blog de [Waldo Jaquith](https://waldo.jaquith.org/blog/2011/02/ocr-video/) en el que se basa esta primera entrada. \n\nEsta primera parte va a consistir en varios pasos\n\n* Bajar el video del especial cachitos nochevieja \n* Extraer fotogramas con subtítulos (imagemagick)\n* Recortar los subtítulos (imagemagick)\n* Reconocimiento óptico de caracteres (tesseract)\n\nLo primero que tenemos que hacer es conseguir los vídeos de cachitos de 2019 y de 2020. Para el primero podemos encontrarlo en youtube, pero el segundo no estaba (al menos en el momento en que hice todo esto).  Si está en youtube se puede descargar usando [youtube-dl](https://youtube-dl.org/https://youtube-dl.org/), pero cómo eso lo contará Raúl en uno de sus próximos post me voy a centrar en como descargar el cachitos 2020 desde la [web oficial ](https://www.rtve.es/alacarta/). \n\nPara eso, una vez que ya hemos encontrado el programa que queremos, tenemos que ir a inspeccionar código , sección XHR, filtar por mp4 y darle al play para así poder identificar a qué Url hace request y ver exactamente la dirección de dónde está alojado el mp4. Mejor pongo una imagen\n\n![imagen](cachitos_2020.png)\n\n\nDel request Url anterior, nos quedamos con la dirección hasta el `.mp4` y ya podemos bajarlo. \nAntes de nada, para todo el proceso aconsejor usar un SO unix -friendly. En el caso de linux es importante instalar por consola imagemagick, mplayer, parallel y tesseract. \n\nNos bajamos el video con \n\n```bash\n    wget http://mediavod-lvlt.rtve.es/resources/TE_GLUCA/mp4/2/4/1609487028742.mp4\n    mv 1609487028742.mp4 2020_cachitos.mp4\n\n```\n\nUna vez ya tenemos el video tenemos que decidir cuántos fotogramas extraer para pillar los subtítulos, viendo que los subtítulos duran entre 5 y 10 segundos , podríamos extraer un fotograma cada 220. Yo he decidido extraer uno cada 200 para ilustrar posteriormente como con análisis de texto podemos identificar los rótulos duplicados y también para que no se me escape ni un sólo subtítulo. \n\nVamos a utilizar `mplayer` para extraer 1/200 fotogramas a formato jpg. \n\n```bash\nmplayer -vf framestep=200 -framedrop -nosound 2020_cachitos.mp4 -speed 100 -vo jpeg:outdir=2020_jpg \n```\n\nY después de un rato (tengo que probar si hacerlo con ffmpeg es más rápido), tenemos unos 1300 jpg. Hemos resumido 3 horas de video en 1300 imágenes. \nPongo un ejemplo.  \n\n![imagen](00000186_original_size)\n\nPara ahorrar espacio reescalamos la imagen usando `mogrify` de `imagemagick` . Y aquí ya empezamos a usar `parallel` para hacer el proceso en paralelo. \n\n```bash\ncd 2020_jpg\n# Uso los 6 cores físicos de mi portátil\n# con {} le decimos que nos ponga el mismo nombre al fichero resultante, sustituyendo\n# al anterior\nfind . -name '*.jpg' |  parallel -j 6 mogrify -resize 642x480 {}\n```\n\nY el resultado es una imagen más pequeña\n\n![](00000186.jpg)\n\nAl extraer uno de cada 200 frames, muchas veces extraemos fotogramas sin rótulos y otras (las menos) el mismo rótulo 2 veces. \n![](00000187.jpg)\n\n\nPara extraer sólo el rótulo hay que utilizar la herramienta `crop` también de `imagemagick` dónde le decimos la resolución de la imagen resultante y la coordenada x e y de la imagen de 642x480 original dónde empieza el corte.  Aquí tuve que hacer bastantes pruebas hasta identificar la posición de los subtítulos, dado que el cuadro dónde aparecen es de tamaño variable. \n\nEn este caso decimos que nos cree ficheros tif que tengan el mismo nombr que el original y le añada el sufijo .subtitulo.tif. Por ejemplo tendremos ficheros con este patrón `00000186.jpg.subtitulo.tif` \n\n```bash\n# en paralelo de nuevo\nfind . -name '*.jpg' |  parallel -j 6 convert {} -crop 460x50+90+295 +repage -compress none -depth 8 {}.subtitulo.tif\n```\n\n![](00000186.jpg.subtitulo.png)\n\nCómo me comentaba ayer alguien por twitter, tesseract es un poco \"tiquismiquis\", así que para facilitarle el trabajo \"negativizamos\" las imágenes.\n\n\n```bash\nfind . -name '*.tif' |  parallel -j 6 convert {} -negate -fx '.8*r+.8*g+0*b' -compress none -depth 8 {}\n```\n\n![](00000187.jpg.subtitulo.png)\n\nY ahora utilizamos [tesseract](https://github.com/tesseract-ocr/tesseract) para extraer el texto de estas imágenes. Recomiendo instalar tesseract con los modelos para el idioma español para que lo haga mejor (pille tildes y eñes). En ubuntu y derivados lo instalamos con apt\n\n```bash\nsudo apt-get install tesseract-ocr tesseract-ocr-spa\n```\n\nYo estoy usando la versión 4.1.1, la cual dicen en su github que utiliza modelos LSTM para mejorar el reconocimiento de texto. Sea como fuere, para extraer el texto  sería con \n\n```bash\nfind . -name '*.tif' |  parallel -j 6 tesseract -l spa {} {}\n```\n\ny nos generaría un fichero txt por cada una de las imágenes .subtitulo.tif . La mayoría de esos txt no tienen texto (muchos fotogramas no tienen rótulo). Veamos cómo lo ha hecho con el fichero `00000186.jpg.subtitulo.tif.txt`\n\n```bash\n\n╰─ $ ▶ cat 00000186.jpg.subtitulo.tif.txt \nNuestro “We Are The World” cantado para el mundo\nen el mismo inglés que hablaba Emilio Botín\n\n```\n\nPues al menos en este caso funciona bastante bien. En las siguientes entradas comentaremos brevemente como podríamos analizar los subtítulos. \n\nCon estos pasos hemos conseguido extraer el texto de los subtítulos de unas 3 horas de vídeo, evidentemente si los subtítulos estuvieran en una pista srt dentro del mp4 no habría sido necesario todo esto. Este tipo de análisis hecho enteramente en bash es fácilmente escalable y se puede utilizar por ejemplo para identificar matrículas o similar. \n\n\nOs dejo también un script `extract_subtitles.sh` que le pasas como argumento el año , 2020 o 2019 y te baja el video, te extrae los fotogramas, hace el ocr y te deja los ficheros de texto en un directorio. \n\nSaludos.\n\n\n```bash\n#!/bin/bash\n\nroot_directory=/home/jose/proyecto_cachitos\nmkdir -p $root_directory\ncd $root_directory\n\necho \"First arg: $1\"\nmkdir -p video\n\ncd video\n\nANNO=$1\necho $ANNO\nsuffix_video=\"_cachitos.mp4\"\nsuffix_jpg_dir=\"_jpg\"\nsuffix_txt_dir=\"_txt\"\n\nvideo_file=$ANNO$suffix_video\necho $video_file\n \nif [ \"$ANNO\" == \"2020\" ] ;\nthen\n    wget http://mediavod-lvlt.rtve.es/resources/TE_GLUCA/mp4/2/4/1609487028742.mp4\n    mv 1609487028742.mp4 $video_file\nfi\n\nif [ \"$ANNO\" == \"2019\" ] ;\nthen\n    wget https://rtvehlsvod2020a-fsly.vod-rtve.cross-media.es/resources/TE_GLUCA/mp4/0/9/1577860099590.mp4\n    mv 1577860099590.mp4 $video_file\nfi\n\n# Pasar a jpg uno de cada 220 fotogramas\n\nmplayer -vf framestep=200 -framedrop -nosound $video_file -speed 100 -vo jpeg:outdir=$ANNO$suffix_jpg_dir \n \ncd $ANNO$suffix_jpg_dir \n \n# Convertir a formato más pequño\nfind . -name '*.jpg' |  parallel -j 6 mogrify -resize 642x480 {}\n\n# Seleccionar cacho dond estan subtitulos\nfind . -name '*.jpg' |  parallel -j 6 convert {} -crop 460x50+90+295 +repage -compress none -depth 8 {}.subtitulo.tif\n\n# Poner en negativo para que el ocr funcione mejor\nfind . -name '*.tif' |  parallel -j 6 convert {} -negate -fx '.8*r+.8*g+0*b' -compress none -depth 8 {}\n\n# Pasar el ocr con idioma en español\nfind . -name '*.tif' |  parallel -j 6 tesseract -l spa {} {}\n\n# mover a directorio texto\nmkdir -p $root_directory/$ANNO$suffix_txt_dir\n\nmv *.txt $root_directory/$ANNO$suffix_txt_dir\n\ncd $root_directory\n\n```\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}