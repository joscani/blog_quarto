{
  "hash": "b109a39665155ee0fd185f3ae601bf20",
  "result": {
    "markdown": "---\ntitle: Los viejos [R]ockeros. model.matrix\nauthor: jlcr\ndate: '2021-09-10'\nslug: los-viejos-r-ockeros-model-matrix\ncategories:\n  - R\n  - python\n  - causal inference\n  - 2021\n\n---\n\n\n\n\n\nNota: He cambiado la parte final para que hiciera lo mismo que el código de python, gracias a mi tocayo José Luis Hidalgo \n\nEl otro día por linkedin, mi jefe compartió el siguiente [artículo](https://www.kausa.ai/blog/how-causal-inference-lifts-augmented-analytics-beyond-flatland#5b4e41206487) recomendable por otro lado. El repo con el código y datos está [aquí](https://github.com/kausa-ai/blog/tree/master/how_causal_inference_lifts_augmented_analytics_beyond_flatland). \n\nEn el artículo hacen referencia a que una forma de ver el CATE (Conditional Average Treatmen Effect) cuando hay variables categóricas puede ser construirse los términos de interacción de alto orden entre las variables categóricas y calcular la diferencia entre la media de la variable de interés antes del tratamiento y después del tratamiento, en cada una de las variables de interacción consideradas. \n\nPara eso el autor del artículo hace lo siguiente\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport pandas as pd\nimport datetime as dt\nimport numpy as np\nimport itertools\nimport time\nfrom copy import copy\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ndf = pd.read_csv(\"https://raw.githubusercontent.com/kausa-ai/blog/master/how_causal_inference_lifts_augmented_analytics_beyond_flatland/dataset/ecommerce_sample.csv\")\n\nkpi_axis = 'order_value'\ntime_axis = 'time'\n\ndf[time_axis] = pd.to_datetime(df[time_axis],format = '%d/%m/%Y')\ndf.head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        time       system  ... customer_age  customer_country\n0 2019-09-08       win-pc  ...        21-24            france\n1 2019-09-08  android-mob  ...        21-24            poland\n2 2019-09-08  android-mob  ...        18-21            france\n3 2019-09-08      ios-mob  ...        30-35           germany\n4 2019-09-08   android-tv  ...        18-21            poland\n\n[5 rows x 9 columns]\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ndf.columns\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nIndex(['time', 'system', 'product_category', 'order_value', 'household_income',\n       'first_order_made', 'gender', 'customer_age', 'customer_country'],\n      dtype='object')\n```\n:::\n:::\n\n\n\n\nY crea una función para crear las interacciones de orden n. \n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ndef binarize(df,cols,kpi_axis,time_axis,order):\n    cols = cols.drop([kpi_axis,time_axis]) \n    features = []\n    for k in range(0,order):\n        features.append(cols)\n    fs = []\n    for f in itertools.product(*features):\n      #  list(set(f)).sort()\n        f = np.unique(f)\n        fs.append(tuple(f))\n    fs = tuple(set(i for i in fs))\n    for f in fs:\n        states =[]\n        for d in f:\n            states.append(tuple(set(df[d].astype('category'))))\n        for state in itertools.product(*states):\n            z = 1\n            name = str()\n            for d in range(0,len(f)):\n                z = z*df[f[d]]==state[d]\n                name +=  f[d] + \" == \" +str(state[d])\n                if d<len(f)-1:\n                   name += \" AND \"\n            df[name] = z\n    for d in cols:\n        df = df.drop([d],axis = 1)\n    return df\n```\n:::\n\n\nY crea las variables, al medir cuánta tarda vemos que es en torno al minuto.\n\n\n::: {.cell}\n\n```{.python .cell-code}\nstart_time = time.time()\ndf = binarize(df,df.columns,kpi_axis,time_axis,3)\nelapsed_time = time.time() - start_time\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nprint(elapsed_time/60)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1.0172961990038554\n```\n:::\n\n```{.python .cell-code}\ndf.head(20)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         time  order_value  ...  customer_age == 46+  customer_age == 36-45\n0  2019-09-08        52.03  ...                False                  False\n1  2019-09-08        30.21  ...                False                  False\n2  2019-09-08        55.15  ...                False                  False\n3  2019-09-08        50.00  ...                False                  False\n4  2019-09-08        71.80  ...                False                  False\n5  2019-09-08        60.31  ...                False                  False\n6  2019-09-08        51.94  ...                False                  False\n7  2019-09-08       144.58  ...                False                  False\n8  2019-09-08        47.79  ...                False                  False\n9  2019-09-08        36.27  ...                False                  False\n10 2019-09-08        57.49  ...                False                   True\n11 2019-09-08        65.43  ...                False                  False\n12 2019-09-08        34.47  ...                False                   True\n13 2019-09-08        35.83  ...                False                  False\n14 2019-09-08       122.96  ...                False                   True\n15 2019-09-08       108.20  ...                False                  False\n16 2019-09-08        57.94  ...                 True                  False\n17 2019-09-08        33.60  ...                 True                  False\n18 2019-09-08        41.48  ...                False                  False\n19 2019-09-08        45.48  ...                False                  False\n\n[20 rows x 2719 columns]\n```\n:::\n:::\n\n\n\nY aquí es dónde vienen los viejos [R]ockeros. Cada vez que oigo hablar de interacciones pienso en R y en nuestras queridas fórmulas. \nEn R podemos hacer lo mismo tirando de nuestro viejo amigo `model.matrix` \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# puedo pasar de python a R con \n# df <-  py$df \n# o leer el csv igual \n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(collapse) # for fast calculation\ndf <- readr::read_csv(\"https://raw.githubusercontent.com/kausa-ai/blog/master/how_causal_inference_lifts_augmented_analytics_beyond_flatland/dataset/ecommerce_sample.csv\")\n```\n:::\n\n\nConvertimos las variables que nos interesan a tipo factor\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- df %>% \n  mutate(time = time %>% as.character %>% dmy) %>%  \n  mutate(corte_fecha = if_else(time <= '2019-09-11', \"antes\", \"despues\" )) %>% \n  mutate_if(is.character,as.factor) \n\n\nfeatures <- setdiff(colnames(df),c(\"time\",\"order_value\", \"corte_fecha\"))\nglimpse(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 100,000\nColumns: 10\n$ time             <date> 2019-09-08, 2019-09-08, 2019-09-08, 2019-09-08, 2019…\n$ system           <fct> win-pc, android-mob, android-mob, ios-mob, android-tv…\n$ product_category <fct> household, electronics, electronics, electronics, ele…\n$ order_value      <dbl> 52.03, 30.21, 55.15, 50.00, 71.80, 60.31, 51.94, 144.…\n$ household_income <fct> medium, low, low, low, low, medium, medium, medium, l…\n$ first_order_made <fct> no, no, no, yes, no, no, no, no, no, yes, no, no, yes…\n$ gender           <fct> male, female, female, n.a., n.a., n.a., n.a., n.a., m…\n$ customer_age     <fct> 21-24, 21-24, 18-21, 30-35, 18-21, 30-35, 30-35, 30-3…\n$ customer_country <fct> france, poland, france, germany, poland, france, fran…\n$ corte_fecha      <fct> antes, antes, antes, antes, antes, antes, antes, ante…\n```\n:::\n:::\n\n\nY al utilizar model matrix R hace por defecto codificación parcial de las variables (One Hot quitando la que sobra para los modernos), así que para tener lo mismo hay que tocar un argumento de model matrix. el truco es definir para cada variable el contrasts = FALSE. Por ejemplo\n\nPor defecto el contrasts para una variable categórica elimina la categoría redundante.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrasts(df$product_category) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                    electronics household sports and outdoors\nbooks                         0         0                   0\nelectronics                   1         0                   0\nhousehold                     0         1                   0\nsports and outdoors           0         0                   1\n```\n:::\n:::\n\n\nPero podemos decir que no, y así nos construirá tantas variables dicotómicas como categorías tenga nuestra variable. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ncontrasts(df$product_category, contrasts = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                    books electronics household sports and outdoors\nbooks                   1           0         0                   0\nelectronics             0           1         0                   0\nhousehold               0           0         1                   0\nsports and outdoors     0           0         0                   1\n```\n:::\n:::\n\nYa podemos crear nuestra función `binarize` \n\nPara crear interacciones de orden n en R basta con definir la fórmula  `~ 0 + ( var1 + var2 + var3)^n `  \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbinarize <- function(df, columns, order = 3) {\n  \n  # creo formula  uniendo por + las variables y luego la interación del orden deseado\n  features_unidas <- paste(features, collapse = \" + \")\n\n  formula_orden <- as.formula(paste0(\"~ 0 + (  \", features_unidas, \")^ \", order))\n  \n  # con model.matrix me creo el dataframe con los términos de interacción \n  df_variables <- as_tibble(model.matrix(\n    formula_orden,\n    df,\n    # aqui está la clave \n    contrasts.arg = lapply(df[, features], contrasts, contrasts = FALSE)\n  ))\n\n  df_final <- bind_cols(\n    df %>%\n      select(time, order_value, corte_fecha),\n    df_variables\n  )\n\n\n  df_final <- df_final %>%\n    select(-time) %>%\n    select(corte_fecha, order_value, everything())\n}\n```\n:::\n\n\nY podemos medir cuanto tarda nuestra función sobre el mismo conjunto de datos. Y vemos, que en crear las variables tarda unos pocos segundos. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntictoc::tic()\ndf_final <- binarize(df, features, 3)\ntictoc::toc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n2.482 sec elapsed\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(df_final, 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 2,719\n   corte_fecha order_v…¹ syste…² syste…³ syste…⁴ syste…⁵ syste…⁶ produ…⁷ produ…⁸\n   <fct>           <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 antes            52.0       0       0       0       0       1       0       0\n 2 antes            30.2       1       0       0       0       0       0       1\n 3 antes            55.2       1       0       0       0       0       0       1\n 4 antes            50         0       0       1       0       0       0       1\n 5 antes            71.8       0       1       0       0       0       0       1\n 6 antes            60.3       0       0       0       1       0       0       0\n 7 antes            51.9       0       0       1       0       0       0       0\n 8 antes           145.        1       0       0       0       0       0       1\n 9 antes            47.8       0       1       0       0       0       0       0\n10 antes            36.3       0       0       0       0       1       1       0\n# … with 2,710 more variables: product_categoryhousehold <dbl>,\n#   `product_categorysports and outdoors` <dbl>, household_incomehigh <dbl>,\n#   household_incomelow <dbl>, household_incomemedium <dbl>,\n#   first_order_madeno <dbl>, first_order_madeyes <dbl>, genderfemale <dbl>,\n#   gendermale <dbl>, gendern.a. <dbl>, `customer_age18-21` <dbl>,\n#   `customer_age21-24` <dbl>, `customer_age25-30` <dbl>,\n#   `customer_age30-35` <dbl>, `customer_age36-45` <dbl>, …\n```\n:::\n:::\n\n\nY ya estaría . \n\n## CATE\n\nLa parte interesante del artículo es la de calcular el CATE como la diferencia de medias  de la variable `order_value` en cada uno de los segmentos antes de una determinada fecha y después. \n\nEn el artículo lo hacen así\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\nstart_time = time.time()\n\ndf_before = df[df[time_axis] <= '2019-09-11']\ndf_after  = df[df[time_axis] > '2019-09-11']\nfeatures = copy(df.drop([time_axis,kpi_axis], axis=1).columns)\n\nK = 10 \nsubgroups=[]\nscore=[]\nfor k in range(0,K):\n    CATE = []\n    y_before = df_before[kpi_axis]\n    y_after= df_after[kpi_axis]\n    \n    #compute CATEs for all subgroups\n    for d in features:\n        g = df_before[d] == True\n        m_before = np.mean(y_before[g])\n        g = df_after[d] == True\n        m_after = np.mean(y_after[g])\n        CATE.append(m_after-m_before)\n    \n    #find subgroup with biggest CATE\n    index = np.argsort(-abs(np.array(CATE)))\n    subgroups.append(features[index[0]])\n    score.append(abs( CATE [index[0]]))\n    \n    #remove found subgroups from dataset\n    df_before = df_before[df_before[features[index[0]]] == False]\n    df_after = df_after[df_after[features[index[0]]] == False] \n    features = features.drop(features[index[0]])\n    \n\ndf_nuevo = pd.DataFrame(np.array([score,subgroups]).T, columns=['CATE','features'])\n\nelapsed_time = time.time() - start_time\n\nprint(elapsed_time)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n39.18984651565552\n```\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ndf_nuevo\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 CATE                                           features\n0   289.4008630608073  customer_age == 46+ AND first_order_made == ye...\n1   8.979524530417706  customer_age == 30-35 AND customer_country == ...\n2   8.690151515151513  customer_age == 36-45 AND customer_country == ...\n3   8.567118700265269  customer_age == 36-45 AND customer_country == ...\n4   7.811875000000015  customer_age == 30-35 AND customer_country == ...\n5   7.510393162393143  customer_age == 36-45 AND customer_country == ...\n6    8.40514915254235  customer_age == 36-45 AND customer_country == ...\n7   7.597928321678324  customer_age == 36-45 AND customer_country == ...\n8  7.4170337760987906  customer_age == 46+ AND customer_country == ca...\n9  7.2043861024033475  customer_age == 21-24 AND customer_country == ...\n```\n:::\n:::\n\n\nY tarda su ratillo, pero no está mal\n\nEn R lo podemos hacer utilizando nuestro viejo amigo el R base para poner las condiciones\n\n\n::: {.cell}\n\n```{.r .cell-code}\nCalcularCate_old <-  function(f, df){\n  \n  filtro_antes   = df[[f]] == 1 & df$corte_fecha == \"antes\"\n  filtro_despues = df[[f]] == 1 & df$corte_fecha != \"antes\"\n  \n  media_antes   = mean(df$order_value[filtro_antes])\n  media_despues = mean(df$order_value[filtro_despues])\n  \n  cate = media_despues - media_antes\n  \n  return(cate)\n  \n  \n}\n\n# usando fmean de collapse\n\nCalcularCate <-  function(f, df){\n  \n  filtro_antes   = df[[f]] == 1 & df$corte_fecha == \"antes\"\n  filtro_despues = df[[f]] == 1 & df$corte_fecha != \"antes\"\n  \n  media_antes   = fmean(df$order_value[filtro_antes])\n  media_despues = fmean(df$order_value[filtro_despues])\n  \n  cate = media_despues - media_antes\n  \n  return(cate)\n  \n  \n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntictoc::tic()\nK = 10\ncate = c()\ntmp <-  df_final\n\nfor ( k in 1:K) {\n  \n  features <- colnames(tmp)[3:ncol(tmp)]\n  res <-  unlist(lapply(features, function(x) CalcularCate(x, df = tmp)))\n  names(res) <- features\n  ordenado <-  sort(abs(res), decreasing = TRUE)[1]\n  f <-  names(ordenado)\n  cate <- c(cate, ordenado)\n  tmp <-  tmp[tmp[[f]]== 0, c(\"corte_fecha\", \"order_value\", setdiff(features, f))]\n}\n\n \n \ntictoc::toc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n40.084 sec elapsed\n```\n:::\n\n```{.r .cell-code}\ncate\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              systemandroid-tv:first_order_madeyes:customer_age46+ \n                                                        289.400863 \n                systemios-mob:customer_age30-35:customer_countryuk \n                                                          8.979525 \n     household_incomelow:customer_age36-45:customer_countrygermany \n                                                          8.690152 \n            systemwin-pc:customer_age36-45:customer_countrygermany \n                                                          8.567119 \n     household_incomehigh:customer_age30-35:customer_countrycanada \n                                                          7.811875 \n   product_categorybooks:customer_age36-45:customer_countrygermany \n                                                          7.510393 \n        systemandroid-tv:customer_age36-45:customer_countrygermany \n                                                          8.405149 \n            genderfemale:customer_age36-45:customer_countrygermany \n                                                          7.597928 \nproduct_categoryelectronics:customer_age46+:customer_countrycanada \n                                                          7.417034 \n                 systemios-pc:customer_age21-24:customer_countryuk \n                                                          7.204386 \n```\n:::\n:::\n\n\n\n\nY bueno, parece que en este caso, los viejos [R]ockeros no lo hacen mal del todo, sobre todo la parte de model.matrix es muy rápida, y usando `collapse` para calcular la media es aún más rápido\n\nEn resumen, model.matrix de rbase es muy rápido, y usar fmean de collapse en vez del mean de R-base mejor, con lo que con esta implementación en R es mucho más rápida que la vista en python (que seguramente se puede mejorar hasta igualar)\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}