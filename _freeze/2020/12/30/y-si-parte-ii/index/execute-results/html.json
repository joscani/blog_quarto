{
  "hash": "005338429e668aa0f6633801609a978a",
  "result": {
    "markdown": "---\ntitle: ¿Y si ... ? Parte II\ndate: '2020-12-30'\ncategories:\n  - estadística\n  - causal inference\n  - 2020\ndescription: ''\nexecute: \n  message: false\n  warning: false\n  echo: true\nformat: \n  html: \n    fig-height: 5\n    fig-dpi: 300\n    fig-width: 8.88\n    fig-align: center\n    code-fold: show\n    code-summary: \"Mostrar / ocultar código\"\nknitr:\n  opts_chunk:\n    out.width: 80%\n    fig.showtext: TRUE\n    collapse: true\n    comment: \"#>\"\n---\n\n\n\n\n\nVolvamos a nuestro [ejemplo tonto](https://muestrear-no-es-pecado.netlify.app/2020/11/15/y-si-parte-i/), dónde habíamos visto que el T-learner cuando el modelo base es un modelo lineal equivale a tener un modelo saturado (con interacciones). \n\nEn estos de los \"metalearners\" tenemos entre otros, los T-learners vistos en el post anterior , los S-learner y los X-learners.\n\nLos S-learners no es más que usar un solo modelo \"Single\" para estimar el Conditional Average Treatment Effect , CATE. \n\nUsando el mismo ejemplo sencillo, se tiene que. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(155)\n\nX <- rnorm(100, 10,1)\nW <- rbinom(100, 1, 0.6)\n\n# Me construyo la Y de forma que haya efectos principales e interacción\nY <- 4 + 2 * X + 2 * W + 2 * W * X + rnorm(100, 0, sd = 2)\n\ndf <- as.data.frame(cbind(Y,W,X))\n\ndf\n#>            Y W         X\n#> 1   48.78438 1 10.800067\n#> 2   25.28644 0 10.707605\n#> 3   28.39538 0  9.925625\n#> 4   47.60225 1 10.652555\n#> 5   46.72225 1  9.992698\n#> 6   55.15008 1 11.514759\n#> 7   40.46547 1  9.093717\n#> 8   22.17879 0  9.157972\n#> 9   49.44883 1  9.866499\n#> 10  51.21602 1 11.100414\n#> 11  46.90193 1 10.287350\n#> 12  22.88517 0  9.295653\n#> 13  39.44776 1  9.156142\n#> 14  40.78560 1  8.513496\n#> 15  48.04199 1 10.067613\n#> 16  47.80314 1  9.898276\n#> 17  25.33331 0 10.578513\n#> 18  24.15651 0  9.253759\n#> 19  25.13304 0 10.365123\n#> 20  25.23243 0 11.040849\n#> 21  30.45260 0 12.869587\n#> 22  44.82112 1  9.319895\n#> 23  25.11998 0  9.830254\n#> 24  19.99574 0  9.635928\n#> 25  43.48504 1  9.215349\n#> 26  41.14271 1  8.356523\n#> 27  22.81061 0  8.883480\n#> 28  25.58288 0  9.784855\n#> 29  44.41997 1  9.404844\n#> 30  27.84046 0 10.414529\n#> 31  39.59324 1  9.041776\n#> 32  51.28215 1 10.442391\n#> 33  38.53548 1  8.142158\n#> 34  21.95668 0  9.042216\n#> 35  46.84521 1  9.724798\n#> 36  43.87810 1  9.013322\n#> 37  42.12536 1  9.633154\n#> 38  45.74959 1 10.873450\n#> 39  18.78703 0  9.748465\n#> 40  21.79664 0 10.607739\n#> 41  37.35355 1  8.361663\n#> 42  22.53808 0 10.303852\n#> 43  42.48434 1  9.004360\n#> 44  49.39156 1 10.580300\n#> 45  47.92040 1 10.672659\n#> 46  48.76256 1 11.773249\n#> 47  23.67107 0  9.875302\n#> 48  48.76949 1  9.921954\n#> 49  41.39283 1  8.920843\n#> 50  42.49853 1  8.688555\n#> 51  48.09462 1 10.564605\n#> 52  44.45942 1  9.194570\n#> 53  45.84477 1  9.438857\n#> 54  41.94149 1  9.888696\n#> 55  47.26368 1  9.887931\n#> 56  51.42203 1 11.055223\n#> 57  39.17177 1  8.327467\n#> 58  51.15275 1 10.320770\n#> 59  50.40525 1 10.585048\n#> 60  42.49727 1  9.336601\n#> 61  28.05959 0 10.952144\n#> 62  49.10409 1 10.562264\n#> 63  27.15474 0 12.045244\n#> 64  19.24901 0  8.091111\n#> 65  47.67471 1 10.241636\n#> 66  24.39380 0 10.824896\n#> 67  26.49221 0 10.812256\n#> 68  38.77565 1  8.358974\n#> 69  45.05843 1  9.515578\n#> 70  52.28683 1 11.800317\n#> 71  23.36347 0  9.797133\n#> 72  26.84582 0 10.470713\n#> 73  42.10340 1  9.598281\n#> 74  39.43318 1  8.326351\n#> 75  44.69754 1  9.965926\n#> 76  48.71043 1 10.870054\n#> 77  24.30603 0  9.038770\n#> 78  24.54690 0 11.097281\n#> 79  22.08450 0 10.558284\n#> 80  51.71144 1 11.264590\n#> 81  53.69442 1 11.434979\n#> 82  26.79476 0 12.390173\n#> 83  40.80879 1  9.520336\n#> 84  43.63049 1 10.081028\n#> 85  20.06392 0  8.716013\n#> 86  41.11569 1  8.556393\n#> 87  24.45452 0  9.109263\n#> 88  24.05505 0 10.779678\n#> 89  41.82733 1  9.990715\n#> 90  53.17613 1 11.501511\n#> 91  49.50179 1 11.061493\n#> 92  20.42382 0  7.543992\n#> 93  41.57695 1  8.856854\n#> 94  50.83502 1 11.004920\n#> 95  41.66118 1  9.274137\n#> 96  47.30987 1 10.771928\n#> 97  20.74180 0  9.829798\n#> 98  24.39354 0 10.412418\n#> 99  53.71654 1 11.506078\n#> 100 51.22245 1 10.711256\n```\n:::\n\n\n### S-learner\n\nEl S-learner sería estimar un sólo modelo y ver la diferencia (en esperanzas) en lo que estima el modelo para cuando W=1 versus lo que estima cuando W=0. \n\n$E[Y=y | W=1, X=x] - E[Y=y | W=0, X=x]$\n\nSi hacemos un modelo lineal en este ejemplo, cabe plantearse dos, uno con la interacción\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_saturado <-  lm(Y ~ W *X , data = df)\nsummary(mod_saturado)\n#> \n#> Call:\n#> lm(formula = Y ~ W * X, data = df)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -4.6786 -1.2138  0.1903  1.5419  4.6289 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)   6.9118     3.1354   2.204   0.0299 *  \n#> W            -1.8395     4.0511  -0.454   0.6508    \n#> X             1.6981     0.3085   5.504 3.08e-07 ***\n#> W:X           2.4096     0.4016   6.000 3.49e-08 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 2.011 on 96 degrees of freedom\n#> Multiple R-squared:  0.9689,\tAdjusted R-squared:  0.9679 \n#> F-statistic: 995.9 on 3 and 96 DF,  p-value: < 2.2e-16\n```\n:::\n\n\nDónde la estimación CATE para un caso con X=14. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_w0 <- data.frame(X = 14, W=0)\ndf_w1 <- data.frame(X = 14, W=1)\n\npredict(mod_saturado, df_w1) - predict(mod_saturado, df_w0)\n#>        1 \n#> 31.89504\n```\n:::\n\n\nQue es lo mismo que haber considerado solo los coeficientes cuando W = 1\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\n(cate1 <- coef(mod_saturado)[2] + coef(mod_saturado)[4] * 14 )\n#>        W \n#> 31.89504\n```\n:::\n\n\nEsto ya lo habíamos visto en el post anterior. El tema es que hemos elegido como modelo base el modelo saturado pero podríamos haber elegido otro. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_efectos_ppal <- lm(Y ~ W  + X , data = df)\npredict(mod_efectos_ppal, df_w1) - predict(mod_efectos_ppal, df_w0)\n#>        1 \n#> 22.33547\n```\n:::\n\nY el CATE en este caso está subestimado ya que no hemos tenido en cuenta la interacción (que existe por construcción del efecto).\n\nPodríamos haber elegido otro modelo, y obtener otra estimación del CATE. Usando un árbol por ejemplo, o en caso de tener más variables, cualquier modelo que se os ocurra. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rpart)\n\nmod_arbol <-  rpart(Y ~ W  + X , data = df)\npredict(mod_arbol, df_w1) - predict(mod_arbol, df_w0)\n#>        1 \n#> 27.88051\n```\n:::\n\n\nTotal, que el S-learner es eso, usar un sólo modelo y obtener la diferencia entre lo que estima para cuando W = 1 y cuando W = 0. \n\n### X-learner\n\nLos X-learner es una forma un poco más inteligente de usar los T-learners.  Básicamente se trata de.\n\n* Estimamos dos modelos, uno con los datos cuando W=0 y otro cuando W=1.  Los notamos por \n\n$$\\hat{\\mu}_{0} = M_{1}(Y^0 \\sim X^0)$$\ny por \n$$\\hat{\\mu}_{1} = M_{2}(Y^1 \\sim X^1)$$\n\n\n* Ahora usamos esos modelos de la siguiente forma, para las observaciones que tengan W=0 utilizamos el modelo  $\\hat{\\mu}_{1}$,  y para las observaciones con W=1 usamos  el modelo que se ha estimado usando la otra parte de los datos  $\\hat{\\mu}_{0}$. \n\n* Calculamos para cada observación con W=0 la diferencia entre lo observado y lo estimado por el modelo $\\hat{\\mu}_{1}$ y lo mismo para las observaciones con W=1. Así tenemos.\n\n$$D_{i}^{0} = \\hat{\\mu}_{1}(X_{i}^{0})- Y_{i}^{0} $$\ny \n$$D_{i}^{1} = Y_{i}^{1} - \\hat{\\mu}_{0}(X_{i}^{0})$$\n\n* Volvemos a usar lo del T-learner pero esta vez sobre las diferencias obtenidas en el paso anterior\n\n$$\\hat{\\tau}_1 = M_{3}(D^1 \\sim X^1) $$\n$$\\hat{\\tau}_0 = M_{4}(D^0 \\sim X^0) $$\n\n* Hacemos una combinación convexa para obtener \n\n$$\\hat{\\tau}(x) = ps(x)\\hat{\\tau}_0(x) + (1- ps(x))\\hat{\\tau}_1(x) $$\nDónde $ps(x) \\in [0,1]$ es una función de pesos con ciertas propiedades, normalmente se suele usar el propensity score,  que básicamente es la estimación de la probabilidad de que cada observación pertenezca al tratamiento vs al control. \n\nY en nuestro ejemplo como sería. \n\n**Modelos 1 y 2** usando como modelos base un árbol por ejemplo. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- rpart(Y ~  X , data = df, subset = (W==0))\nm2 <- rpart(Y ~ X , data = df, subset = (W==1))\n```\n:::\n\n\n**Diferencias**\n\nUsamos modelo 1 para estimar cuando W=1 y el modelo 2 para estimar cuando W = 0\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Con el viejo R-base sería \ndf$Difer[df$W==1] <- df$Y[df$W==1] - predict(m1, df[df$W==1, ])\nhead(df)\n#>          Y W         X    Difer\n#> 1 48.78438 1 10.800067 22.14350\n#> 2 25.28644 0 10.707605       NA\n#> 3 28.39538 0  9.925625       NA\n#> 4 47.60225 1 10.652555 22.79507\n#> 5 46.72225 1  9.992698 21.91507\n#> 6 55.15008 1 11.514759 28.50920\n```\n:::\n\n\nY ahora para W=0\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf$Difer[df$W==0] <-  predict(m2, df[df$W==0, ]) - df$Y[df$W==0] \nhead(df)\n#>          Y W         X    Difer\n#> 1 48.78438 1 10.800067 22.14350\n#> 2 25.28644 0 10.707605 23.69278\n#> 3 28.39538 0  9.925625 17.87909\n#> 4 47.60225 1 10.652555 22.79507\n#> 5 46.72225 1  9.992698 21.91507\n#> 6 55.15008 1 11.514759 28.50920\n```\n:::\n\n\n**Modelamos las diferencias**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm3 <- rpart(Difer ~  X , data = df, subset = (W==1))\nm4 <- rpart(Difer ~ X , data = df, subset = (W==0))\n```\n:::\n\n\n**Combinamos**\n\nModelo para propensity score\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm1 <- glm(W ~ X, data = df, family=binomial)\ndf$pesos <- predict(glm1, df, type = \"response\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf$combinado <- df$pesos * predict(m4, df) + (1-df$pesos) * predict(m3, df) \n\nhead(df[, c(\"Y\", \"W\", \"pesos\", \"combinado\")])\n#>          Y W     pesos combinado\n#> 1 48.78438 1 0.6087519  24.38836\n#> 2 25.28644 0 0.6124915  24.39265\n#> 3 28.39538 0 0.6435533  22.05802\n#> 4 47.60225 1 0.6147118  24.39520\n#> 5 46.72225 1 0.6409317  22.05217\n#> 6 55.15008 1 0.5794443  25.32695\n```\n:::\n\n\nLa estimación del CATE para nuestra nueva x sería\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_nueva_x <- data.frame(X = 14)\n\npredict(glm1, df_nueva_x, type=\"response\") * predict(m4, df_nueva_x) + (1-predict(glm1, df_nueva_x, type=\"response\"))* predict(m3, df_nueva_x) \n#>        1 \n#> 25.44921\n```\n:::\n\n\nEste ejemplo es muy sencillo, y supongo que habría que verlo con muchas más variables y utilizando modelos base más complejos. \n\nNo obstante, todo esto de los metalearners no tiene mucho sentido si el grado de solape entre la distribución de las X en el tratamiento y el control no es suficiente, cosa que se intenta arreglar un poco utilizando los propensity scores en el X-learner.\n\n## Extra, uso de causalml\n\nEn la librería causalml de Uber vienen implmentandos los metalearner entre otras cosas. \nUsando el mismo ejemplo veamos como se calcularía el CATE. \n\nNota: He sido incapaz de ver como predecir para mi nueva x, no hay o no he encontrado que funcione un método `predict` para aplicar el X learner a unos nuevos datos. \n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom causalml.inference.meta import BaseXRegressor\n#> The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\nfrom sklearn.linear_model import LinearRegression\n# llamamos al df que está en R\ndf_python = r.df[['Y','W','X','pesos']]\ndf_python\n#>             Y    W          X     pesos\n#> 0   48.784384  1.0  10.800067  0.608752\n#> 1   25.286438  0.0  10.707605  0.612492\n#> 2   28.395375  0.0   9.925625  0.643553\n#> 3   47.602247  1.0  10.652555  0.614712\n#> 4   46.722247  1.0   9.992698  0.640932\n#> ..        ...  ...        ...       ...\n#> 95  47.309873  1.0  10.771928  0.609891\n#> 96  20.741797  0.0   9.829798  0.647284\n#> 97  24.393540  0.0  10.412418  0.624340\n#> 98  53.716540  1.0  11.506078  0.579804\n#> 99  51.222453  1.0  10.711256  0.612344\n#> \n#> [100 rows x 4 columns]\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nlearner_x = BaseXRegressor(learner=LinearRegression())\n\nX = df_python.X.values.reshape(-1,1)\ny = df_python.Y.values\ntreatment = df_python.W.values\ne = df_python.pesos.values\nnueva_X = r.df_nueva_x['X'].values.reshape(-1,1)\n\n# estimamos\ncate_x = learner_x.fit_predict(X=X, treatment=treatment, y=y, p=e)\n\nprint(cate_x)\n\n#> [[24.18445071]\n#>  [23.96165333]\n#>  [22.07738827]\n#>  [23.8290041 ]\n#>  [22.23900667]\n#>  [25.90657902]\n#>  [20.07281545]\n#>  [20.22764413]\n#>  [21.93491718]\n#>  [24.90817005]\n#>  [22.94900375]\n#>  [20.55940033]\n#>  [20.22323467]\n#>  [18.67470923]\n#>  [22.41952385]\n#>  [22.01148778]\n#>  [23.65059347]\n#>  [20.4584526 ]\n#>  [23.13640524]\n#>  [24.76464061]\n#>  [29.17118624]\n#>  [20.61781408]\n#>  [21.84758166]\n#>  [21.37933037]\n#>  [20.36590009]\n#>  [18.29646419]\n#>  [19.56622485]\n#>  [21.73818594]\n#>  [20.82250793]\n#>  [23.25545554]\n#>  [19.9476568 ]\n#>  [23.32259103]\n#>  [17.77992951]\n#>  [19.94871811]\n#>  [21.59347327]\n#>  [19.87909366]\n#>  [21.37264782]\n#>  [24.36127525]\n#>  [21.65050016]\n#>  [23.72101678]\n#>  [18.30885076]\n#>  [22.98876753]\n#>  [19.85749887]\n#>  [23.65489924]\n#>  [23.8774463 ]\n#>  [26.52943858]\n#>  [21.9561297 ]\n#>  [22.06854152]\n#>  [19.65625568]\n#>  [19.09653297]\n#>  [23.61708013]\n#>  [20.31583121]\n#>  [20.90446626]\n#>  [21.98840222]\n#>  [21.98655993]\n#>  [24.7992766 ]\n#>  [18.2264522 ]\n#>  [23.02953222]\n#>  [23.66633862]\n#>  [20.65807062]\n#>  [24.55089614]\n#>  [23.61143985]\n#>  [27.18483957]\n#>  [17.65692503]\n#>  [22.83885017]\n#>  [24.24427817]\n#>  [24.21382276]\n#>  [18.30237035]\n#>  [21.08933438]\n#>  [26.59466223]\n#>  [21.76777266]\n#>  [23.39083619]\n#>  [21.28861592]\n#>  [18.22376141]\n#>  [22.17449599]\n#>  [24.35309297]\n#>  [19.94041482]\n#>  [24.90061955]\n#>  [23.60184813]\n#>  [25.3037691 ]\n#>  [25.71434126]\n#>  [28.01598546]\n#>  [21.10080014]\n#>  [22.45184837]\n#>  [19.16269587]\n#>  [18.77807334]\n#>  [20.1102733 ]\n#>  [24.1353215 ]\n#>  [22.23422848]\n#>  [25.87465564]\n#>  [24.81438579]\n#>  [16.33858204]\n#>  [19.50206724]\n#>  [24.67806615]\n#>  [20.5075564 ]\n#>  [24.11664769]\n#>  [21.84648138]\n#>  [23.25036905]\n#>  [25.88566055]\n#>  [23.97045205]]\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}