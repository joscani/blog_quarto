{
  "hash": "a82e2e80a148c560e5b518b319575f12",
  "result": {
    "markdown": "---\ntitle: ¿Y si ... ? Parte I\ndate: '2020-11-15'\npublishdate: '2020-11-15'\ncategories:\n  - estadística\n  - causal inference\n  - 2020\ndescription: ''\nexecute: \n  message: false\n  warning: false\n  echo: true\nformat: \n  html: \n    fig-height: 5\n    fig-dpi: 300\n    fig-width: 8.88\n    fig-align: center\n    code-fold: show\n    code-summary: \"Mostrar / ocultar código\"\nknitr:\n  opts_chunk:\n    out.width: 80%\n    fig.showtext: TRUE\n    collapse: true\n    comment: \"#>\"\n---\n\n\nLo de la inferencia causal está de moda, y motivos hay, es una herramienta que intenta dar respuesta a preguntas cómo las siguientes. \n\n* ¿Qué habría pasado si en vez de poner este precio a este producto hubiera puesto otro? \n\n* ¿Se habría vendido más? \n\n* ¿He mandado a mi campaña a aquellos para los que justo  al mandar a campaña su probabilidad de compra se incrementa?\n\nTradicionalmente a esta pregunta, los estadísticos respondían con una de sus herramientas más potentes, el diseño de experimentos. Pero muchas veces lo único que tenemos son datos observacionales y se trata de estimar el tamaño del efecto. \n\nLeyendo sobre cosas de este tipo llegué a los \"metalearners\" y en particular al \"T-learner\". \n\nSe trata de estimar el efecto de una variable, típicamente un tratamiento con 2 categorías sobre una variable respuesta, y con presencia de otras variables, de forma que el efecto del tratamiento puede ser diferente según el valor de las covariables, vamos, que haya interacción.\n\nSupongamos que tenemos una variable respuesta Y, un tratamiento W (con dos niveles, 0 y 1) y una o varias covariables X. El T-learner (La T es de two models) lo que propone básicamente es estimar dos modelos. Uno que estime $E[Y | X]$  en el grupo de control (W=0) y otro que estime lo mismo pero en el grupo del tratamiento (W=1) y luego restar esas dos esperanzas. A esto lo llaman una estimación del CATE (Conditional Average Treatment Effects) ¿Fácil, verdad? \n\nSi estamos en el marco de los modelos lineales esta forma de proceder es idéntica a estimar un sólo modelo dónde W es otra variable más y además pondríamos todas las posibles interacciones entre W y X, casi podríamos decir que es el modelo saturado.  De hecho en un modelo lineal, podríamos sacar el CATE simplemente utilizando los coeficientes estimados. \n\n\nEjemplo tonto\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(155)\n\nX <- rnorm(100, 10,1)\nW <- rbinom(100, 1, 0.6)\n\n# Me construyo la Y de forma que haya efectos principales e interacción\nY <- 4 + 2 * X + 2 * W + 2 * W * X + rnorm(100, 0, sd = 2)\n\ndf <- as.data.frame(cbind(Y,W,X))\n```\n:::\n\n\nSi hacemos un modelo sólo sobre los que son W = 0 y otro para los que son W = 1\n(He obviado la parte de hacer train, test, validación, etc).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod0 <- lm(Y ~ X, data = df[W==0, ])\nmod1 <- lm(Y ~ X, data = df[W==1, ])\n```\n:::\n\n\nY si suponemos una nueva observación dónde X = 14 entonces laa estimación del CATE mediante un T -learner.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_nuevo <- data.frame(X = 14)\n(cate1 <- predict(mod1, newdata = df_nuevo) - predict(mod0, newdata = df_nuevo))\n#>        1 \n#> 31.89504\n```\n:::\n\n\n\nHaciendo el modelo con interacción\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\nmod_saturado <-  lm(Y ~ W *X , data = df)\nsummary(mod_saturado)\n#> \n#> Call:\n#> lm(formula = Y ~ W * X, data = df)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -4.6786 -1.2138  0.1903  1.5419  4.6289 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)   6.9118     3.1354   2.204   0.0299 *  \n#> W            -1.8395     4.0511  -0.454   0.6508    \n#> X             1.6981     0.3085   5.504 3.08e-07 ***\n#> W:X           2.4096     0.4016   6.000 3.49e-08 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 2.011 on 96 degrees of freedom\n#> Multiple R-squared:  0.9689,\tAdjusted R-squared:  0.9679 \n#> F-statistic: 995.9 on 3 and 96 DF,  p-value: < 2.2e-16\n```\n:::\n\n\n\nPara ver el efecto de W sobre una hipotética población sería tener la misma observación con X=14, pero en un caso con W= 0 y en otro con W=1\n\nUtilizando los coeficientes, el CATE sería simplemente tener en cuenta cuando interviene W (los otros términos se cancelan).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# \n(cate_2 <- coef(mod_saturado)[2] + coef(mod_saturado)[4] * 14 )\n#>        W \n#> 31.89504\n```\n:::\n\nQue coincide con la estimación usando el \"T - Learner\". Es decir, en este ejemplo sencillo, utilizando como modelo base del T-learner un modelo lineal, la estimación es la misma que considerar un solo modelo dónde tenemos las interacciones del tratamiento con las covariables.\n\nLa aproximación de T - Learner (y de otros metalearners ) cobra sentido cuando tenemos muchas covariables y un modelo lineal con interacciones se puede volver muy complicado. En el caso del T-learner se podría utilizar como modelo base cualquier modelo que estime la $E[Y|W=w_i,X=x]$. \n\nSin meterme mucho en la parte de los \"potential outcomes\" , básicamente se trata de inferir con la población con W=0 lo que pasaría si todas las observaciones tuvieran $Y^{(0)}$ y lo mismo con la población con W=1. Este tipo de estrategias funcionan bien mientras el grado de solape de tratamiento y control en los diferentes valores de X sea alto (en el diseño de experimentos se busca justo eso, jeje).\n\nEn fin, que creo que me he enrollado demasiado para algo que es muy simple. En próximos post a ver si explico mejor los S-learners, los X- learners, los causal tree y causal forest,  modelos de uplift, y más cositas, y con algún ejemplo más claro. \n\n\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}