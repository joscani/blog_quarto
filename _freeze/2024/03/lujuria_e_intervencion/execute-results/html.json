{
  "hash": "d0e1414bd3dcefeb5a442193ca936e3f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lujuria e intervención\"  \ndate: '2024-03-31'\ncategories: \n  - 2024\n  - estadística\n  - full luxury bayes\n  - análisis bayesiano\n  - R\ndescription: ''\nexecute: \n  message: false\n  warning: false\n  echo: true\nformat: \n  html: \n    fig-height: 5\n    fig-dpi: 300\n    fig-width: 8\n    fig-align: center\n    code-fold: show\n    code-summary: \"Show the code\"\nknitr:\n  opts_chunk:\n    out.width: 80%\n    fig.showtext: TRUE\n    collapse: true\n    comment: \"#>\"\n---\n\n\n\n\n::: callout-note\n\n## Listening\n\n<iframe style=\"border-radius:12px\" src=\"https://open.spotify.com/embed/track/6BxCmy6vGbuOckxg6YfQOW?utm_source=generator\" width=\"100%\" height=\"352\" frameBorder=\"0\" allowfullscreen=\"\" allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\" loading=\"lazy\">\n\n</iframe>\n\n:::\n\n## Introducción \n\nCuenta Richard McElreath en sus vídeos de Statistical Rethinking que la inferencia causal no es más\nque predecir la intervención. Una de las cosas que más me llamó la atención es lo que él llama\n\"full luxury bayes\". El \"full luxury\" permite ajustar todo el DAG de un modelo causal, permitiéndonos cosas \nque los seguidores de Pearl dicen que no se puede hacer, cosas como condicionar por un collider o cosas así.\n\nUna vez tenemos el DAG entero ajustado conjuntamente, podemos hacer cosas como simular la intervención. \nEsto no es más que - oye, ¿qué hubiera pasado si todo los individuos hubieran recibido el tratamiento?,\n¿y si todos hubieran estado en control?-  y de esta forma  podemos estimar lo que queremos, que unos lo \nllaman el efecto causal, o ATE (average treatmen effect) y cosas así. \n\n\n\n## Ejemplo simulado\n\nSupongamos que tenemos un DAG. Y que el DAG es correcto.  Esto que acabo de escribir, de que el \nDAG es correcto es la principal asunción de toda la inferencia causal.  No hay inferencia causal sin\nuna descripción explícita de tu modelo causal (__Ciencia antes que estadística__). Las técnicas de \ninferencia causal son sólo herramientas técnicas que nos ayudarán a estimar el efecto. Pero si nuestras\nasunciones son incorrectas, no hay técnica que nos salve.\n\n\n### DAG\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\nlibrary(tidyverse)\nlibrary(dagitty)\nlibrary(ggdag)\n\negypt <- MetBrewer::met.brewer(\"Egypt\")\n\ntheme_nice <- function() {\n  theme_minimal(base_family = \"Archivo Narrow\") +\n    theme(panel.grid.minor = element_blank(),\n          plot.background = element_rect(fill = \"white\", color = NA),\n          plot.title = element_text(face = \"bold\"),\n          axis.title = element_text(face = \"bold\"),\n          strip.text = element_text(face = \"bold\", size = rel(0.8), hjust = 0),\n          strip.background = element_rect(fill = \"grey80\", color = NA),\n          legend.title = element_text(face = \"bold\"))\n}\n\ntheme_set(\n  theme_nice()\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n\ndag_coords <-\n  tibble(name = c(\"S\",  \"M\", \"D\"),\n         x = c(0,  1,  2),\n         y = c(0,  0.2,  0))\n\ndag_simple <- dagify(\n       M ~ S,\n       D ~ M,\n       coords = dag_coords\n       )\ndag_simple %>%\n  ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +\n  geom_dag_text(color = \"black\", size = 10) +\n  geom_dag_point(data = . %>%  filter(name %in% c(\"U\")),\n               shape = 1, stroke = 2, color = \"black\") +\n  geom_dag_edges(edge_color = \"black\", edge_width = 2,\n                 arrow_directed = grid::arrow(length = grid::unit(15, \"pt\"),\n                                              type = \"closed\")) +\n  theme_void()\n```\n\n::: {.cell-output-display}\n![](lujuria_e_intervencion_files/figure-html/unnamed-chunk-2-1.png){width=80%}\n:::\n:::\n\n\n### Simulamos los datos. \n\nVamos a simular los datos, de forma que sabremos cuál es el verdadero efecto causal. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\nS <- rbinom(100,1, 0.3)\n\nM <- 2 * S + rnorm(100, 0, 1)\n\nD <-  5 + 5 * M + rnorm(100, 0, 1)\n```\n:::\n\n\nSabemos que el efecto total de _S_ sobre _D_ es de 10. Por ser M una variable mediadora, y tal\ncomo hemos generado los datos se multiplican los coeficientes. \n\n### Usando dagitty\n\n`dagitty` nos permite saber por qué variabbles hemos de condicionar, según los criterios de Pearl, para obtener \ndiferentes efectos. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\ndagitty::adjustmentSets(dag_simple, exposure = \"S\", outcome = \"D\")\n#>  {}\n```\n:::\n\n\nY vemos que no hay que \"controlar\" por ninguna variable para obtener el efecto de _S_ sobre _D_\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- data.frame(S = S , D = D, M = M)\n\nmod_simple_correcto <- lm(D ~ S, data = df)\nsummary(mod_simple_correcto)\n#> \n#> Call:\n#> lm(formula = D ~ S, data = df)\n#> \n#> Residuals:\n#>      Min       1Q   Median       3Q      Max \n#> -12.7691  -3.8648  -0.5862   3.6303  14.5658 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)   4.6562     0.7031   6.622 1.91e-09 ***\n#> S            11.4955     1.1559   9.945  < 2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 5.581 on 98 degrees of freedom\n#> Multiple R-squared:  0.5023,\tAdjusted R-squared:  0.4972 \n#> F-statistic:  98.9 on 1 and 98 DF,  p-value: < 2.2e-16\n```\n:::\n\n\nY obtenemos el coeficiente correcto. \n\n## Full luxury bayes\n\nEn modelos sencillos usar `dagitty` nos permite encontrar el mínimo conjunto de variables  por las \nque controlar, para encontrar el efecto que buscamos. Pero pueden darse situaciones en las que sea \nnecesario condicionar por una variable que en un \"path\" sea una variable de confusión, mientras que\nen otro sea un \"collider\". En esos casos hay que recurrir al \"front door criterio\" y a veces ni aún\nasí basta. \n\nPero tal y como empezaba el post. La inferencia causal no es más que predecir el efecto de la intervención. \nY eso vamos a hacer. \n\nEn análisis bayesiano podemos ajustar el DAG entero y aún así estimar los efectos incluso condicionando\npor variable que los criterior de Pearl nos dicen que no se pueden. Esto lleva un coste computacional\nno despreciable si el DAG es complejo, de ahí lo de \"luxury\".\n\n\nCon las librerías `brms` y `cmdstanr` es relativamente sencillo ajustar este tipo de modelos\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# library(cmdstanr)  # No me funciona cmdstanr al renderizar en quarto\n#set_cmdstan_path(path = \"~/.cmdstan/cmdstan-2.34.1/\")\nlibrary(brms)\nlibrary(ggdist) # pa pintar \nbf1 <- bf(M  ~  S)\nbf2 <- bf(D  ~  M )\nbf_full <- bf1 + bf2 + set_rescor(rescor = FALSE)\n\nmod_full_luxury <- brm(\n                       bf_full, \n                       chains = 4,\n                       cores = 4, \n                       iter = 2000, \n                       data = df) \n                       #backend = \"cmdstanr\")\n\n```\n:::\n\n\nEn el summary del modelo vemos que este modelo ha recuperado los coeficientes correctos. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n\nsummary(mod_full_luxury)\n#>  Family: MV(gaussian, gaussian) \n#>   Links: mu = identity; sigma = identity\n#>          mu = identity; sigma = identity \n#> Formula: M ~ S \n#>          D ~ M \n#>    Data: df (Number of observations: 100) \n#>   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n#>          total post-warmup draws = 4000\n#> \n#> Regression Coefficients:\n#>             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> M_Intercept    -0.09      0.14    -0.35     0.18 1.00     6248     3076\n#> D_Intercept     5.05      0.11     4.84     5.25 1.00     6264     2969\n#> M_S             2.31      0.22     1.88     2.75 1.00     6005     3074\n#> D_M             5.02      0.06     4.90     5.15 1.00     5702     2801\n#> \n#> Further Distributional Parameters:\n#>         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n#> sigma_M     1.09      0.08     0.95     1.26 1.00     5204     3058\n#> sigma_D     0.97      0.07     0.85     1.11 1.00     5868     3185\n#> \n#> Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n#> and Tail_ESS are effective sample size measures, and Rhat is the potential\n#> scale reduction factor on split chains (at convergence, Rhat = 1).\n```\n:::\n\n\nUna vez tenemos esto , podemos usar las posterior de dos forma. Una sería multiplicando las posteriors \ndel coeficiente de M y el de S, y otra haciendo una \"intervención\"\n\n\n### Multiplicando posteriors\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\nposteriors  <- as.data.frame(mod_full_luxury)\n\nhead(posteriors)\n#>   b_M_Intercept b_D_Intercept    b_M_S    b_D_M  sigma_M   sigma_D Intercept_M\n#> 1 -0.2078611456      5.080026 2.369867 4.952089 1.187319 0.9102176   0.6689897\n#> 2 -0.0006802141      5.046711 2.296216 5.092021 1.054625 1.0270438   0.8489196\n#> 3 -0.1377945778      5.036534 2.246501 5.007023 1.132313 0.9869086   0.6934108\n#> 4 -0.0438541017      4.999751 2.367703 4.909060 1.145089 0.9267522   0.8321959\n#> 5 -0.0092326616      4.999116 2.125023 5.206066 1.023490 1.0684353   0.7770260\n#> 6 -0.2239945163      5.021916 2.550931 5.053909 1.017421 1.0031544   0.7198501\n#>   Intercept_D    lprior      lp__\n#> 1    8.884465 -8.663475 -295.7457\n#> 2    8.958653 -8.639493 -294.9437\n#> 3    8.883175 -8.652335 -294.1798\n#> 4    8.771132 -8.654670 -297.0658\n#> 5    8.998672 -8.632764 -299.1002\n#> 6    8.904578 -8.628174 -294.8313\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n\nefecto_global_S  <- posteriors$b_M_S * posteriors$b_D_M\n\nquantile(efecto_global_S, c(0.025, 0.5, 0.975))\n#>      2.5%       50%     97.5% \n#>  9.458785 11.638945 13.835363\n```\n:::\n\n\nPintando la posterior\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\nefecto_global_S  %>% \n  enframe()  %>%\n  ggplot(aes(x = value)) +\n  stat_halfeye(.width = c(0.67, 0.89, 0.97)) +\n  labs(x = expression(beta[S1]), y = \"Density\")\n```\n\n::: {.cell-output-display}\n![](lujuria_e_intervencion_files/figure-html/unnamed-chunk-10-1.png){width=80%}\n:::\n:::\n\n\n### Simulando la intervención\n\nUna vez tenemos el Dag estimado, podemos recorrerlo haciendo una intervención.\nEsto no es más que ver como sería el efecto cuando S= 0 y cuando S=1\n\nEl \"truco\" es que hay que recorrer el DAG y obteniendo las posteriors tras hacer la intervención. \n\nPor ejemplo, la posterior del coeficiente de M no vale la que ha sacado el modelo, sino que hay que \ncalcularla utilizando el primer modelo el de `M ~ S`, pero poniendo que S = 0, y usar esa posterior \nobtenida en el modelo `D ~ M`.  \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\n# S == 0\n\nM_post0  <- with(posteriors,  b_M_Intercept + b_M_S * 0 )\nD_post0  <- with(posteriors,  b_D_Intercept + b_D_M * M_post0 )\n\n# S == 1\n\nM_post1  <- with(posteriors,  b_M_Intercept + b_M_S * 1 )\nD_post1  <- with(posteriors,  b_D_Intercept + b_D_M * M_post1 )\n\n\nefecto_global_S_intervencion <- D_post1 - D_post0\n\nefecto_global_S_intervencion  %>% \n  enframe()  %>%\n  ggplot(aes(x = value)) +\n  stat_halfeye(.width = c(0.67, 0.89, 0.97)) +\n  labs(x = expression(beta[S1]), y = \"Density\")\n```\n\n::: {.cell-output-display}\n![](lujuria_e_intervencion_files/figure-html/unnamed-chunk-11-1.png){width=80%}\n:::\n:::\n\n\nEl efecto correcto se recupera ajustando el DAG completo y luego simulando una intervención. Tal \ny como dice Richard McElreath, la inferencia causal es predecir el efecto de la intervención. \n\n\n\n## Conclusión\n\nLa inferencia bayesiana nos permite ajustar un DAG completo e incluso ajustar por \"colliders\" o por \nvariables no observadas. Esto puede ser útil cuando tenemos DAGs en los que no se puede obtener correctamente\nel efecto buscado , ya sea porque implica condicionar por variables que tengan el doble rol de \n\"confounder\" y de \"colliders\" en diferentes \"paths\" o por otros motivos. \nEl \"full luxury bayes\" conlleva coste computacional elevado por lo que la estrategia debería ser la \nde usarlo sólo en caso necesario. Pero la verdad es que encuentro cierta belleza en ajustar todo el \ndiagrama causal y luego simular la intervención.\n\n\n\n\n\n\n\n",
    "supporting": [
      "lujuria_e_intervencion_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}