{
  "hash": "2328fe0c2c3f95abd225c1db059a7e9a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Predictores a nivel de grupo e inferencia causal \"  \ndate: '2024-08-29'\ncategories: \n  - 2024\n  - Inferencia causal \n  - análisis bayesiano\n  - R\ndescription: ''\nexecute: \n  message: false\n  warning: false\n  echo: true\nformat: \n  html: \n    fig-height: 5\n    fig-dpi: 300\n    fig-width: 8\n    fig-align: center\n    code-fold: show\n    code-summary: \"Show the code\"\nknitr:\n  opts_chunk:\n    out.width: 80%\n    fig.showtext: TRUE\n    collapse: true\n    comment: \"#>\"\n---\n\n\n::: callout-note\n## Listening\n\n<iframe style=\"border-radius:12px\" src=\"https://open.spotify.com/embed/track/0X7BwjJPco2VMoZnMrIPp6?utm_source=generator\" width=\"100%\" height=\"250\" frameBorder=\"0\" allowfullscreen allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\" loading=\"lazy\">\n\n</iframe>\n\n:::\n\n\n## Introducción\n\nEn una [entrada de mi blog\nanterior](https://muestrear-no-es-pecado-old.netlify.app/2019/02/04/predictores-a-nivel-de-grupo/) comentaba una de las\nfortalezas de los modelos mixtos vs los clásicos, y es la posibilidad de incluir predictores a nivel de grupo. \n\nImaginemos que tenemos datos de los clientes de una empresa a nivel nacional, y entre esos datos tenemos la provincia\ndónde vive cada cliente. Además pensamos que a nivel provincial la propensión a la compra de de nuestro producto varía,\ny también pensamos que esa propensión puede variar por ejemplo por el poder adquisitivo que tienen nuestros clientes.\nPero el caso es que no tenemos los ingresos a nivel de cada cliente, pero si que tenemos información agregada a nivel de\nprovincia, por ejemplo cosas como tasa de paro provincial o renta media provincial. ¿No sería útil usar esa información\n(provincia, tasa paro provincial, renta media provincial) en un posible modelo que explique esas propensiones? \n\n\nSimplificando sería algo como `Propension_i= f(variables_cliente, provincia_cliente, tasa_paro_provincial,\ningresos_medios_provinciales)` que si consideramos modelo glm simple en sintaxis de R, dónde modelamos la variable\ndicótomica, venta/no_venta sería `glm(venta_si ~ variables_cliente + provincia_cliente + tasa_paro_provincial +\ningresos_medios_provinciales, family = binomial)`\n\nPues como contaba en el post de 2019, en un modelo lineal no podemos meter a la vez la variable categórica provincia y\nvariables cuyo valor sea el mismo para todos los clientes de esa provincia. \n\n\nEn cambio, si consideramos un modelo mixto (bayesiano o no), podemos considerar la provincia como efecto aleatorio y la\ntasa de paro provincial y los ingresos medios provinciales como predictores a nivel de grupo. \n\nLa inclusión de estos predictores incrementan la eficiencia de la estimación de la proporción de ventas a nivel de grupo\n, especialmente en los grupos de menor tamaño muestral. Piénsese en tener pocos clientes de Ceuta o Melilla, si no se\ntiene en cuentan predictores a nivel de grupo, el modelo mixto daría estimaciones de proporción de  ventas similares a\nlas que se dan a nivel nacional (lo cual sería una estimación mejor que si consideramos la proporción muestral en los\ndatos ), pero si tenemos datos agregados a nivel de provincia, usarlos en el modelo hará que la estimación de la\nproporción de ventas para esa provincia con pocos datos se parezca más a provincias similares.\n\n\n## ¿Y qué tiene que ver esto con la inferencia causal? \n\nPues apunto algunas cosillas.\n\n1. Usar un modelo mixto (o multinivel o jerárquico o por otro de sus muchos nombres) puede ser muy útil para mejorar la\n   estimación del efecto causal cuando tenemos subgrupos de pequeño tamaño \n\n2. Si usamos un modelo de __varying intercept__ (en terminología de lme4 sería  `outcome ~ (1 | grupo) + Treatment +\n   Confounders)`) se asume implícitamente que los _Intercepts_ son independientes de las otras variables, incluido el\n   tratamiento, pero esta asunción no es realista. Gelman y Hill comentan que se puede solventar añadiendo como\n   predictor a nivel de grupo la proporción de _tratados_ en cada nivel de la variable _grupo_.  Sería algo así como\n   `outcome ~ (1 | grupo ) + Treatment  + Treatment_prop_j + Confounders`. También comentan que añadir otras variables\n   _Confounders_ como predictores a nivel de grupo puede ayudar.\n\n3. Una alternativa es considerar un modelo de __varying slopes__  dónde se permita que el efecto del tratamiento sea\n   distinto en cada nivel de la variable `grupo`. Esto sería algo así como `outcome ~ (1 + Treatment | grupo) +\n   Confounders`. \n\n\nA ver si encuentro un ejemplo dónde explicar esto mismo con datos. Buen verano.\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}