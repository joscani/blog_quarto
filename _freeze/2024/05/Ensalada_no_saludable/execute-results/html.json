{
  "hash": "7eaccd615ae52d61796f1386d60835be",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Ensalada no saludable\"  \ndate: '2024-05-02'\ncategories: \n  - 2024\n  - inferencia causal\n  - full luxury bayes\n  - análisis bayesiano\n  - R\ndescription: ''\nexecute: \n  message: false\n  warning: false\n  echo: true\nformat: \n  html: \n    fig-height: 5\n    fig-dpi: 300\n    fig-width: 8\n    fig-align: center\n    code-fold: show\n    code-summary: \"Show the code\"\nimage: causal_salad.png\nknitr:\n  opts_chunk:\n    out.width: 80%\n    fig.showtext: TRUE\n    collapse: true\n    comment: \"#>\"\n---\n\n\n::: callout-note\n## Listening\n\n<iframe style=\"border-radius:12px\" src=\"https://open.spotify.com/embed/track/58m5an212Vp9B7mmXcnGtm?utm_source=generator\" width=\"100%\" height=\"250\" frameBorder=\"0\" allowfullscreen allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\" loading=\"lazy\">\n\n</iframe>\n\n:::\n\n\n\n## Introducción\n\nEste es el primero de varios posts que más que contenido propio es simplemente comentar lo leído\nen el blog de Richard McElreath, y en particular los 3 posts que me abrieron la mente sobre la \ninferencia causal. \n\nLa serie de post son los siguientes: \n\n* [Regression, Fire, and Dangerous Things (1/3)](https://elevanth.org/blog/2021/06/15/regression-fire-and-dangerous-things-1-3/)\n* [Regression, Fire, and Dangerous Things (2/3)](https://elevanth.org/blog/2021/06/21/regression-fire-and-dangerous-things-2-3/)\n* [Regression, Fire, and Dangerous Things (3/3)](https://elevanth.org/blog/2021/06/29/regression-fire-and-dangerous-things-3-3/)\n\n\nEn el primero cuenta sobre lo que denomina \"Causal Salad\", que no es más que la equivocada \ncostumbre de meter en un modelo todas las variables que se te ocurren y el error de interpretar \nlos coeficientes(en caso de que sea lineal) como efectos causales. Las revistas científicas están \nllenas de esta perjudicial ensalada. \n\nEn el segundo explica cómo si pensamos en el modelo causal, ya sea utilizando un DAG, o en otras formas\nse ha de razonar para a partir de ahí encontrar la forma de contestar a la pregunta de \n¿Cuál es el efecto \"causal\" de X en Y? \n\n\nEn el tercero, explica como utilizando modelos bayesianos podemos ajustar un DAG completo, y utilizar\nese modelo ajustado para responder diferentes cuestiones causales, haciendo simulaciones. \nEn este último post es cuando utiliza el término \"full luxury bayes\". También explica la diferencia entre\ntener un modelo para cada pregunta causal (a lo Pearl), y tener todo el DAG estimado , así como ambas perspectivas \npueden combinarse. De hecho, se puede utilizar el enfoque de Pearl para detectar sobre qué variables no hay que \"condicionar\" \ny la perspectiva de full luxury para poder hacer cosas que el enfoque de Pearl no llega, tales como condicionar por un *collider*\n\n\n## Ensalada causal\n\nEn los posts parte de una muestra hipótetica de pares de madres e hijas, y se trata de estudiar si el número de hijos \nde la madre influye en el número de hijos de la hija. Y considera que hay variables de confusión no medidas, \ntales como entorno social común, cultura del país, etcétera. Otra variable que se cree que puede influir en el número \nde hijos tanto de la madre como de la hija es el orden de nacimiento ( si fueron primogénitas  o no). \n\n\nPara ilustrar la situación simula unos datos, pego su código\nSi no os gustan las asunciones, cambiad la simulación  y los efectos y punto. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1908)\nN <- 200 # number of pairs\nU <- rnorm(N) # simulate confounds\n# birth order and family sizes\nB1 <- rbinom(N, size=1, prob=0.5) # 50% first borns\nM <- rnorm( N , 2*B1 + U )\nB2 <- rbinom(N,size=1,prob=0.5)\nD <- rnorm( N , 2*B2 + U + 0*M ) # change the 0 to turn on causal influence of mom\n```\n:::\n\n\nEn estos datos simulados ha supuesto que hay una variable de confusión no observada, y que afecta por igual manera\n(coeficiente 1) tanto al número de hijos de la madre como de la hija. Ha simulado también que la mitad de las madres \ny de las hijas son primogénitas. Ha considerado que ser primogénita afecta de igual manera(coeficiente 2) \nal número de hijos de madres e hijas.  \n\nY por último ha puesto que el efecto del número de hijos de la madre (M) sobre el número de hijos de la hija(D) es 0. \n\nEs decir, al simular los datos sabemos cuál es el verdadero efecto causal , que en este caso es nulo. Esto va a permitir que \npodamos comparar si la técnica o técnicas propuestas son adecuadas. \n\n\n::: {.callout-tip}\n\n## Ojo\n\nCiencia antes que estadística. En este caso sabemos cuál es la verdad y la relación entre las variables. \nEn la vida real tendremos que crear hipótesis y modelos \"causales \"  de cómo se relacionan las variables, y podrían ser erróneos\n:::\n\n\nLo primero que se nos ocurre para estimar el efecto de M sobre D, sería tan sencillo como una regresión simple. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\nmod_simple <- lm(D ~ M)\nsummary(mod_simple)\n#> \n#> Call:\n#> lm(formula = D ~ M)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -3.9714 -0.9486 -0.0337  1.1119  4.0630 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)   0.7128     0.1244   5.729 3.71e-08 ***\n#> M             0.2596     0.0619   4.194 4.12e-05 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 1.522 on 198 degrees of freedom\n#> Multiple R-squared:  0.08161,\tAdjusted R-squared:  0.07697 \n#> F-statistic: 17.59 on 1 and 198 DF,  p-value: 4.124e-05\n```\n:::\n\n\nY vemos que el coeficiente estimado está muy lejos de la verdad. En este caso se ha estimado como positivo y con un \nerror estándard bastante pequeño. \n\n¿Por qué se ha alejado tanto?  Pues por la asociación que induce la variable U tanto en M como D, de hecho para poder\nestimar el efecto correcto habría que *condicionar* por U, es decir, en este caso incluir U en el modelo. Pero U es \nuna variable que no tenemos medida y por tanto no podemos usarla. \n\n\nEn este momento es cuando alguien dice - ey, pues metamos todas las variables que tenemos medidas en el modelo, eso \ndebería ayudar, ya sabéis, todo el rollo del ceteris paribus y demás-  .  Pues venga, vamos a hacer la ensalada causal\n\n\nY usamos todas  las variables observadas en nuestro modelo de regresión lineal superchachi\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\nmod_salad <- lm(D ~ M + B1 + B2)\nsummary(mod_salad)\n#> \n#> Call:\n#> lm(formula = D ~ M + B1 + B2)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -3.2102 -0.8440  0.1087  0.8454  2.9353 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept) -0.03980    0.15280  -0.260   0.7948    \n#> M            0.39468    0.06326   6.239 2.67e-09 ***\n#> B1          -0.52544    0.22049  -2.383   0.0181 *  \n#> B2           1.80475    0.17101  10.553  < 2e-16 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 1.203 on 196 degrees of freedom\n#> Multiple R-squared:  0.4321,\tAdjusted R-squared:  0.4234 \n#> F-statistic: 49.71 on 3 and 196 DF,  p-value: < 2.2e-16\n```\n:::\n\n\nOh vaya, no sólo no nos acercamos al  verdadero valor del coeficiente buscado, sino que ha habido una amplificación del sesgo. \n\n\nPero, ¿acaso al incluir más variables no hemos mejorado la forma en que modelamos D?. Pues en principio si, tanto viendo\nlos Adjusted R-squared como los AIC , el modelo con más variables predice mejor D.  Pero esto es lo que pasa, porque\nel añadir más variables se está teniendo en cuenta la asociación estadística entre las variables, pero la asociación estadística\nes muy diferente de la pregunta que nos estamos haciendo. Si nuestro objetivo es hacer buenas predicciones, la \"ensalada causal\"\npuede ser útil, pero si el objetivo es entender cómo afecta el número de hijos de la madre sobre el número de hijos de su hija, \nse está antes un problema muy distinto. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\nAIC(mod_simple)\n#> [1] 739.5342\nAIC(mod_salad)\n#> [1] 647.3987\n```\n:::\n\n\n\nEl problema de la aproximación como \"ensalada causal\" es que se ha usado y se sigue usando en muchos estudios, \nde econometría, de sociología, etcétera, dónde el objetivo no era predecir mejor una variable, sino entender como \nafecta el cambio de una variable sobre otra. \n\nPara intentar (y ojo que digo intentar) estimar el efecto causal correctamente hay que pensar de otra manera, hay que \nhacer hipótesis, plantear modelos causales etcétera. Las técnicas estadísticas en muchos casos serán las mismas, pero \nhay que usarlas de forma correcta. De hecho, la parte técnica es la sencilla, lo díficil es plantear el modelo causal\ny que sea correcto, y hay que dar triples saltos mortales haciendo asunciones que pueden no ser comprobables. Pero \nes lo que hay, no nos podemos quedar en la frase de \"asociación no implica causalidad\"\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}