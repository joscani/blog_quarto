{
  "hash": "4ac8cd35d1d688391036176128fb41ca",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Métricas modelo con quarto y h2o\"  \ndate: '2024-04-20'\ncategories: \n  - 2024\n  - quarto\n  - h2o\ndescription: ''\nexecute: \n  message: false\n  warning: false\n  echo: true\nformat: \n  html: \n    fig-height: 5\n    fig-dpi: 300\n    fig-width: 8\n    fig-align: center\n    code-fold: show\n    code-summary: \"Show the code\"\nimage: dashboard.png\nknitr:\n  opts_chunk:\n    out.width: 80%\n    fig.showtext: TRUE\n    collapse: true\n    comment: \"#>\"\n---\n\n\n::: callout-note\n## Listening\n\n<iframe style=\"border-radius:12px\" src=\"https://open.spotify.com/embed/track/15Trb1S2FDZSMLDzWfnlbg?utm_source=generator\" width=\"100%\" height=\"250\" frameBorder=\"0\" allowfullscreen allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\" loading=\"lazy\">\n\n</iframe>\n:::\n\nComo muchos sabréis soy bastante fan de usar h2o en modelización. H2O se\nintegra muy bien con R, Python o con Spark. De hecho , gracias a mi\ninsistencia y conocimiento de como usar esta librería he conseguido\ncambiar la forma de hacer las cosas en más de una empresa, -si, no tengo\nabuela, pero ya va siendo hora de contar las cosas como han sido-.\n\nUna vez tienes entrenado un modelo con h2o se puede guardar como un MOJO\n(Model Object Java Optimization), y este mojo lo puedes usar para\npredecir usando R, python, java o spark, y es muy fácil de\nproductivizar.\n\nEn el fichero mojo (una vez lo descomprimes) aparte del modelo también\nse crea un fichero json en la ruta `experimental/modelDetails.json`\ndónde se guarda información sobre el modelo utilizado, métricas de\ndesempeño en train y validación, y un montón de cosas.\n\nPues parseando ese fichero y tratándolo podemos crearnos un dashboard.\n\nYo me he creado un fichero quarto que toma como parámetro ese fichero\njson y genera un dashboard.\n\n### Fichero qmd \n\nAl bajar, renombrar quitando el _txt\n\n[Descargar Archivo](metricas.qmd_txt)\n\n\nEl contenido es. \n\n\n\n::: {.cell}\n\n```\n#> ---\n#> title: Métricas modelo Churn\n#> author: Squad B2C\n#> format: \n#>   dashboard:\n#>     orientation: columns\n#>     theme: yeti\n#> params:\n#>   fichero_json: \n#>     value: x\n#> ---\n#> \n#> \n#> ```{r setup, include=FALSE}\n#> library(flexdashboard)\n#> library(jsonlite)\n#> library(tidyverse)\n#> ```\n#> \n#> \n#> ```{r load_data}\n#> ## '/home/jose/canadasreche@gmail.com/h2o_production/epa_glm/experimental/modelDetails.json'\n#> ## '/home/jose/canadasreche@gmail.com/h2o_production/xgboost_model_target_jazztel_20191120_stable/experimental/modelDetails.json'\n#> df <- fromJSON(params$fichero_json)\n#> # df <- fromJSON(\"churn_iter13mojo/experimental/modelDetails.json\")\n#> \n#> metricas_training <- df$output$training_metrics$thresholds_and_metric_scores$data %>% t() %>% as.data.frame()\n#> \n#> \n#> if(!is.null(df$output$validation_metrics)){\n#>  metricas_validation <- df$output$validation_metrics$thresholds_and_metric_scores$data %>% t() %>% as.data.frame()\n#>  colnames(metricas_validation) <- df$output$validation_metrics$thresholds_and_metric_scores$columns$name\n#> \n#> }\n#> \n#> \n#> colnames(metricas_training) <- df$output$training_metrics$thresholds_and_metric_scores$columns$name\n#> \n#> \n#> colnames(metricas_training) <- df$output$training_metrics$thresholds_and_metric_scores$columns$name\n#> \n#> ```\n#> \n#> # Training Metrics\n#> \n#> ## Column {width=10%}\n#> \n#> ### Row 1\n#> \n#> \n#> ```{r}\n#> #| title: AUC\n#> gauge(df$output$training_metrics$AUC, min = 0.5, max=1, abbreviateDecimals = 2)\n#> ```\n#> \n#> ### Row 2\n#> \n#> ```{r}\n#> #| component: valuebox\n#> #| title: F1\n#> list(\n#>   icon = \"stopwatch\",\n#>   color = \"primary\",\n#>   value = round(metricas_training[which.max(metricas_training$f1), c(\"f1\")], 2)\n#> )\n#> ```\n#> \n#> \n#> ## Column {width=40%}\n#> \n#> \n#> ### ROC\n#> \n#> ```{r}\n#> plotly::ggplotly(ggplot(metricas_training, aes(x = fpr, y = tpr)) +\n#>   geom_line(color=\"darkorange\") + geom_abline(intercept = 0, slope = 1, size = rel(0.1)))\n#> ```\n#> \n#> \n#> ## Column {width=50%}\n#> \n#> ::: {.panel-tabset}\n#> \n#> ### Gain Lift\n#> \n#> ```{r}\n#> t_gain_lift_data <- as.data.frame(t(df$output$training_metrics$gains_lift_table$data))\n#> colnames(t_gain_lift_data) <- df$output$training_metrics$gains_lift_table$columns$name\n#> \n#> t_gain_lift_data[,] <- sapply(t_gain_lift_data[,], function(x) as.numeric(as.character(x)))\n#> \n#> DT::datatable(round(t_gain_lift_data,2), rownames = FALSE)\n#> ```\n#> \n#> \n#> ### Lift Plot\n#> ```{r}\n#> ggplot(t_gain_lift_data, aes(x=cumulative_data_fraction, y = lift)) +\n#>   geom_line(color=\"darkorange\")\n#> ```\n#> \n#> :::\n#> \n#> # Validation Metrics\n#> ## Column {width=10%}\n#> \n#> ### Row 1\n#> \n#> \n#> ```{r}\n#> #| title: AUC\n#> gauge(df$output$validation_metrics$AUC, min = 0.5, max=1, abbreviateDecimals = 2)\n#> ```\n#> \n#> ### Row 2\n#> \n#> ```{r}\n#> #| component: valuebox\n#> #| title: F1\n#> list(\n#>   icon = \"stopwatch\",\n#>   color = \"primary\",\n#>   value = round(metricas_validation[which.max(metricas_validation$f1), c(\"f1\")], 2)\n#> )\n#> ```\n#> \n#> \n#> ## Column {width=40%}\n#> \n#> \n#> ### ROC\n#> \n#> ```{r}\n#> plotly::ggplotly(ggplot(metricas_validation, aes(x = fpr, y = tpr)) +\n#>   geom_line(color=\"darkorange\") + geom_abline(intercept = 0, slope = 1, size = rel(0.1)))\n#> ```\n#> \n#> \n#> ## Column {width=50%}\n#> \n#> ::: {.panel-tabset}\n#> \n#> ### Gain Lift\n#> \n#> ```{r}\n#> t_gain_lift_data <- as.data.frame(t(df$output$validation_metrics$gains_lift_table$data))\n#> colnames(t_gain_lift_data) <- df$output$validation_metrics$gains_lift_table$columns$name\n#> \n#> t_gain_lift_data[,] <- sapply(t_gain_lift_data[,], function(x) as.numeric(as.character(x)))\n#> \n#> DT::datatable(round(t_gain_lift_data,2), rownames = FALSE)\n#> ```\n#> \n#> \n#> ### Lift Plot\n#> ```{r}\n#> ggplot(t_gain_lift_data, aes(x=cumulative_data_fraction, y = lift)) +\n#>   geom_line(color=\"darkorange\")\n#> ```\n#> \n#> :::\n#> \n#> \n#> # Variable importance\n#> \n#> ## Column\n#> \n#> \n#> ### **Variable Importance**\n#> \n#> ```{r}\n#> var_importance <- df$output$variable_importances$data %>% t() %>% as.data.frame()\n#> colnames(var_importance) <- c(\"variable\", \"importance\",\"rel_importance\", \"otra\")\n#> var_importance <- var_importance %>% \n#>   transmute(\n#>      variable = variable,\n#>      importance = importance %>% as.character() %>% as.numeric,\n#>      rel_importance = rel_importance%>% as.character() %>% as.numeric)\n#> # var_importance$variable <-  as.character(var_importance$variable)\n#> \n#> p <- var_importance %>% \n#>   mutate(variable = fct_reorder(variable, rel_importance)) %>%\n#>   top_n(25, rel_importance)  %>% \n#>   ggplot(\n#>     aes( \n#>     x = variable,\n#>     y = rel_importance \n#>     )) +\n#>   geom_col(fill = \"darkorange\") +\n#>   coord_flip()\n#> \n#> plotly::ggplotly(p)\n#> \n#> write_csv(var_importance, file = \"variables_importantes.csv\")\n#> \n#> \n#> ```\n```\n:::\n\n\n### Script para generar el dashboard\n\nTengo un script en R , pero podría ser en bash que descomprime el modelo (fichero mojo) en una carpeta\ntemporal y llama al fichero qmd para generar el dashboard\n\n[Descargar generar_metricas_quarto.R](generar_metricas_quarto.R)\n\n\n\n::: {.cell}\n\n```\n#> #!/usr/bin/env Rscript\n#> args = commandArgs(trailingOnly=TRUE)\n#> \n#> zipfile = args[1]\n#> output_path = paste0(args[2],'.html')\n#> \n#> fichero_qmd <- 'metricas.qmd'\n#> \n#> \n#> # Generar informe automático\n#> \n#> tmp_dir <- tempdir()\n#> tmp <- tempfile()\n#> \n#> unzip(zipfile = zipfile, exdir = tmp_dir )\n#> \n#> fichero_json = paste0(tmp_dir, \"/experimental/modelDetails.json\")\n#> \n#> \n#> quarto::quarto_render(\n#>   input = fichero_qmd, \n#>   execute_params = list(fichero_json = fichero_json), \n#>   output_file = output_path\n#>     \n#> )\n```\n:::\n\n\n\nY ya sólo quedaría ejecutar esto \n\n```\nRscript --vanilla generar_metricas_quarto.R modelo_mojo.zip output_file\n```\n\n\n### Entrenar un modelo de ejemplo \n\nTengo unos datos bajados de kaggle\n\n[datos kaggle](WA_Fn-UseC_-Telco-Customer-Churn.csv)\n\n\nEntrenamos el modelo con h2o y guardamos el mojo\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(h2o)\n\nh2o.init()\n#> \n#> H2O is not running yet, starting it now...\n#> \n#> Note:  In case of errors look at the following log files:\n#>     /tmp/RtmpwT3Yln/file19a0f3c7ccf4c/h2o_jose_started_from_r.out\n#>     /tmp/RtmpwT3Yln/file19a0f5eb2fdfc/h2o_jose_started_from_r.err\n#> \n#> \n#> Starting H2O JVM and connecting: .. Connection successful!\n#> \n#> R is connected to the H2O cluster: \n#>     H2O cluster uptime:         1 seconds 617 milliseconds \n#>     H2O cluster timezone:       Europe/Madrid \n#>     H2O data parsing timezone:  UTC \n#>     H2O cluster version:        3.44.0.3 \n#>     H2O cluster version age:    3 months and 30 days \n#>     H2O cluster name:           H2O_started_from_R_jose_veb551 \n#>     H2O cluster total nodes:    1 \n#>     H2O cluster total memory:   7.80 GB \n#>     H2O cluster total cores:    12 \n#>     H2O cluster allowed cores:  12 \n#>     H2O cluster healthy:        TRUE \n#>     H2O Connection ip:          localhost \n#>     H2O Connection port:        54321 \n#>     H2O Connection proxy:       NA \n#>     H2O Internal Security:      FALSE \n#>     R Version:                  R version 4.3.3 (2024-02-29)\n\n# Load data\n\nchurn_df <- read_csv(\"./WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n\n# Split data\n\nchurn_hex <-  as.h2o(churn_df)\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\nchurn_hex$Churn  <-  as.factor(churn_hex$Churn)\n\nsplits <- h2o.splitFrame(data = churn_hex, ratios = 0.8, seed = 1234)\ntrain <- h2o.assign(splits[[1]], \"train\")\ntest <- h2o.assign(splits[[2]], \"test\")\n\n\n# Train model\n\nx  <-  colnames(churn_hex)[!colnames(churn_hex) %in% c(\"customerID\", \"Churn\")]\nx\n#>  [1] \"gender\"           \"SeniorCitizen\"    \"Partner\"          \"Dependents\"      \n#>  [5] \"tenure\"           \"PhoneService\"     \"MultipleLines\"    \"InternetService\" \n#>  [9] \"OnlineSecurity\"   \"OnlineBackup\"     \"DeviceProtection\" \"TechSupport\"     \n#> [13] \"StreamingTV\"      \"StreamingMovies\"  \"Contract\"         \"PaperlessBilling\"\n#> [17] \"PaymentMethod\"    \"MonthlyCharges\"   \"TotalCharges\"\ny  <- \"Churn\"\ny\n#> [1] \"Churn\"\n\nmodel <-  h2o.xgboost(\n  model_id = \"Churn_model\", \n  x = x,\n  y = y,\n  training_frame = train,\n  validation_frame = test,\n  distribution = \"bernoulli\",\n  nthread = -1,\n  ntrees = 20,\n  max_depth = 3,\n)\n#> \n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |==================                                                    |  25%\n  |                                                                            \n  |======================================================================| 100%\n\n\nh2o.save_mojo(model, path = \".\", force = TRUE)\n#> [1] \"/media/hd1/canadasreche@gmail.com/blog_quarto/2024/04/Churn_model.zip\"\n\n\nh2o.shutdown(prompt = FALSE)\n```\n:::\n\n\nY ejecutando en la misma carpeta dónde están el modelo y el fichero qmd. \n\nEvidentemente hay que tener instalado  `quarto` y demás cosas. \n\n### Comando que hay que ejecutar en consola\n\n```bash\nRscript --vanilla generar_metricas_quarto.R Churn_model.zip Churn_model_metrics\n```\n\n\n### Informe\n\nY nos genera este bonito informe (descomrpimir el zip)\n\n[Informe generado](dashboard.zip)\n\n![captura pantalla](dashboard.png)\n\nY esto es todo, de esta forma es como yo en mi día a día guardo un pequeño dashboard de cada modelo, simplemente\nleyendo la info que h2o ha guardado en el _mojo_  y así estoy seguro de que esas métricas son justo las que corresponden con los datos usados por el modelo. \n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}